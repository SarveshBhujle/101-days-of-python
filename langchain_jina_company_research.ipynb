{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Company Research 🧊\n",
    "\n",
    "##### 💡 **Research Areas:** Rapid Prototyping, Generative AI, Information Retrieval, Langchain Basics, AI-assisted Market Research, Entrepreneurial Hacking.\n",
    "\n",
    "<div style=\"display:flex; align-items:center; padding: 50px;\">\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"300px\" style=\"width:auto;\" width=\"200px\" src=\"https://avatars.githubusercontent.com/u/192148546?s=400&u=95d76fbb02e6c09671d87c9155f17ca1e4ef8f21&v=4\"> \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "#### This is a simple prototype for automated company research. We wanted a tool to boost our client outreach process, either save time, or come up with better ideas. We built this prototype to gather valuable information from the public internet about companies to help us understand their business and develop better solutions for them.\n",
    "\n",
    "## 🔥 Powered by LangChain, Jina AI & Google Gemini!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Installing Requirements\n",
    "\n",
    "The `install_requirements()` function handles the installation of dependencies from a requirements.txt file.\n",
    "\n",
    "\n",
    "- It checks if the requirements are already installed and skips the installation if true.\n",
    "\n",
    "- If not, it tries to install the requirements using `pip install -r requirements.txt`.\n",
    "\n",
    "- If the installation fails, it retries up to the specified maximum number of retries (`max_retries`).\n",
    "\n",
    "- The process exits with an error if the installation fails after the maximum retries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "requirements_installed = False\n",
    "max_retries = 3\n",
    "retries = 0\n",
    "\n",
    "\n",
    "def install_requirements():\n",
    "    \"\"\"Installs the requirements from requirements.txt file\"\"\"\n",
    "    global requirements_installed\n",
    "    global retries\n",
    "    global max_retries\n",
    "    if requirements_installed:\n",
    "        print(\"Requirements already installed.\")\n",
    "        return\n",
    "\n",
    "    print(\"Installing requirements...\")\n",
    "    install_status = os.system(\"pip install -r requirements.txt\")\n",
    "    if install_status == 0:\n",
    "        print(\"Requirements installed successfully.\")\n",
    "        requirements_installed = True\n",
    "    else:\n",
    "        print(\"Failed to install requirements.\")\n",
    "        if retries < max_retries:\n",
    "            print(\"Retrying...\")\n",
    "            retries += 1\n",
    "            return install_requirements()\n",
    "        exit(1)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `install_requirements()` function checks if the required dependencies are already installed by examining the global variable `requirements_installed`. If they are not installed, the function attempts to install them using `pip` from the `requirements.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_requirements()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Setting Up Environment Variables\n",
    "\n",
    "The `setup_env()` function ensures that required environment variables are loaded and available for the application. It checks if the environment variables (`OPENAI_API_KEY`, `GEMINI_API_KEY`, `SERPER_API_KEY`) are set, and if not, it exits the program. The function uses `load_dotenv()` to load variables from a `.env` file into the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "def setup_env():\n",
    "    \"\"\"Sets up the environment variables\"\"\"\n",
    "\n",
    "    def check_env(env_var):\n",
    "        value = os.getenv(env_var)\n",
    "        if value is None:\n",
    "            print(f\"Please set the {env_var} environment variable.\")\n",
    "            exit(1)\n",
    "        else:\n",
    "            print(f\"{env_var} is set.\")\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    variables_to_check = [\"OPENAI_API_KEY\", \"GEMINI_API_KEY\", \"SERPER_API_KEY\"]\n",
    "\n",
    "    for var in variables_to_check:\n",
    "        check_env(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The setup_env() function is invoked to ensure that the required environment variables are loaded and set correctly. It checks the presence of critical API keys, and if any are missing, the program exits. If all variables are set, the function proceeds to load environment variables from the .env file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Using Google Serper API and OpenAI for Search and Summarization\n",
    "\n",
    "The `simple_serper_openai_search()` function allows you to perform a Google search using the Serper API and summarizes the search results using the OpenAI API. It first retrieves search results for a query, then formats the results into a JSON object. If the `verbose` flag is set to `True`, the function prints the raw results and the summary. Finally, it returns a human-readable summary of the search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "\n",
    "def simple_serper_openai_search(\n",
    "    query=\"What is the current latest news in New York?\", verbose=False\n",
    "):\n",
    "    \"\"\"Simple function to search for a query using Google Serper API and summarize the results using OpenAI API\"\"\"\n",
    "    search = GoogleSerperAPIWrapper()\n",
    "    openai = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    search_results = search.results(query)\n",
    "    search_results_json = json.dumps(search_results, indent=4)\n",
    "    if verbose:\n",
    "        print(\"Search Results Found:\\n\", search_results_json)\n",
    "    search_summary = openai.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a summarizer of search results.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"Given a JSON of search results, neatly format the data into a summary. \n",
    "             The search results are as follows: {search_results_json}. \n",
    "             Don't miss out any details, make sure everything in the JSON is included in a human readable format.\n",
    "             Don't hallucinate or make up factual information.\"\"\",\n",
    "            },\n",
    "        ],\n",
    "        model=\"gpt-4o\",\n",
    "    )\n",
    "    result = search_summary.choices[0].message.content\n",
    "    if verbose:\n",
    "        print(\"Summary of Search Results:\\n\", result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Displaying the Query and Its Response\n",
    "\n",
    "In this step, the code executes a search query, retrieves the summarized result using the `simple_serper_openai_search()` function, and displays it in a formatted Markdown format within the Jupyter notebook.\n",
    "\n",
    "\n",
    "- `query`: The search query to be sent to the Google Serper API.\n",
    "\n",
    "- `response`: The result of the search query after being processed and summarized by the OpenAI API.\n",
    "\n",
    "- `Markdown(f\"### {query}\\n{response}\")`: Formats the query and its response as a Markdown text, displaying it with a heading.\n",
    "\n",
    "- `clear_output()`: Clears the previous output in the notebook to ensure the display is clean before rendering the new content.\n",
    "\n",
    "- `display(markdown)`: Displays the formatted query and response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display, clear_output\n",
    "\n",
    "query = \"What is the latest news in California?\"\n",
    "response = simple_serper_openai_search(query=query, verbose=True)\n",
    "markdown = Markdown(f\"### {query}\\n{response}\")\n",
    "clear_output()\n",
    "display(markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Search Functions for Handling and Processing Results\n",
    "\n",
    "In this step, several functions are created to perform searches and handle the results efficiently, ensuring the data is accurate and relevant.\n",
    "\n",
    "### Functions Overview:\n",
    "\n",
    "- **`jina_search(query)`**:\n",
    "\n",
    "  - **Purpose**: Performs a search using the **Jina AI API**.\n",
    "  \n",
    "  - **Details**: Sends the query to the API and returns the response as text.\n",
    "\n",
    "- **`regular_search(query)`**:\n",
    "\n",
    "  - **Purpose**: Uses the **Google Serper API** to perform a regular search.\n",
    "  \n",
    "  - **Details**: Returns the search results in a structured format, providing organized insights.\n",
    "\n",
    "- **`dedupe_links(links)`**:\n",
    "\n",
    "  - **Purpose**: Removes duplicate links from the given list.\n",
    "  \n",
    "  - **Details**: Converts the list of links to a set and back to a list to ensure uniqueness.\n",
    "\n",
    "- **`collect_links(response)`**:\n",
    "\n",
    "  - **Purpose**: Extracts and collects links from the search results.\n",
    "  \n",
    "  - **Details**: Analyzes the response object, gathers sitelinks and main links, and removes duplicates by using the `dedupe_links` function.\n",
    "\n",
    "These functions work together to perform intelligent searches, collect the necessary links, and process them for further use, ensuring the results are both relevant and non-redundant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "def jina_search(query):\n",
    "    \"\"\"Searches the query using Jina AI API\"\"\"\n",
    "    url = f\"https://s.jina.ai/{query}\"\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": \"Bearer jina_518eb161d77c4ed8ae0fa50025b1f30bHMfArtRdFm6F9_edQZJ5KbWjw3xW\",\n",
    "        \"X-Retain-Images\": \"none\",\n",
    "        \"X-Return-Format\": \"markdown\",\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def regular_search(query):\n",
    "    \"\"\"Searches the query using Google Serper API\"\"\"\n",
    "    search = GoogleSerperAPIWrapper()\n",
    "    response = search.results(query)\n",
    "    return response\n",
    "\n",
    "\n",
    "def dedupe_links(links):\n",
    "    \"\"\"Dedupes the links\"\"\"\n",
    "    return list(set(links))\n",
    "\n",
    "\n",
    "def collect_links(response: str):\n",
    "    \"\"\"Collects the links from the response\"\"\"\n",
    "    organic = response[\"organic\"]\n",
    "    links = []\n",
    "    for item in organic:\n",
    "        sitelinks = item.get(\"sitelinks\")\n",
    "        if sitelinks or (type(sitelinks) == list and len(sitelinks) > 0):\n",
    "            for link in sitelinks:\n",
    "                links.append(link[\"link\"])\n",
    "        links.append(item[\"link\"])\n",
    "    return dedupe_links(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Link Caching for API Credit Efficiency\n",
    "\n",
    "This step implements caching to reduce repeated API calls and save credits by storing search results for future use.\n",
    "\n",
    "### Functions Overview:\n",
    "\n",
    "- **`load_links_cache()`**:\n",
    "\n",
    "  - **Purpose**: Loads the cached links from a JSON file (`links_cache.json`).\n",
    "  \n",
    "  - **Details**: Returns the links stored in the cache, allowing for faster access without repeated API calls.\n",
    "\n",
    "- **`save_links_cache()`**:\n",
    "\n",
    "  - **Purpose**: Saves the current state of the `linksCache` dictionary to the `links_cache.json` file.\n",
    "  \n",
    "  - **Details**: Ensures that the cache is updated with the latest search results to be used in future queries.\n",
    "\n",
    "- **`add_links_to_cache(query, links)`**:\n",
    "\n",
    "  - **Purpose**: Adds newly fetched links for a query to the cache.\n",
    "  \n",
    "  - **Details**: Calls `save_links_cache()` to store the new links, ensuring the cache remains up-to-date with fresh data.\n",
    "\n",
    "- **`get_links_from_regular_search(query)`**:\n",
    "\n",
    "  - **Purpose**: Checks if the links for a query already exist in the cache.\n",
    "  \n",
    "  - **Details**: If cached links are available, they are returned directly. If not, a regular search is performed, links are collected, added to the cache, and then returned for use.\n",
    "\n",
    "By utilizing link caching, this process helps minimize unnecessary API calls, saving credits and improving efficiency by reusing previously fetched search results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Link caching to save API credits\n",
    "linksCache = {}\n",
    "links_cache_file = \"outputs/links_cache.json\"\n",
    "\n",
    "\n",
    "def load_links_cache():\n",
    "    \"\"\"Loads the links cache from the file\"\"\"\n",
    "    with open(links_cache_file, \"r\") as f:\n",
    "        linksCache = json.load(f)\n",
    "    return linksCache\n",
    "\n",
    "\n",
    "def save_links_cache():\n",
    "    \"\"\"Saves the links cache to the file\"\"\"\n",
    "    with open(links_cache_file, \"w\") as f:\n",
    "        json.dump(linksCache, f)\n",
    "\n",
    "\n",
    "def add_links_to_cache(query, links):\n",
    "    \"\"\"Adds the links to the cache\"\"\"\n",
    "    linksCache[query] = links\n",
    "    save_links_cache()\n",
    "\n",
    "\n",
    "def get_links_from_regular_search(query):\n",
    "    \"\"\"Gets the links from the regular search\"\"\"\n",
    "    ## check if file exists\n",
    "\n",
    "    try:\n",
    "        linksCache = load_links_cache()\n",
    "    except:\n",
    "        linksCache = {}\n",
    "\n",
    "    cached_links = linksCache.get(query)\n",
    "    if cached_links:\n",
    "        return cached_links\n",
    "    response = regular_search(query)\n",
    "    links = collect_links(response)\n",
    "    add_links_to_cache(query, links)\n",
    "    return links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Integrating Gemini API for Content Generation\n",
    "\n",
    "This step integrates the Google Gemini API to generate responses to queries using the Gemini model.\n",
    "\n",
    "### Functions Overview:\n",
    "\n",
    "- **`get_gemini_client(model)`**:\n",
    "\n",
    "  - **Purpose**: Configures the Gemini API client with the provided API key and the specified model.\n",
    "  \n",
    "  - **Details**: Returns the client for the given Gemini model, allowing interaction with the Gemini API for content generation.\n",
    "\n",
    "- **`gemini(query, model)`**:\n",
    "\n",
    "  - **Purpose**: Calls the `get_gemini_client()` function to get the Gemini model.\n",
    "  \n",
    "  - **Details**: Sends the query to the model for content generation and returns the generated response text.\n",
    "\n",
    "By integrating the Gemini API, this step enables content generation based on queries, allowing for more dynamic and interactive responses from the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "DEFAULT_GEMINI_MODEL = \"gemini-1.5-flash\"\n",
    "\n",
    "\n",
    "def get_gemini_client(model=DEFAULT_GEMINI_MODEL):\n",
    "    genai.configure(api_key=gemini_api_key)\n",
    "    model = genai.GenerativeModel(model_name=model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def gemini(query, model=DEFAULT_GEMINI_MODEL):\n",
    "    model = get_gemini_client(model)\n",
    "    response = model.generate_content(query)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Running Basic Research on a Company\n",
    "\n",
    "This step performs basic research on a company by querying various aspects such as its goals, founders, competitors, and latest news.\n",
    "\n",
    "### Functions Overview:\n",
    "\n",
    "- **`queries`**:\n",
    "\n",
    "  - **Purpose**: A list of queries is defined to gather general information about the company. These may include details about the company's mission, founders, competitors, and recent news.\n",
    "\n",
    "- **`raw_markdown`**:\n",
    "\n",
    "  - **Purpose**: Initializes an empty string to store the raw Markdown content of search results, allowing for structured aggregation of the information.\n",
    "\n",
    "- **For each query**:\n",
    "\n",
    "  - **Purpose**: The function `jina_search(query)` is called to perform the search using the Jina AI API.\n",
    "\n",
    "  - **Details**: The search results are appended to the `raw_markdown` string, with each query’s results labeled with a title. Progress is printed as the results are updated.\n",
    "\n",
    "- **Return**:\n",
    "\n",
    "  - **Purpose**: The function returns the complete raw Markdown content with all the research results, providing a comprehensive overview of the company.\n",
    "\n",
    "This step automates the process of researching a company by gathering structured data on key aspects, returning the results in Markdown format for easy analysis and review.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_basic_reserach(company):\n",
    "    \"\"\"Runs basic research on the company.\"\"\"\n",
    "    queries = [\n",
    "        f\"What is {company}?\",\n",
    "        f\"What are the top goals of {company}?\",\n",
    "        f\"Who are the founders of {company}?\",\n",
    "        f\"Who are the competitors of {company}?\",\n",
    "        f\"What is the latest news about {company}?\",\n",
    "    ]\n",
    "\n",
    "    raw_markdown = \"\"\n",
    "\n",
    "    for query in queries:\n",
    "        print(f\"Searching for: {query}\")\n",
    "        search_results = jina_search(query)\n",
    "        title = f\"### Search results for {query}\"\n",
    "        raw_markdown += title + \"\\n\" + search_results + \"\\n\"\n",
    "        print(\"Updated results.\")\n",
    "    return raw_markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Creating and Generating a Research Report\n",
    "\n",
    "This step creates a structured research report for a company based on basic research and generates a professional markdown document.\n",
    "\n",
    "### Functions Overview:\n",
    "\n",
    "- **`RESEARCH_REPORT_CREATION_PROMPT`**:\n",
    "\n",
    "  - **Purpose**: A predefined prompt is used to guide the generation of the research report. This prompt ensures that the output is professional, factual, and properly structured.\n",
    "\n",
    "- **`create_research_report`**:\n",
    "\n",
    "  - **Purpose**: Accepts the company name and basic research notes as inputs and formats the prompt for generating the report.\n",
    "  \n",
    "  - **Steps**:\n",
    "  \n",
    "    1. Calls the Gemini API (`gemini`) to generate the research report based on the provided details.\n",
    "    \n",
    "    2. Saves the generated result to a file.\n",
    "    \n",
    "    3. Returns the final report, ensuring it is in Markdown format.\n",
    "    \n",
    "\n",
    "- **`generate_research_report`**:\n",
    "\n",
    "  - **Purpose**: \n",
    "  \n",
    "    1. First, it performs the basic research by calling `run_basic_research`.\n",
    "    \n",
    "    2. Then, it generates the research report by calling `create_research_report`.\n",
    "    \n",
    "    3. The function returns the generated report as a Markdown object for display.\n",
    "\n",
    "This step automates the creation of a professional research report by leveraging the basic research data and generating a well-structured Markdown document using the Gemini API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, clear_output\n",
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "RESEARCH_REPORT_CREATION_PROMPT = \"\"\"\n",
    "    I'm giving you the raw research notes of {company}.\n",
    "    Your job is to generate a compact, 5 page research report in markdown. \n",
    "    Label the page numbers, mark the sections well. \n",
    "    Make sure it is professional, factual and well structured.\n",
    "    Don't hallucinate or make up information.\n",
    "    Make sure each page has atleast 4 sections with 2 paragraphs each or atleast 10 bullet points.\n",
    "    Filter only the information relevant to {company} and discard the rest.\n",
    "    This is a \"Company Research Report\" for Responsible AI stakeholders and Global Hacker Groups that are Legal & Ethical.\n",
    "\n",
    "    Raw Research Notes: '{basic_research}'\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def create_reserach_report(company: str, basic_research: str, output_file=None):\n",
    "    \"\"\"Creates a research report for the company\"\"\"\n",
    "    prompt = RESEARCH_REPORT_CREATION_PROMPT.format(\n",
    "        company=company, basic_research=basic_research\n",
    "    )\n",
    "    print(\"Generating research report...\")\n",
    "    research_report = gemini(prompt)\n",
    "    print(\"Research report generated.\")\n",
    "    clear_output()\n",
    "\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(research_report)\n",
    "    return research_report\n",
    "\n",
    "\n",
    "def generate_research_report(company: str, output_file=None):\n",
    "    \"\"\"Generates a research report for the company\"\"\"\n",
    "    if not output_file:\n",
    "        unix_timestamp = math.floor(datetime.now().timestamp())\n",
    "        output_file = f\"{company}_research_report_${unix_timestamp}.md\"\n",
    "    print(f\"Running basic research on {company}...\")\n",
    "    basic_research = run_basic_reserach(company=company)\n",
    "    print(f\"Basic research completed. {len(basic_research)} characters found.\")\n",
    "    return Markdown(create_reserach_report(company, basic_research, output_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Generating Research Reports for Multiple Companies\n",
    "\n",
    "This step focuses on generating research reports for one or more companies, tracking the time taken for each and handling any errors.\n",
    "\n",
    "### Functions Overview:\n",
    "\n",
    "- **`generate_one_company_report`**:\n",
    "\n",
    "  - **Purpose**: This function generates a research report for a single company.\n",
    "  \n",
    "  - **Steps**:\n",
    "  \n",
    "    1. Tracks the start and end time to calculate the time taken for report generation.\n",
    "    \n",
    "    2. If successful, it returns the generated report.\n",
    "    \n",
    "    3. If an error occurs, it prints the exception stack trace for debugging.\n",
    "  \n",
    "- **`generate_batch_company_reports`**:\n",
    "\n",
    "  - **Purpose**: Handles generating reports for a list of companies.\n",
    "  \n",
    "  - **Steps**:\n",
    "  \n",
    "    1. Iterates through each company in the list.\n",
    "    \n",
    "    2. Calls `generate_research_report` for each company.\n",
    "    \n",
    "    3. Prints the time taken for each individual report generation.\n",
    "    \n",
    "    4. At the end, it provides the total time taken for generating all reports in the batch.\n",
    "    \n",
    "    5. Handles errors gracefully and displays appropriate messages when issues arise.\n",
    "\n",
    "\n",
    "These functions streamline the process of generating research reports for multiple companies, ensuring that the time taken is tracked, errors are handled, and progress is monitored effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import traceback\n",
    "\n",
    "\n",
    "def generate_one_company_report(company: str):\n",
    "    \"\"\"Generates a research report for one company\"\"\"\n",
    "    total_time = 0\n",
    "    try:\n",
    "        company_start_time = datetime.now()\n",
    "        print(f\"Generating research report for {company}...\")\n",
    "        report = generate_research_report(\n",
    "            company,\n",
    "            output_file=f\"data/company_research/${company}_research_report_090825.md\",\n",
    "        )\n",
    "        company_end_time = datetime.now()\n",
    "        company_total_time_seconds = (company_end_time - company_start_time).seconds\n",
    "        total_time += company_total_time_seconds\n",
    "        print(f\"Research report for {company} generated.\")\n",
    "        print(f\"Time taken: {company_total_time_seconds} seconds\")\n",
    "        return report\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to generate research report for {company}.\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "def generate_batch_company_reports(companies: list):\n",
    "    \"\"\"Generates research reports for a batch of companies\"\"\"\n",
    "    print(f\"Generating research reports for {len(companies)} companies.\")\n",
    "    total_time = 0\n",
    "    for company in companies:\n",
    "        try:\n",
    "            company_start_time = datetime.now()\n",
    "            print(f\"Generating research report for {company}...\")\n",
    "            generate_research_report(\n",
    "                company,\n",
    "                output_file=f\"data/company_research/${company}_research_report_090825.md\",\n",
    "            )\n",
    "            company_end_time = datetime.now()\n",
    "            company_total_time_seconds = (company_end_time - company_start_time).seconds\n",
    "            total_time += company_total_time_seconds\n",
    "            print(f\"Research report for {company} generated.\")\n",
    "            print(f\"Time taken: {company_total_time_seconds} seconds\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to generate research report for {company}.\")\n",
    "            print(f\"Error: {e}\")\n",
    "    print(f\"Total time taken: {total_time} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Example of Generating a Research Report for One Company\n",
    "\n",
    "In this step, a research report is generated for a single company (Vercel) using the `generate_one_company_report` function.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "- **`company = \"Vercel\"`**:\n",
    "\n",
    "  - Sets the company name to \"Vercel\" for which the report will be generated.\n",
    "\n",
    "- **`report = generate_one_company_report(company)`**:\n",
    "\n",
    "  - Calls the `generate_one_company_report` function, which generates a research report for \"Vercel\" and stores the result in the `report` variable.\n",
    "\n",
    "- **`display(report)`**:\n",
    "\n",
    "  - Displays the generated research report as Markdown in the notebook.\n",
    "  \n",
    "  - This shows the results of the generated research for the specified company.\n",
    "\n",
    "This example demonstrates how to generate a research report for a single company (Vercel) using the functions defined, providing a clean and structured output in Markdown format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example: One Company Report\n",
    "\n",
    "from IPython.display import Markdown, display, clear_output\n",
    "\n",
    "company = \"Vercel\"\n",
    "\n",
    "report = generate_one_company_report(company)\n",
    "\n",
    "# clear_output()\n",
    "display(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Example of Running Reports on a Batch of Companies (Commented to Save API Credits)\n",
    "\n",
    "In this step, a batch of companies is used to generate research reports.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "- **`companies list:`**\n",
    "\n",
    "  - A list of company names is defined, including \"Google\", \"Deloitte India\", \"Zepto\", and \"Dyte\".\n",
    "\n",
    "- **`generate_batch_company_reports(companies):`**\n",
    "\n",
    "  - This function is called with the `companies` list. It generates research reports for each company in the list and saves them in the specified output file (though this is commented out to avoid consuming API credits).\n",
    "\n",
    "- **`batch_output_report:`**\n",
    "\n",
    "  - This variable holds the path for saving the batch output report. It’s currently commented to save API credits.\n",
    "\n",
    "This example demonstrates how to run reports for multiple companies at once using the `generate_batch_company_reports` function, efficiently handling multiple requests and saving results in a batch output file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example: Run reports on a batch of companies (commented to save API credits)\n",
    "\n",
    "# batch_output_report = \"outputs/batch_company_research_report_01.md\"\n",
    "\n",
    "# companies = [\n",
    "#     \"Google\",\n",
    "#     \"Deloitte India\",\n",
    "#     \"Zepto\",\n",
    "#     \"Dyte\",\n",
    "# ]\n",
    "\n",
    "# generate_batch_company_reports(companies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Company Deep Research\n",
    "\n",
    "The `company_deep_research` function conducts thorough research on a company by exploring multiple queries related to it, such as its founders, competitors, and latest news. \n",
    "\n",
    "It collects relevant links from search results, fetches the page content, converts it to Markdown format, and compiles the information into a research report. \n",
    "\n",
    "This report is then saved in a specified file for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import traceback\n",
    "from markdownify import markdownify as md\n",
    "from uuid import uuid4\n",
    "\n",
    "DEFAULT_REQUEST_TIMEOUT = 30\n",
    "\n",
    "\n",
    "def fetch_page_markdown(url, timeout=DEFAULT_REQUEST_TIMEOUT):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=timeout)\n",
    "        response.raise_for_status()\n",
    "        html = response.text\n",
    "        markdown = md(html)\n",
    "        return markdown\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch page text for {url}.\")\n",
    "        traceback.print_exc()\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def check_file_exists(file):\n",
    "    \"\"\"Checks if the file exists\"\"\"\n",
    "    return os.path.exists(file)\n",
    "\n",
    "\n",
    "def update_temp_file(temp_file, markdown):\n",
    "    \"\"\"Updates the temp file with the markdown\"\"\"\n",
    "    if not check_file_exists(temp_file):\n",
    "        print(f\"Temp file {temp_file} does not exist.\")\n",
    "        print(f\"Creating temp file: {temp_file}\")\n",
    "        with open(temp_file, \"w\") as f:\n",
    "            f.write(markdown)\n",
    "    with open(temp_file, \"a\") as f:\n",
    "        f.write(markdown)\n",
    "\n",
    "\n",
    "def crawl_links_and_get_markdown(links):\n",
    "    \"\"\"Crawls the links and gets the markdown\"\"\"\n",
    "    temp_file = f\"outputs/temp_{uuid4()}.md\"\n",
    "    print(f\"Rolling write to temp file: {temp_file}\")\n",
    "    markdown = \"\"\n",
    "    for link in links:\n",
    "        print(f\"Crawling link: {link}\")\n",
    "        response = fetch_page_markdown(link) + \"\\n\"\n",
    "        title = f\"### PAGE: {link}\\n\"\n",
    "        current_markdown = title + response\n",
    "        update_temp_file(temp_file, current_markdown)\n",
    "        print(f\"Temp file {temp_file} updated.\")\n",
    "        markdown += title + response\n",
    "    return markdown\n",
    "\n",
    "\n",
    "def company_deep_research(company: str) -> Markdown:\n",
    "    \"\"\"Does a deep research on the company.\"\"\"\n",
    "    link_exploration_queries = [\n",
    "        f\"What is {company}?\",\n",
    "        f\"Who are the founders of {company}?\",\n",
    "        f\"Who are the competitors of {company}?\",\n",
    "        f\"What is the latest news about {company}?\",\n",
    "        f\"What are the top goals of {company}?\",\n",
    "        f\"What is {company}'s business model?\",\n",
    "        f\"What is {company} known for\",\n",
    "        f\"Who are some of {company}'s customers?\",\n",
    "        f\"What are some employee reviews of {company}?\",\n",
    "        f\"Where is the headquarters of {company}?\",\n",
    "        f\"What industry does {company} operate in?\",\n",
    "        f\"What are some of the products of {company}?\",\n",
    "    ]\n",
    "\n",
    "    all_links = []\n",
    "\n",
    "    for query in link_exploration_queries:\n",
    "        print(f\"Exploring links for: {query}\")\n",
    "        links = get_links_from_regular_search(query)\n",
    "        all_links.extend(links)\n",
    "\n",
    "    raw_markdown = crawl_links_and_get_markdown(all_links)\n",
    "    unix_timestamp = math.floor(datetime.now().timestamp())\n",
    "    research_report = create_reserach_report(\n",
    "        company,\n",
    "        raw_markdown,\n",
    "        output_file=f\"data/company_research/{company}_research_report_${unix_timestamp}_naive.md\",\n",
    "    )\n",
    "    Markdown(research_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14: Deep Research on Company\n",
    "\n",
    "This code performs deep research on the company \"Databricks\" by exploring various queries related to the company, retrieving relevant links, and then fetching their markdown content.\n",
    "\n",
    " The collected data is compiled into a markdown research report. Finally, the report is displayed in the Jupyter notebook using the `display` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Research: 🚀\n",
    "\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "company = \"Databricks\"\n",
    "\n",
    "display_markdown(company_deep_research(company))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "This app provides a robust solution for generating detailed research reports on companies using various AI-driven search techniques and summarization tools. By integrating APIs like Google Serper and Gemini, along with caching mechanisms, the app ensures efficient and accurate data retrieval. \n",
    "\n",
    "The app's ability to generate both individual and batch reports, format them into markdown, and leverage external links for in-depth research makes it a comprehensive tool for business and market analysis. It automates the research process while ensuring that reports are professional, fact-based, and structured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Thank You for visiting The Hackers Playbook! 🌐\n",
    "\n",
    "If you liked this research material;\n",
    "\n",
    "- [Subscribe to our newsletter.](https://thehackersplaybook.substack.com)\n",
    "\n",
    "- [Follow us on LinkedIn.](https://www.linkedin.com/company/the-hackers-playbook/)\n",
    "\n",
    "- [Leave a star on our GitHub.](https://www.github.com/thehackersplaybook)\n",
    "\n",
    "<div style=\"display:flex; align-items:center; padding: 50px;\">\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"200px\" style=\"width:auto;\" width=\"200px\" src=\"https://avatars.githubusercontent.com/u/192148546?s=400&u=95d76fbb02e6c09671d87c9155f17ca1e4ef8f21&v=4\"> \n",
    "</p>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
