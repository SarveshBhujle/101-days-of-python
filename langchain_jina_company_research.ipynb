{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Company Research ðŸ§Š\n",
    "\n",
    "##### ðŸ’¡ **Research Areas:** Rapid Prototyping, Generative AI, Information Retrieval, Langchain Basics, AI-assisted Market Research, Entrepreneurial Hacking.\n",
    "\n",
    "#### This is a simple prototype for automated company research. We wanted a tool to boost our client outreach process, either save time, or come up with better ideas. We built this prototype to gather valuable information from the public internet about companies to help us understand their business and develop better solutions for them.\n",
    "\n",
    "## ðŸ”¥ Powered by LangChain, Jina AI & Google Gemini!\n",
    "\n",
    "<div style=\"display:flex; align-items:center; padding: 50px;\">\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"300px\" style=\"width:auto;\" width=\"200px\" src=\"https://avatars.githubusercontent.com/u/192148546?s=400&u=95d76fbb02e6c09671d87c9155f17ca1e4ef8f21&v=4\"> \n",
    "</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "requirements_installed = False\n",
    "max_retries = 3\n",
    "retries = 0\n",
    "\n",
    "\n",
    "def install_requirements():\n",
    "    \"\"\"Installs the requirements from requirements.txt file\"\"\"\n",
    "    global requirements_installed\n",
    "    global retries\n",
    "    global max_retries\n",
    "    if requirements_installed:\n",
    "        print(\"Requirements already installed.\")\n",
    "        return\n",
    "\n",
    "    print(\"Installing requirements...\")\n",
    "    install_status = os.system(\"pip install -r requirements.txt\")\n",
    "    if install_status == 0:\n",
    "        print(\"Requirements installed successfully.\")\n",
    "        requirements_installed = True\n",
    "    else:\n",
    "        print(\"Failed to install requirements.\")\n",
    "        if retries < max_retries:\n",
    "            print(\"Retrying...\")\n",
    "            retries += 1\n",
    "            return install_requirements()\n",
    "        exit(1)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_requirements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "def setup_env():\n",
    "    \"\"\"Sets up the environment variables\"\"\"\n",
    "\n",
    "    def check_env(env_var):\n",
    "        value = os.getenv(env_var)\n",
    "        if value is None:\n",
    "            print(f\"Please set the {env_var} environment variable.\")\n",
    "            exit(1)\n",
    "        else:\n",
    "            print(f\"{env_var} is set.\")\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    variables_to_check = [\"OPENAI_API_KEY\", \"GEMINI_API_KEY\", \"SERPER_API_KEY\"]\n",
    "\n",
    "    for var in variables_to_check:\n",
    "        check_env(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "\n",
    "def simple_serper_openai_search(\n",
    "    query=\"What is the current latest news in New York?\", verbose=False\n",
    "):\n",
    "    \"\"\"Simple function to search for a query using Google Serper API and summarize the results using OpenAI API\"\"\"\n",
    "    search = GoogleSerperAPIWrapper()\n",
    "    openai = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    search_results = search.results(query)\n",
    "    search_results_json = json.dumps(search_results, indent=4)\n",
    "    if verbose:\n",
    "        print(\"Search Results Found:\\n\", search_results_json)\n",
    "    search_summary = openai.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a summarizer of search results.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"Given a JSON of search results, neatly format the data into a summary. \n",
    "             The search results are as follows: {search_results_json}. \n",
    "             Don't miss out any details, make sure everything in the JSON is included in a human readable format.\n",
    "             Don't hallucinate or make up factual information.\"\"\",\n",
    "            },\n",
    "        ],\n",
    "        model=\"gpt-4o\",\n",
    "    )\n",
    "    result = search_summary.choices[0].message.content\n",
    "    if verbose:\n",
    "        print(\"Summary of Search Results:\\n\", result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display, clear_output\n",
    "\n",
    "query = \"What is the latest news in California?\"\n",
    "response = simple_serper_openai_search(query=query, verbose=True)\n",
    "markdown = Markdown(f\"### {query}\\n{response}\")\n",
    "clear_output()\n",
    "display(markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "def jina_search(query):\n",
    "    \"\"\"Searches the query using Jina AI API\"\"\"\n",
    "    url = f\"https://s.jina.ai/{query}\"\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": \"Bearer jina_518eb161d77c4ed8ae0fa50025b1f30bHMfArtRdFm6F9_edQZJ5KbWjw3xW\",\n",
    "        \"X-Retain-Images\": \"none\",\n",
    "        \"X-Return-Format\": \"markdown\",\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def regular_search(query):\n",
    "    \"\"\"Searches the query using Google Serper API\"\"\"\n",
    "    search = GoogleSerperAPIWrapper()\n",
    "    response = search.results(query)\n",
    "    return response\n",
    "\n",
    "\n",
    "def dedupe_links(links):\n",
    "    \"\"\"Dedupes the links\"\"\"\n",
    "    return list(set(links))\n",
    "\n",
    "\n",
    "def collect_links(response: str):\n",
    "    \"\"\"Collects the links from the response\"\"\"\n",
    "    organic = response[\"organic\"]\n",
    "    links = []\n",
    "    for item in organic:\n",
    "        sitelinks = item.get(\"sitelinks\")\n",
    "        if sitelinks or (type(sitelinks) == list and len(sitelinks) > 0):\n",
    "            for link in sitelinks:\n",
    "                links.append(link[\"link\"])\n",
    "        links.append(item[\"link\"])\n",
    "    return dedupe_links(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Link caching to save API credits\n",
    "linksCache = {}\n",
    "links_cache_file = \"outputs/links_cache.json\"\n",
    "\n",
    "\n",
    "def load_links_cache():\n",
    "    \"\"\"Loads the links cache from the file\"\"\"\n",
    "    with open(links_cache_file, \"r\") as f:\n",
    "        linksCache = json.load(f)\n",
    "    return linksCache\n",
    "\n",
    "\n",
    "def save_links_cache():\n",
    "    \"\"\"Saves the links cache to the file\"\"\"\n",
    "    with open(links_cache_file, \"w\") as f:\n",
    "        json.dump(linksCache, f)\n",
    "\n",
    "\n",
    "def add_links_to_cache(query, links):\n",
    "    \"\"\"Adds the links to the cache\"\"\"\n",
    "    linksCache[query] = links\n",
    "    save_links_cache()\n",
    "\n",
    "\n",
    "def get_links_from_regular_search(query):\n",
    "    \"\"\"Gets the links from the regular search\"\"\"\n",
    "    ## check if file exists\n",
    "\n",
    "    try:\n",
    "        linksCache = load_links_cache()\n",
    "    except:\n",
    "        linksCache = {}\n",
    "\n",
    "    cached_links = linksCache.get(query)\n",
    "    if cached_links:\n",
    "        return cached_links\n",
    "    response = regular_search(query)\n",
    "    links = collect_links(response)\n",
    "    add_links_to_cache(query, links)\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "DEFAULT_GEMINI_MODEL = \"gemini-1.5-flash\"\n",
    "\n",
    "\n",
    "def get_gemini_client(model=DEFAULT_GEMINI_MODEL):\n",
    "    genai.configure(api_key=gemini_api_key)\n",
    "    model = genai.GenerativeModel(model_name=model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def gemini(query, model=DEFAULT_GEMINI_MODEL):\n",
    "    model = get_gemini_client(model)\n",
    "    response = model.generate_content(query)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_basic_reserach(company):\n",
    "    \"\"\"Runs basic research on the company.\"\"\"\n",
    "    queries = [\n",
    "        f\"What is {company}?\",\n",
    "        f\"What are the top goals of {company}?\",\n",
    "        f\"Who are the founders of {company}?\",\n",
    "        f\"Who are the competitors of {company}?\",\n",
    "        f\"What is the latest news about {company}?\",\n",
    "    ]\n",
    "\n",
    "    raw_markdown = \"\"\n",
    "\n",
    "    for query in queries:\n",
    "        print(f\"Searching for: {query}\")\n",
    "        search_results = jina_search(query)\n",
    "        title = f\"### Search results for {query}\"\n",
    "        raw_markdown += title + \"\\n\" + search_results + \"\\n\"\n",
    "        print(\"Updated results.\")\n",
    "    return raw_markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, clear_output\n",
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "RESEARCH_REPORT_CREATION_PROMPT = \"\"\"\n",
    "    I'm giving you the raw research notes of {company}.\n",
    "    Your job is to generate a compact, 5 page research report in markdown. \n",
    "    Label the page numbers, mark the sections well. \n",
    "    Make sure it is professional, factual and well structured.\n",
    "    Don't hallucinate or make up information.\n",
    "    Make sure each page has atleast 4 sections with 2 paragraphs each or atleast 10 bullet points.\n",
    "    Filter only the information relevant to {company} and discard the rest.\n",
    "    This is a \"Company Research Report\" for Responsible AI stakeholders and Global Hacker Groups that are Legal & Ethical.\n",
    "\n",
    "    Raw Research Notes: '{basic_research}'\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def create_reserach_report(company: str, basic_research: str, output_file=None):\n",
    "    \"\"\"Creates a research report for the company\"\"\"\n",
    "    prompt = RESEARCH_REPORT_CREATION_PROMPT.format(\n",
    "        company=company, basic_research=basic_research\n",
    "    )\n",
    "    print(\"Generating research report...\")\n",
    "    research_report = gemini(prompt)\n",
    "    print(\"Research report generated.\")\n",
    "    clear_output()\n",
    "\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(research_report)\n",
    "    return research_report\n",
    "\n",
    "\n",
    "def generate_research_report(company: str, output_file=None):\n",
    "    \"\"\"Generates a research report for the company\"\"\"\n",
    "    if not output_file:\n",
    "        unix_timestamp = math.floor(datetime.now().timestamp())\n",
    "        output_file = f\"{company}_research_report_${unix_timestamp}.md\"\n",
    "    print(f\"Running basic research on {company}...\")\n",
    "    basic_research = run_basic_reserach(company=company)\n",
    "    print(f\"Basic research completed. {len(basic_research)} characters found.\")\n",
    "    return Markdown(create_reserach_report(company, basic_research, output_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import traceback\n",
    "\n",
    "\n",
    "def generate_one_company_report(company: str):\n",
    "    \"\"\"Generates a research report for one company\"\"\"\n",
    "    total_time = 0\n",
    "    try:\n",
    "        company_start_time = datetime.now()\n",
    "        print(f\"Generating research report for {company}...\")\n",
    "        report = generate_research_report(\n",
    "            company,\n",
    "            output_file=f\"data/company_research/${company}_research_report_090825.md\",\n",
    "        )\n",
    "        company_end_time = datetime.now()\n",
    "        company_total_time_seconds = (company_end_time - company_start_time).seconds\n",
    "        total_time += company_total_time_seconds\n",
    "        print(f\"Research report for {company} generated.\")\n",
    "        print(f\"Time taken: {company_total_time_seconds} seconds\")\n",
    "        return report\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to generate research report for {company}.\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "def generate_batch_company_reports(companies: list):\n",
    "    \"\"\"Generates research reports for a batch of companies\"\"\"\n",
    "    print(f\"Generating research reports for {len(companies)} companies.\")\n",
    "    total_time = 0\n",
    "    for company in companies:\n",
    "        try:\n",
    "            company_start_time = datetime.now()\n",
    "            print(f\"Generating research report for {company}...\")\n",
    "            generate_research_report(\n",
    "                company,\n",
    "                output_file=f\"data/company_research/${company}_research_report_090825.md\",\n",
    "            )\n",
    "            company_end_time = datetime.now()\n",
    "            company_total_time_seconds = (company_end_time - company_start_time).seconds\n",
    "            total_time += company_total_time_seconds\n",
    "            print(f\"Research report for {company} generated.\")\n",
    "            print(f\"Time taken: {company_total_time_seconds} seconds\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to generate research report for {company}.\")\n",
    "            print(f\"Error: {e}\")\n",
    "    print(f\"Total time taken: {total_time} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example: One Company Report\n",
    "\n",
    "from IPython.display import Markdown, display, clear_output\n",
    "\n",
    "company = \"Vercel\"\n",
    "\n",
    "report = generate_one_company_report(company)\n",
    "\n",
    "# clear_output()\n",
    "display(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example: Run reports on a batch of companies (commented to save API credits)\n",
    "\n",
    "# batch_output_report = \"outputs/batch_company_research_report_01.md\"\n",
    "\n",
    "# companies = [\n",
    "#     \"Google\",\n",
    "#     \"Deloitte India\",\n",
    "#     \"Zepto\",\n",
    "#     \"Dyte\",\n",
    "# ]\n",
    "\n",
    "# generate_batch_company_reports(companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import traceback\n",
    "from markdownify import markdownify as md\n",
    "from uuid import uuid4\n",
    "\n",
    "DEFAULT_REQUEST_TIMEOUT = 30\n",
    "\n",
    "\n",
    "def fetch_page_markdown(url, timeout=DEFAULT_REQUEST_TIMEOUT):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=timeout)\n",
    "        response.raise_for_status()\n",
    "        html = response.text\n",
    "        markdown = md(html)\n",
    "        return markdown\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch page text for {url}.\")\n",
    "        traceback.print_exc()\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def check_file_exists(file):\n",
    "    \"\"\"Checks if the file exists\"\"\"\n",
    "    return os.path.exists(file)\n",
    "\n",
    "\n",
    "def update_temp_file(temp_file, markdown):\n",
    "    \"\"\"Updates the temp file with the markdown\"\"\"\n",
    "    if not check_file_exists(temp_file):\n",
    "        print(f\"Temp file {temp_file} does not exist.\")\n",
    "        print(f\"Creating temp file: {temp_file}\")\n",
    "        with open(temp_file, \"w\") as f:\n",
    "            f.write(markdown)\n",
    "    with open(temp_file, \"a\") as f:\n",
    "        f.write(markdown)\n",
    "\n",
    "\n",
    "def crawl_links_and_get_markdown(links):\n",
    "    \"\"\"Crawls the links and gets the markdown\"\"\"\n",
    "    temp_file = f\"outputs/temp_{uuid4()}.md\"\n",
    "    print(f\"Rolling write to temp file: {temp_file}\")\n",
    "    markdown = \"\"\n",
    "    for link in links:\n",
    "        print(f\"Crawling link: {link}\")\n",
    "        response = fetch_page_markdown(link) + \"\\n\"\n",
    "        title = f\"### PAGE: {link}\\n\"\n",
    "        current_markdown = title + response\n",
    "        update_temp_file(temp_file, current_markdown)\n",
    "        print(f\"Temp file {temp_file} updated.\")\n",
    "        markdown += title + response\n",
    "    return markdown\n",
    "\n",
    "\n",
    "def company_deep_research(company: str) -> Markdown:\n",
    "    \"\"\"Does a deep research on the company.\"\"\"\n",
    "    link_exploration_queries = [\n",
    "        f\"What is {company}?\",\n",
    "        f\"Who are the founders of {company}?\",\n",
    "        f\"Who are the competitors of {company}?\",\n",
    "        f\"What is the latest news about {company}?\",\n",
    "        f\"What are the top goals of {company}?\",\n",
    "        f\"What is {company}'s business model?\",\n",
    "        f\"What is {company} known for\",\n",
    "        f\"Who are some of {company}'s customers?\",\n",
    "        f\"What are some employee reviews of {company}?\",\n",
    "        f\"Where is the headquarters of {company}?\",\n",
    "        f\"What industry does {company} operate in?\",\n",
    "        f\"What are some of the products of {company}?\",\n",
    "    ]\n",
    "\n",
    "    all_links = []\n",
    "\n",
    "    for query in link_exploration_queries:\n",
    "        print(f\"Exploring links for: {query}\")\n",
    "        links = get_links_from_regular_search(query)\n",
    "        all_links.extend(links)\n",
    "\n",
    "    raw_markdown = crawl_links_and_get_markdown(all_links)\n",
    "    unix_timestamp = math.floor(datetime.now().timestamp())\n",
    "    research_report = create_reserach_report(\n",
    "        company,\n",
    "        raw_markdown,\n",
    "        output_file=f\"data/company_research/{company}_research_report_${unix_timestamp}_naive.md\",\n",
    "    )\n",
    "    Markdown(research_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Research: ðŸš€\n",
    "\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "company = \"Databricks\"\n",
    "\n",
    "display_markdown(company_deep_research(company))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
