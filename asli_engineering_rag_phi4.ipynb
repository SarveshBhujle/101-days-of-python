{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate: This block goes into every notebook.\n",
    "# It sets up the environment, installs the requirements, and checks for the required environment variables.\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "requirements_installed = False\n",
    "max_retries = 3\n",
    "retries = 0\n",
    "REQUIRED_ENV_VARS = []\n",
    "\n",
    "\n",
    "def install_requirements():\n",
    "    \"\"\"Installs the requirements from requirements.txt file\"\"\"\n",
    "    global requirements_installed\n",
    "    if requirements_installed:\n",
    "        print(\"Requirements already installed.\")\n",
    "        return\n",
    "\n",
    "    print(\"Installing requirements...\")\n",
    "    install_status = os.system(\"pip install -r requirements.txt\")\n",
    "    if install_status == 0:\n",
    "        print(\"Requirements installed successfully.\")\n",
    "        requirements_installed = True\n",
    "    else:\n",
    "        print(\"Failed to install requirements.\")\n",
    "        if retries < max_retries:\n",
    "            print(\"Retrying...\")\n",
    "            retries += 1\n",
    "            return install_requirements()\n",
    "        exit(1)\n",
    "    return\n",
    "\n",
    "\n",
    "def setup_env():\n",
    "    \"\"\"Sets up the environment variables\"\"\"\n",
    "\n",
    "    def check_env(env_var):\n",
    "        value = os.getenv(env_var)\n",
    "        if value is None:\n",
    "            print(f\"Please set the {env_var} environment variable.\")\n",
    "            exit(1)\n",
    "        else:\n",
    "            print(f\"{env_var} is set.\")\n",
    "\n",
    "    load_dotenv(override=True)\n",
    "\n",
    "    variables_to_check = REQUIRED_ENV_VARS\n",
    "\n",
    "    for var in variables_to_check:\n",
    "        check_env(var)\n",
    "\n",
    "\n",
    "install_requirements()\n",
    "clear_output()\n",
    "setup_env()\n",
    "print(\"ðŸš€ Setup complete. Continue to the next cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from typing import List\n",
    "import traceback\n",
    "from markdownify import markdownify as md\n",
    "from youtube_transcript_api.formatters import TextFormatter\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "formatter = TextFormatter()\n",
    "\n",
    "cache = {}\n",
    "\n",
    "\n",
    "def get_base_url(url):\n",
    "    return \"/\".join(url.split(\"/\")[:3])\n",
    "\n",
    "\n",
    "def get_links_from_page(url):\n",
    "    global cache\n",
    "    try:\n",
    "        cached_item = cache.get(url)\n",
    "        cached_urls = cached_item.get(\"urls\") if cached_item else None\n",
    "        if cached_urls:\n",
    "            print(f\"Returning cached links for {url}\")\n",
    "            return cached_urls, None\n",
    "        base_url = get_base_url(url)\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        links = []\n",
    "        for link in soup.find_all(\"a\"):\n",
    "            cur_link = link.get(\"href\")\n",
    "            if not cur_link:\n",
    "                continue\n",
    "            if not cur_link.startswith(\"http\"):\n",
    "                links.append(f\"{base_url}{cur_link}\")\n",
    "            else:\n",
    "                links.append(cur_link)\n",
    "        if not cached_item:\n",
    "            cache[url] = {\n",
    "                \"urls\": links,\n",
    "                \"content\": None,\n",
    "                \"url\": url,\n",
    "            }\n",
    "        else:\n",
    "            cached_item[\"urls\"] = links\n",
    "            cache[url] = cached_item\n",
    "        return links, None\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to get links from {url}. Error: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return [], str(e)\n",
    "\n",
    "\n",
    "def get_page_content(url):\n",
    "    try:\n",
    "        cached_item = cache.get(url)\n",
    "        cached_content = cached_item.get(\"content\") if cached_item else None\n",
    "        if cached_content:\n",
    "            print(f\"Returning cached content for {url}\")\n",
    "            return cached_content, None\n",
    "        if \"youtube\" in url or \"youtu.be\" in url or \"youtube.com\" in url:\n",
    "            video_id = url.split(\"=\")[-1]\n",
    "            transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "            text_transcript = formatter.format_transcript(transcript)\n",
    "            return md(text_transcript), None\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        result = md(str(soup))\n",
    "        if not cached_item:\n",
    "            cache[url] = {\n",
    "                \"urls\": None,\n",
    "                \"content\": result,\n",
    "                \"url\": url,\n",
    "            }\n",
    "        else:\n",
    "            cached_item[\"content\"] = result\n",
    "            cache[url] = cached_item\n",
    "        return result, None\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to get content from {url}. Error: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return \"\", str(e)\n",
    "\n",
    "\n",
    "def get_page_content_batch(urls: List[str]):\n",
    "    results = []\n",
    "    for url in urls:\n",
    "        cached_item = cache.get(url)\n",
    "        cached_content = cached_item.get(\"content\") if cached_item else None\n",
    "        if cached_content:\n",
    "            print(f\"Returning cached content for {url}\")\n",
    "            results.append({\"url\": url, \"content\": cached_content, \"error\": None})\n",
    "            continue\n",
    "        print(f\"Getting content from {url}\")\n",
    "        content, error = get_page_content(url)\n",
    "        results.append({\"url\": url, \"content\": content, \"error\": error})\n",
    "        if not cached_item:\n",
    "            cache[url] = {\n",
    "                \"urls\": None,\n",
    "                \"content\": content,\n",
    "                \"url\": url,\n",
    "            }\n",
    "        else:\n",
    "            cached_item[\"content\"] = content\n",
    "            cache[url] = cached_item\n",
    "        result_bytes_count = len(content.encode(\"utf-8\"))\n",
    "        print(f\"Content from {url} fetched. Size: {result_bytes_count} bytes!\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "knowledge_base_cache = {}\n",
    "\n",
    "\n",
    "def get_ae_blog_links():\n",
    "    blogs_base_url = \"https://arpitbhayani.me/blogs\"\n",
    "    blog_links = []\n",
    "    links, error = get_links_from_page(blogs_base_url)\n",
    "    if error:\n",
    "        return blog_links, error\n",
    "    blog_links.extend(links)\n",
    "    return blog_links, None\n",
    "\n",
    "\n",
    "def clean_whitespace(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Cleans the whitespace as per following rules;\n",
    "    - Removes leading and trailing whitespaces.\n",
    "    - Replaces multiple whitespaces with a single whitespace.\n",
    "    - Replaces multiple newlines with a single newline.\n",
    "    - Removes any leading or trailing newlines.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    multiple_whitespaces_remover = \" \".join(text.split())\n",
    "    return (\n",
    "        multiple_whitespaces_remover.replace(\"\\n \", \"\\n\").replace(\" \\n\", \"\\n\").strip()\n",
    "    )\n",
    "\n",
    "\n",
    "def fetch_knowledge_base():\n",
    "    knowledge_base_link = \"https://arpitbhayani.me/knowledge-base\"\n",
    "    links_to_fetch = []\n",
    "    sub_page_links, error = get_links_from_page(knowledge_base_link)\n",
    "    if error:\n",
    "        return [], error\n",
    "    for link in sub_page_links:\n",
    "        is_knowledge_base_link = \"knowledge-base\" in link\n",
    "        if not is_knowledge_base_link:\n",
    "            continue\n",
    "        is_google_drive_link = \"drive.google.com\" in link\n",
    "        if is_google_drive_link:\n",
    "            continue\n",
    "        result_links = []\n",
    "        try:\n",
    "            blog_links, error = get_links_from_page(link)\n",
    "            if error:\n",
    "                print(f\"Failed to get links from {link}. Error: {error}\")\n",
    "                continue\n",
    "            result_links.extend(blog_links)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to get links from {link}. Error: {e}\")\n",
    "            traceback.print_exc()\n",
    "        links_to_fetch.extend(result_links)\n",
    "    result = get_page_content_batch(links_to_fetch)\n",
    "    return result\n",
    "\n",
    "\n",
    "def build_knowledge_base(output_file=\"ae_knowledge_base.md\"):\n",
    "    try:\n",
    "        now = datetime.now()\n",
    "        now_human_formtted = now.strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "        output_file_name, extension = os.path.splitext(output_file)\n",
    "        output_file = f\"{output_file_name}_{now_human_formtted}{extension}\"\n",
    "        file_exists = os.path.exists(output_file)\n",
    "        if not file_exists:\n",
    "            with open(output_file, \"w\") as f:\n",
    "                f.write(\"# AE Knowledge Base\\n\\n\")\n",
    "        blog_links, error = get_ae_blog_links()\n",
    "        if error:\n",
    "            return [], error\n",
    "        all_content = []\n",
    "        content = get_page_content_batch(blog_links)\n",
    "        knowledge_base_content = fetch_knowledge_base()\n",
    "        all_content.extend(knowledge_base_content)\n",
    "        with open(output_file, \"w\") as f:\n",
    "            for c in all_content:\n",
    "                # c['content'] = clean_whitespace(c['content'])\n",
    "                f.write(f\"# {c['url']}\\n\")\n",
    "                f.write(c[\"content\"])\n",
    "                f.write(\"\\n\\n\")\n",
    "        return content, None\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to build knowledge base. Error: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return [], str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_links, error = get_ae_blog_links()\n",
    "\n",
    "print(f\"Found {len(ae_links)} links\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_base_content = fetch_knowledge_base()\n",
    "\n",
    "print(f\"Fetched {len(knowledge_base_content)} links.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"ae_knowledge_base_v0_0_2.md\"\n",
    "contents, error = build_knowledge_base(output_file=output_file)\n",
    "\n",
    "\n",
    "if error:\n",
    "    print(f\"Failed to build knowledge base. Error: {error}\")\n",
    "else:\n",
    "    print(f\"Knowledge base built successfully. Output file: {output_file}\")\n",
    "    print(f\"Content: {len(contents)} sections. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# TODO: Things to do till this is complete.\n",
    "# - Load and clean the knowledge base content.\n",
    "# - Load the knowledge base content into a vector store.\n",
    "# - Implement a simple RAG using Phi4 and the vector store.\n",
    "# - Implement any optimizations on the RAG to improve response quality.\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
