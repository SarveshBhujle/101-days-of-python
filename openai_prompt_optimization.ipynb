{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "requirements_installed = False\n",
    "max_retries = 3\n",
    "retries = 0\n",
    "\n",
    "\n",
    "def install_requirements():\n",
    "    \"\"\"Installs the requirements from requirements.txt file\"\"\"\n",
    "    global requirements_installed\n",
    "    if requirements_installed:\n",
    "        print(\"Requirements already installed.\")\n",
    "        return\n",
    "\n",
    "    print(\"Installing requirements...\")\n",
    "    install_status = os.system(\"pip install -r requirements.txt\")\n",
    "    if install_status == 0:\n",
    "        print(\"Requirements installed successfully.\")\n",
    "        requirements_installed = True\n",
    "    else:\n",
    "        print(\"Failed to install requirements.\")\n",
    "        if retries < max_retries:\n",
    "            print(\"Retrying...\")\n",
    "            retries += 1\n",
    "            return install_requirements()\n",
    "        exit(1)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_requirements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "def setup_env():\n",
    "    \"\"\"Sets up the environment variables\"\"\"\n",
    "    def check_env(env_var):\n",
    "        value = os.getenv(env_var)\n",
    "        if value is None:\n",
    "            print(f\"Please set the {env_var} environment variable.\")\n",
    "            exit(1)\n",
    "        else:\n",
    "            print(f\"{env_var} is set.\")\n",
    "    load_dotenv()\n",
    "\n",
    "    variables_to_check = [\"OPENAI_API_KEY\"]\n",
    "\n",
    "    for var in variables_to_check:\n",
    "        check_env(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY is set.\n"
     ]
    }
   ],
   "source": [
    "setup_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "\n",
    "class PromptOptimizer:\n",
    "    \"\"\"A simple prompt optimization class that uses OpenAI's Chat API to optimize prompts.\"\"\"\n",
    "\n",
    "    def __init__(self, prompt: str):\n",
    "        \"\"\"Initializes the PromptOptimizer with the given prompt. \"\"\"\n",
    "        self.ai = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        self.prompt = prompt\n",
    "        self.optimized_prompt = None\n",
    "\n",
    "    def optimize(self, optimize_instructions = [\n",
    "        \"Refine the given prompt so that it is fit for use in production environments.\",\n",
    "        \"Make the prompt concise, detailed and clear with a good balance of effectivenss and usefulness.\",\n",
    "    ], turns = 3) -> str:\n",
    "        \"\"\"Optimizes the prompt based on optimize instructions.Â \"\"\"\n",
    "\n",
    "        prompt_to_optimize = self.prompt\n",
    "        previous_optimized_prompt = prompt_to_optimize\n",
    "        for i in range(turns):\n",
    "            try:\n",
    "                print(f\"Optimizing prompt - Turn {i+1}...\")\n",
    "                optimize_prompt = f\"\"\"\n",
    "                    You will be given a prompt, refine it as per the given instructions. \n",
    "                    In addition to the instructions, come up with improvements and apply the refinements to the prompt.\n",
    "                    Respond only with the final refined prompt after all improvements are made.\n",
    "                    Instructions: ```{\"\\n\".join(optimize_instructions)}```\n",
    "                    Prompt: {previous_optimized_prompt}\n",
    "                \"\"\"\n",
    "                system = \"You are an AI prompt optimizer with deep understanding of LLM technology.\"\n",
    "                ai_response = self.ai.chat.completions.create(\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": system},\n",
    "                        { \"role\": \"user\", \"content\": optimize_prompt }\n",
    "                    ],\n",
    "                    model=\"gpt-4o-mini\"\n",
    "                )\n",
    "                previous_optimized_prompt = ai_response.choices[0].message.content\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to optimize prompt for turn {i+1}: {e}\")\n",
    "                continue\n",
    "        self.optimized_prompt = previous_optimized_prompt\n",
    "        return self.optimized_prompt\n",
    "    \n",
    "    def get_optimized_prompt(self) -> str:\n",
    "        \"\"\"Returns the optimized prompt.\"\"\"\n",
    "        if not self.optimized_prompt:\n",
    "            optimized_prompt = self.optimize()\n",
    "            if not optimized_prompt:\n",
    "                print(\"Failed to optimize the prompt.\")\n",
    "        return self.optimized_prompt\n",
    "    \n",
    "\n",
    "    def evaluate(self):\n",
    "        try:\n",
    "            print(\"Evaluating the optimized prompt...\")\n",
    "            optimized_prompt = self.get_optimized_prompt()\n",
    "\n",
    "            if not optimized_prompt:\n",
    "                print(\"Failed to get the optimized prompt, can't evaluate.\")\n",
    "                return None\n",
    "            \n",
    "            evaluation_prompt = f\"\"\"\n",
    "                    Given two prompts, compare the original prompt and the optimized prompt. \n",
    "                    Provide a table with the comparison of the two prompts along with reasons and scores.\n",
    "                    In the markdown response provide a title, summary, and conclusion and the table. \n",
    "                    Respond in markdown format strictly. \n",
    "                    Make sure the markdown tables are compatible with Jupyter notebooks.\n",
    "                    Original Prompt: {self.prompt}\n",
    "                    Optimized Prompt: {optimized_prompt}\n",
    "                \"\"\"\n",
    "            \n",
    "            response = self.ai.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are expert in prompt evaluation.\"},\n",
    "                    {\"role\": \"user\", \"content\": evaluation_prompt}\n",
    "                ])\n",
    "            \n",
    "            header = f\"\"\"# Prompt Optimization Report\\n## Original Prompt\\n{self.prompt}\\n## Optimized Prompt\\n{self.optimized_prompt}\"\"\"\n",
    "            report = response.choices[0].message.content\n",
    "            full_report = header + report\n",
    "            return full_report\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to evaluate the optimized prompt: {e}\")\n",
    "            return None\n",
    "    \n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Markdown\n",
    "\n",
    "def run_prompt_optimizer(prompt: str) -> None:\n",
    "    prompt_optimizer = PromptOptimizer(prompt)\n",
    "    optimized_prompt = prompt_optimizer.get_optimized_prompt()\n",
    "    clear_output()\n",
    "    report = prompt_optimizer.evaluate()\n",
    "    return Markdown(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1\n",
    "prompt = \"Give me a detailed plan for learning Python Programming in 2025.\"\n",
    "\n",
    "run_prompt_optimizer(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2\n",
    "\n",
    "prompt = \"Give me the SOP of a conflict resolution strategy for a team of 5 members in a Big 4 Firm.\"\n",
    "\n",
    "\n",
    "run_prompt_optimizer(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
