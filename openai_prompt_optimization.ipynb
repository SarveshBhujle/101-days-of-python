{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Optimization and Evaluation with OpenAI API\n",
    "\n",
    "<div style=\"display:flex; align-items:center; padding: 50px;\">\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"200px\" style=\"width:auto;\" width=\"200px\" src=\"https://avatars.githubusercontent.com/u/192148546?s=400&u=95d76fbb02e6c09671d87c9155f17ca1e4ef8f21&v=4\"> \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "\n",
    "## Description:\n",
    "\n",
    "This app utilizes OpenAI's GPT-4 model to optimize prompts and evaluate their effectiveness. The PromptOptimizer class refines a given prompt using instructions, iterating several times to improve clarity, conciseness, and effectiveness. After optimization, the app evaluates the original and optimized prompts to generate a comparison report with reasons and scores. The app can be used to optimize prompts for production environments, ensuring they are effective and clear for LLM usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Installing Requirements  \n",
    "\n",
    "---  \n",
    "\n",
    "### Purpose:  \n",
    "\n",
    "- The function **`install_requirements`** ensures that the necessary libraries, which are mentioned in the **`requirements.txt`** file, are installed in the environment.  \n",
    "\n",
    "---  \n",
    "\n",
    "### Steps:  \n",
    "\n",
    "- **Global Variable Setup:**  \n",
    "\n",
    "  - **`requirements_installed`** keeps track of whether the requirements have already been installed.  \n",
    "\n",
    "  - **`max_retries`** and **`retries`** handle the retry mechanism.  \n",
    "\n",
    "- **Installation Logic:**  \n",
    "\n",
    "  - If the requirements aren't installed (**`requirements_installed`** is **False**), it uses the **`os.system()`** method to execute the **`pip install -r requirements.txt`** command to install the packages.  \n",
    "\n",
    "- **Retry Mechanism:**  \n",
    "\n",
    "  - If installation fails, the function retries up to 3 times, before exiting the program.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "requirements_installed = False\n",
    "max_retries = 3\n",
    "retries = 0\n",
    "\n",
    "\n",
    "def install_requirements():\n",
    "    \"\"\"Installs the requirements from requirements.txt file\"\"\"\n",
    "    global requirements_installed\n",
    "    if requirements_installed:\n",
    "        print(\"Requirements already installed.\")\n",
    "        return\n",
    "\n",
    "    print(\"Installing requirements...\")\n",
    "    install_status = os.system(\"pip install -r requirements.txt\")\n",
    "    if install_status == 0:\n",
    "        print(\"Requirements installed successfully.\")\n",
    "        requirements_installed = True\n",
    "    else:\n",
    "        print(\"Failed to install requirements.\")\n",
    "        if retries < max_retries:\n",
    "            print(\"Retrying...\")\n",
    "            retries += 1\n",
    "            return install_requirements()\n",
    "        exit(1)\n",
    "    return\n",
    "\n",
    "install_requirements()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Setting Up Environment Variables  \n",
    "\n",
    "---  \n",
    "\n",
    "### Purpose:  \n",
    "\n",
    "- This code loads environment variables, ensuring that sensitive information (like API keys) are available for the app to function.  \n",
    "\n",
    "---  \n",
    "\n",
    "### Steps:  \n",
    "\n",
    "- **load_dotenv:**  \n",
    "\n",
    "  - The **`load_dotenv()`** method from **`python-dotenv`** loads environment variables from a **`.env`** file into the environment.  \n",
    "\n",
    "- **Checking Required Environment Variables:**  \n",
    "\n",
    "  - The **`check_env`** function checks whether the necessary environment variables (in this case, **`OPENAI_API_KEY`**) are set, and if not, the program prompts the user to set them and exits.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "def setup_env():\n",
    "    \"\"\"Sets up the environment variables\"\"\"\n",
    "    def check_env(env_var):\n",
    "        value = os.getenv(env_var)\n",
    "        if value is None:\n",
    "            print(f\"Please set the {env_var} environment variable.\")\n",
    "            exit(1)\n",
    "        else:\n",
    "            print(f\"{env_var} is set.\")\n",
    "    load_dotenv()\n",
    "\n",
    "    variables_to_check = [\"OPENAI_API_KEY\"]\n",
    "\n",
    "    for var in variables_to_check:\n",
    "        check_env(var)\n",
    "\n",
    "setup_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Prompt Optimization and Evaluation with OpenAI\n",
    "\n",
    "### Purpose:\n",
    "\n",
    "The `PromptOptimizer` class is designed to optimize prompts for use with OpenAI's `GPT-4` model.\n",
    "\n",
    "It takes a user-defined prompt and refines it through multiple iterations, optimizing it for clarity, conciseness, and effectiveness.\n",
    "\n",
    "After the optimization, it evaluates and compares the original and optimized prompts.\n",
    "\n",
    "### 1. Initial Setup\n",
    "\n",
    "#### Imports:\n",
    "\n",
    "- `OpenAI`: This is used to interact with OpenAI's API, specifically for creating chat completions using `GPT` models.\n",
    "\n",
    "- `os`: This module is used to interact with the operating system, particularly for accessing environment variables like the `OpenAI API` key.\n",
    "\n",
    "### 2. Class Definition: `PromptOptimizer`\n",
    "\n",
    "#### Purpose:\n",
    "\n",
    "This class is the core of the application.\n",
    "\n",
    "It manages the prompt optimization and evaluation process.\n",
    "\n",
    "It interacts with the `OpenAI API` to refine and evaluate prompts.\n",
    "\n",
    "### 3. Constructor: `__init__` Method\n",
    "\n",
    "#### Purpose:\n",
    "\n",
    "The constructor initializes the class with a user-provided prompt and sets up the `OpenAI API` client using the API key from the environment variable.\n",
    "\n",
    "#### Parameters:\n",
    "\n",
    "- `prompt`: The original prompt to be optimized.\n",
    "\n",
    "#### Attributes:\n",
    "\n",
    "- `self.ai`: The `OpenAI API` client, initialized with the API key fetched from the environment (`OPENAI_API_KEY`).\n",
    "\n",
    "- `self.prompt`: The original user-provided prompt.\n",
    "\n",
    "- `self.optimized_prompt`: Placeholder for storing the optimized version of the prompt after optimization.\n",
    "\n",
    "### 4. `optimize` Method\n",
    "\n",
    "#### Purpose:\n",
    "\n",
    "This method optimizes the given prompt using a set of instructions and iteratively refines it for a given number of turns.\n",
    "\n",
    "#### Parameters:\n",
    "\n",
    "- `optimize_instructions`: A list of instructions that guide the optimization process.\n",
    "  - Example instructions: \"Refine the prompt to be concise and clear,\" and \"Make the prompt suitable for production environments.\"\n",
    "  \n",
    "- `turns`: The number of iterations to run the optimization. Each turn involves refining the prompt further.\n",
    "\n",
    "#### 4.1. Optimization Loop\n",
    "\n",
    "- `Optimization Instructions`: The `optimize_instructions` provided are passed along with the prompt to instruct OpenAI's model to refine the prompt.\n",
    "\n",
    "- Loop for Multiple Turns: The loop runs for a number of turns (default 3), allowing the prompt to be optimized iteratively. In each iteration:\n",
    "  - A new message is created to instruct the model to refine the prompt according to the provided instructions.\n",
    "  \n",
    "  - The prompt is progressively refined through the iterations.\n",
    "\n",
    "#### 4.2. `OpenAI API` Request\n",
    "\n",
    "- `API Request`: The `optimize_prompt` (which includes both the instructions and the current prompt) is sent to OpenAI's `GPT-4` model.\n",
    "\n",
    "- `role: \"system\"` provides context to the model about its task.\n",
    "\n",
    "- `role: \"user\"` provides the actual prompt that needs refinement.\n",
    "\n",
    "- Response Handling: The optimized prompt returned by OpenAI is stored in `previous_optimized_prompt` for the next iteration.\n",
    "\n",
    "#### 4.3. Error Handling and Final Optimization\n",
    "\n",
    "- Error Handling: If any error occurs during the optimization (e.g., network issues or `API` failure), it catches the exception and continues with the next iteration.\n",
    "\n",
    "- Final Optimized Prompt: After completing all iterations, the final optimized prompt is stored in `self.optimized_prompt` and returned.\n",
    "\n",
    "### 5. `get_optimized_prompt` Method\n",
    "\n",
    "#### Purpose:\n",
    "\n",
    "This method retrieves the optimized prompt.\n",
    "\n",
    "If it hasn't been optimized yet, it calls the `optimize()` method to perform the optimization.\n",
    "\n",
    "#### Logic:\n",
    "\n",
    "- If the prompt has already been optimized, it returns the optimized version.\n",
    "\n",
    "- If not, it triggers the optimization process and returns the result.\n",
    "\n",
    "### 6. `evaluate` Method\n",
    "\n",
    "#### Purpose:\n",
    "\n",
    "This method evaluates the original prompt against the optimized prompt by providing a detailed comparison.\n",
    "\n",
    "#### Evaluation Process:\n",
    "\n",
    "- The evaluation checks how well the optimization was done and returns a markdown report that compares the two prompts.\n",
    "\n",
    "#### 6.1. Evaluation Prompt Creation\n",
    "\n",
    "- Purpose: This string constructs the evaluation prompt, instructing OpenAI's model to compare both prompts (original and optimized) and generate a markdown table with the comparison.\n",
    "\n",
    "#### 6.2. `API` Call for Evaluation\n",
    "\n",
    "- Purpose: The `evaluation_prompt` is sent to OpenAI's API to compare the two prompts and generate the evaluation.\n",
    "\n",
    "#### 6.3. Report Generation\n",
    "\n",
    "- Purpose: A markdown header with the original and optimized prompts is created, and the evaluation report generated by the API is appended to it.\n",
    "\n",
    "- Return: The full report, including the comparison and evaluation, is returned.\n",
    "\n",
    "### 7. Error Handling in `evaluate` Method\n",
    "\n",
    "#### Purpose:\n",
    "\n",
    "If any error occurs during the evaluation, it is caught and an error message is printed.\n",
    "\n",
    "The method returns `None` if evaluation fails.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary:\n",
    "\n",
    "The `PromptOptimizer` class is a robust tool for refining prompts and comparing their effectiveness.\n",
    "\n",
    "It:\n",
    "\n",
    "- Optimizes a given prompt over multiple iterations using OpenAI’s `GPT-4` model.\n",
    "\n",
    "- Evaluates the original and optimized prompts by generating a detailed comparison report.\n",
    "\n",
    "- Handles errors and ensures that the optimized prompt meets production-ready standards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "\n",
    "class PromptOptimizer:\n",
    "    \"\"\"A simple prompt optimization class that uses OpenAI's Chat API to optimize prompts.\"\"\"\n",
    "\n",
    "    def __init__(self, prompt: str):\n",
    "        \"\"\"Initializes the PromptOptimizer with the given prompt. \"\"\"\n",
    "        self.ai = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        self.prompt = prompt\n",
    "        self.optimized_prompt = None\n",
    "\n",
    "    def optimize(self, optimize_instructions = [\n",
    "        \"Refine the given prompt so that it is fit for use in production environments.\",\n",
    "        \"Make the prompt concise, detailed and clear with a good balance of effectivenss and usefulness.\",\n",
    "    ], turns = 3) -> str:\n",
    "        \"\"\"Optimizes the prompt based on optimize instructions. \"\"\"\n",
    "\n",
    "        prompt_to_optimize = self.prompt\n",
    "        previous_optimized_prompt = prompt_to_optimize\n",
    "        for i in range(turns):\n",
    "            try:\n",
    "                print(f\"Optimizing prompt - Turn {i+1}...\")\n",
    "                optimize_prompt = f\"\"\"\n",
    "                    You will be given a prompt, refine it as per the given instructions. \n",
    "                    In addition to the instructions, come up with improvements and apply the refinements to the prompt.\n",
    "                    Respond only with the final refined prompt after all improvements are made.\n",
    "                    Instructions: ```{\"\\n\".join(optimize_instructions)}```\n",
    "                    Prompt: {previous_optimized_prompt}\n",
    "                \"\"\"\n",
    "                system = \"You are an AI prompt optimizer with deep understanding of LLM technology.\"\n",
    "                ai_response = self.ai.chat.completions.create(\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": system},\n",
    "                        { \"role\": \"user\", \"content\": optimize_prompt }\n",
    "                    ],\n",
    "                    model=\"gpt-4o-mini\"\n",
    "                )\n",
    "                previous_optimized_prompt = ai_response.choices[0].message.content\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to optimize prompt for turn {i+1}: {e}\")\n",
    "                continue\n",
    "        self.optimized_prompt = previous_optimized_prompt\n",
    "        return self.optimized_prompt\n",
    "    \n",
    "    def get_optimized_prompt(self) -> str:\n",
    "        \"\"\"Returns the optimized prompt.\"\"\"\n",
    "        if not self.optimized_prompt:\n",
    "            optimized_prompt = self.optimize()\n",
    "            if not optimized_prompt:\n",
    "                print(\"Failed to optimize the prompt.\")\n",
    "        return self.optimized_prompt\n",
    "    \n",
    "\n",
    "    def evaluate(self):\n",
    "        try:\n",
    "            print(\"Evaluating the optimized prompt...\")\n",
    "            optimized_prompt = self.get_optimized_prompt()\n",
    "\n",
    "            if not optimized_prompt:\n",
    "                print(\"Failed to get the optimized prompt, can't evaluate.\")\n",
    "                return None\n",
    "            \n",
    "            evaluation_prompt = f\"\"\"\n",
    "                    Given two prompts, compare the original prompt and the optimized prompt. \n",
    "                    Provide a table with the comparison of the two prompts along with reasons and scores.\n",
    "                    In the markdown response provide a title, summary, and conclusion and the table. \n",
    "                    Respond in markdown format strictly. \n",
    "                    Make sure the markdown tables are compatible with Jupyter notebooks.\n",
    "                    Original Prompt: {self.prompt}\n",
    "                    Optimized Prompt: {optimized_prompt}\n",
    "                \"\"\"\n",
    "            \n",
    "            response = self.ai.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are expert in prompt evaluation.\"},\n",
    "                    {\"role\": \"user\", \"content\": evaluation_prompt}\n",
    "                ])\n",
    "            \n",
    "            header = f\"\"\"# Prompt Optimization Report\\n## Original Prompt\\n{self.prompt}\\n## Optimized Prompt\\n{self.optimized_prompt}\"\"\"\n",
    "            report = response.choices[0].message.content\n",
    "            full_report = header + report\n",
    "            return full_report\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to evaluate the optimized prompt: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run Prompt Optimization and Generate Evaluation Report\n",
    "\n",
    "This block of code runs the prompt optimization and generates an evaluation report. Here's what each part does:\n",
    "\n",
    "### Importing necessary modules:\n",
    "\n",
    "- `clear_output`: Clears the current output in the Jupyter notebook to keep the display clean.\n",
    "\n",
    "- `Markdown`: Allows the return of the evaluation report in `Markdown` format to be rendered properly in Jupyter notebooks.\n",
    "\n",
    "### Defining the function `run_prompt_optimizer`:\n",
    "\n",
    "This function takes a `prompt` as input, which will be optimized using the `PromptOptimizer` class.\n",
    "\n",
    "### Creating an instance of `PromptOptimizer`:\n",
    "\n",
    "An instance of the `PromptOptimizer` class is created with the given prompt. This initializes the class and prepares it to optimize the provided prompt.\n",
    "\n",
    "### Optimizing the prompt:\n",
    "\n",
    "The `get_optimized_prompt()` method of the `PromptOptimizer` class is called to retrieve the optimized version of the prompt.\n",
    "\n",
    "### Clearing the output:\n",
    "\n",
    "Clears any previous outputs from the notebook to ensure a clean display.\n",
    "\n",
    "### Evaluating the optimized prompt:\n",
    "\n",
    "The `evaluate()` method of the `PromptOptimizer` class is called, which compares the original and optimized prompts and generates a detailed evaluation report.\n",
    "\n",
    "### Returning the evaluation report in `Markdown` format:\n",
    "\n",
    "The generated evaluation report is returned in `Markdown` format, which is rendered in Jupyter notebooks as properly formatted output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Markdown\n",
    "\n",
    "def run_prompt_optimizer(prompt: str) -> None:\n",
    "    prompt_optimizer = PromptOptimizer(prompt)\n",
    "    optimized_prompt = prompt_optimizer.get_optimized_prompt()\n",
    "    clear_output()\n",
    "    report = prompt_optimizer.evaluate()\n",
    "    return Markdown(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Run Prompt Optimization and Evaluation\n",
    "\n",
    "### Example 1:\n",
    "\n",
    "The prompt asks for a detailed plan for learning Python programming in 2025.\n",
    "\n",
    "`run_prompt_optimizer(prompt)` will optimize this prompt and generate an evaluation report comparing the original and optimized versions.\n",
    "\n",
    "### Example 2:\n",
    "\n",
    "The prompt asks for the Standard Operating Procedure (SOP) for a conflict resolution strategy for a team of 5 members in a Big 4 firm.\n",
    "\n",
    "`run_prompt_optimizer(prompt)` will optimize this prompt and provide an evaluation report as well.\n",
    "\n",
    "In both examples, the function optimizes and evaluates the prompts using the `PromptOptimizer` class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1\n",
    "\n",
    "prompt = \"Give me a detailed plan for learning Python Programming in 2025.\"\n",
    "\n",
    "run_prompt_optimizer(prompt)\n",
    "\n",
    "# Example 2\n",
    "\n",
    "prompt = \"Give me the SOP of a conflict resolution strategy for a team of 5 members in a Big 4 Firm.\"\n",
    "\n",
    "run_prompt_optimizer(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "This app provides an easy-to-use interface for refining prompts and evaluating their effectiveness in AI-driven environments. By using OpenAI's GPT-4 model, the app ensures that prompts are optimized to be concise, clear, and useful, followed by a detailed evaluation report comparing the original and optimized prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Thank You for visiting The Hackers Playbook! 🌐\n",
    "\n",
    "If you liked this research material;\n",
    "\n",
    "- [Subscribe to our newsletter.](https://thehackersplaybook.substack.com)\n",
    "\n",
    "- [Follow us on LinkedIn.](https://www.linkedin.com/company/the-hackers-playbook/)\n",
    "\n",
    "- [Leave a star on our GitHub.](https://www.github.com/thehackersplaybook)\n",
    "\n",
    "<div style=\"display:flex; align-items:center; padding: 50px;\">\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"200px\" style=\"width:auto;\" width=\"200px\" src=\"https://avatars.githubusercontent.com/u/192148546?s=400&u=95d76fbb02e6c09671d87c9155f17ca1e4ef8f21&v=4\"> \n",
    "</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
