{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-learning Text Summarization üê¨\n",
    "\n",
    "##### üí° **Research Areas:** Rapid Prototyping, Generative AI, Iterative Refinement, Text Summarization.\n",
    "\n",
    "#### This is a simple prototype demonstrating the power of iterative refinement i.e. iteratively refining the output via the LLM to generate high-quality text summaries.\n",
    "\n",
    "<div style=\"display:flex; align-items:center; padding: 50px;\">\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"300px\" style=\"width:auto;\" width=\"200px\" src=\"https://avatars.githubusercontent.com/u/192148546?s=400&u=95d76fbb02e6c09671d87c9155f17ca1e4ef8f21&v=4\"> \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "## Description:\n",
    "\n",
    "Description\n",
    "Self-learning Text Summarization Prototype\n",
    "This project demonstrates the power of iterative refinement in generating high-quality text summaries. Using an AI-driven pipeline, the system analyzes input text, generates a summary, and improves it iteratively based on self-feedback to enhance clarity, coherence, and conciseness.\n",
    "\n",
    "- Core Features:\n",
    "\n",
    "   \n",
    "    - Rapid prototyping using LLMs.\n",
    "   \n",
    "    - Iterative refinement for quality improvement.\n",
    "   \n",
    "    - Multi-step summarization with context understanding.\n",
    "\n",
    "- Applications:\n",
    "\n",
    " \n",
    "    - Efficient text summarization.\n",
    "    \n",
    "    - Adaptable for multiple formats and contexts (plain text, markdown).\n",
    "    \n",
    "    - Provides metadata and quality evaluations.\n",
    "    \n",
    "    - This tool simplifies complex content for easier understanding and supports detailed refinement for professional use cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup\n",
    "\n",
    "The environment setup process installs necessary dependencies, checks for required environment variables, and clears the output. \n",
    "\n",
    "It includes retry logic for package installation failures, ensuring smooth execution with proper error handling and guidance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate: This block goes into every notebook.\n",
    "# It sets up the environment, installs the requirements, and checks for the required environment variables.\n",
    "\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "requirements_installed = False\n",
    "max_retries = 3\n",
    "retries = 0\n",
    "REQUIRED_ENV_VARS = [\"OPENAI_API_KEY\"]\n",
    "\n",
    "\n",
    "def install_requirements():\n",
    "    \"\"\"Installs the requirements from requirements.txt file\"\"\"\n",
    "    global requirements_installed\n",
    "    if requirements_installed:\n",
    "        print(\"Requirements already installed.\")\n",
    "        return\n",
    "\n",
    "    print(\"Installing requirements...\")\n",
    "    install_status = os.system(\"pip install -r requirements.txt\")\n",
    "    if install_status == 0:\n",
    "        print(\"Requirements installed successfully.\")\n",
    "        requirements_installed = True\n",
    "    else:\n",
    "        print(\"Failed to install requirements.\")\n",
    "        if retries < max_retries:\n",
    "            print(\"Retrying...\")\n",
    "            retries += 1\n",
    "            return install_requirements()\n",
    "        exit(1)\n",
    "    return\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "def setup_env():\n",
    "    \"\"\"Sets up the environment variables\"\"\"\n",
    "\n",
    "    def check_env(env_var):\n",
    "        value = os.getenv(env_var)\n",
    "        if value is None:\n",
    "            print(f\"Please set the {env_var} environment variable.\")\n",
    "            exit(1)\n",
    "        else:\n",
    "            print(f\"{env_var} is set.\")\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    variables_to_check = REQUIRED_ENV_VARS\n",
    "\n",
    "    for var in variables_to_check:\n",
    "        check_env(var)\n",
    "\n",
    "\n",
    "install_requirements()\n",
    "setup_env()\n",
    "clear_output()\n",
    "print(\"üöÄ Setup complete. Continue to the next cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: SelfLearningSummarizer Class\n",
    "\n",
    "The `SelfLearningSummarizer` class automates text summarization, refinement, and comparison. It utilizes OpenAI‚Äôs API, with methods for generating summaries, refining them iteratively, and comparing the quality of different summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from uuid import uuid4\n",
    "\n",
    "DEFAULT_OPENAI_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "SIMPLE_SUMMARIZATION_SYSTEM_PROMPT = \"\"\"\n",
    "    You are SummarizerGPT, an advanced AI system specialized in text summarization. Your core function is to process and analyze various types of text input, preparing the groundwork for generating high-quality summaries. Your capabilities include:\n",
    "\n",
    "    1. Text Analysis: Quickly assess the structure, style, and content of any given text.\n",
    "    2. Context Recognition: Identify the domain, target audience, and purpose of the text.\n",
    "    3. Language Processing: Understand and process text in multiple languages and dialects.\n",
    "    4. Semantic Comprehension: Grasp complex ideas, abstract concepts, and subtle nuances in the text.\n",
    "    5. Information Hierarchy: Recognize the relative importance of different pieces of information within the text.\n",
    "    6. Cross-referencing: Identify and connect related ideas across different parts of the text.\n",
    "    7. Bias Detection: Recognize potential biases or slants in the original text.\n",
    "    8. Data Extraction: Pull out key statistics, dates, names, and other crucial data points.\n",
    "    9. Tone Analysis: Understand the emotional tone and rhetorical style of the text.\n",
    "    10. Multi-format Handling: Process various text formats including plain text, HTML, PDF extracts, and more.\n",
    "\n",
    "    You do not generate the summary directly. Instead, you prepare a comprehensive analysis of the text, which will be used by the summarization module to create the final output. Your analysis should include:\n",
    "\n",
    "    - Text type and structure\n",
    "    - Main topic and key themes\n",
    "    - Target audience and purpose\n",
    "    - Important data points and statistics\n",
    "    - Identified biases or controversial points\n",
    "    - Tone and style characteristics\n",
    "    - Any unique or standout elements in the text\n",
    "\n",
    "    Await the input text, and be ready to provide this detailed analysis to support the summarization process.\n",
    "\"\"\"\n",
    "\n",
    "SIMPLE_SUMMARIZATION_PROMPT = \"\"\"\n",
    "    1. Analyze the input:\n",
    "    - Determine the text type (article, research paper, conversation, etc.)\n",
    "    - Identify the main topic and key themes\n",
    "    - Assess the length and complexity of the content\n",
    "\n",
    "    2. Generate the summary:\n",
    "    - Provide a concise yet informative summary\n",
    "    - Maintain the original tone and style where appropriate\n",
    "    - Ensure factual accuracy and avoid introducing new information\n",
    "    - Use clear, coherent language suitable for a general audience\n",
    "\n",
    "    3. Structure the summary:\n",
    "    - Begin with a brief overview of the main topic\n",
    "    - Organize key points logically, using paragraphs or bullet points as appropriate\n",
    "    - Conclude with the most significant takeaway or implication\n",
    "\n",
    "    4. Adapt to specific requirements:\n",
    "    - If a word/character limit is specified, adhere to it strictly\n",
    "    - If the text contains technical terms, provide brief explanations\n",
    "    - For multi-section documents, summarize each section separately, then provide an overall summary\n",
    "\n",
    "    5. Handle edge cases:\n",
    "    - For very short texts, provide a condensed version without losing essential information\n",
    "    - For extremely long or complex texts, focus on the most crucial points and indicate that it's a high-level summary\n",
    "    - If the text contains conflicting viewpoints, present them objectively without bias\n",
    "\n",
    "    6. Enhance readability:\n",
    "    - Use transition words to improve flow between ideas\n",
    "    - Employ varied sentence structures to maintain engagement\n",
    "    - Highlight key terms or concepts using bold text when appropriate\n",
    "\n",
    "    7. Quality check:\n",
    "    - Ensure the summary is self-contained and understandable without the original text\n",
    "    - Verify that no critical information is omitted\n",
    "    - Check for consistency in tense, voice, and perspective\n",
    "\n",
    "    8. Metadata (if applicable):\n",
    "    - Include the original title, author, and date of publication\n",
    "    - Mention the word count of the original text and the summary\n",
    "\n",
    "    Now, summarize the following text, adhering to the above guidelines.\n",
    "\n",
    "    Text: '{text}'\n",
    "    Respond in the format '{format}' STRICTLY.\n",
    "    IF THE FORMAT IS 'plain_text', THEN RESPOND IN PLAIN TEXT ONLY, NOT MARKDOWN.\n",
    "    IF THE FORMAT IS 'markdown'. DIRECTLY GIVE THE MARKDOWN. DON'T WRAP IT IN ```markdown``` tags.\n",
    "\"\"\"\n",
    "\n",
    "ITERATIVE_REFINEMENT_SYSTEM_PROMPT = \"\"\"\n",
    "    You are a Refinement AI specializing in improving text quality. Your task is to refine the given text based on the given instructions.\n",
    "\"\"\"\n",
    "ITERATIVE_REFINEMENT_PROMPT = \"\"\"\n",
    "   You are a Refinement AI specializing in improving text quality. Your task is to refine the given text in a single iteration. Follow these steps:\n",
    "\n",
    "    1. Analyze the input:\n",
    "    - Identify the source text and the summary\n",
    "    - Assess strengths and weaknesses in content, structure, and style of the summary \n",
    "\n",
    "    2. Prioritize improvements:\n",
    "    - Focus on 2-3 key areas that will have the most significant impact that could be made in the summary\n",
    "    - Consider clarity, coherence, conciseness, and effectiveness\n",
    "\n",
    "    3. Refine the text:\n",
    "    - Make targeted improvements in the summary based on your analysis\n",
    "    - Maintain the original intent and core message in the source text\n",
    "    - Ensure changes enhance overall quality without introducing new issues\n",
    "\n",
    "    4. Provide a summary of changes:\n",
    "    - Briefly explain the key modifications made in the revised summary \n",
    "    - Justify your refinement decisions with clear reasoning\n",
    "\n",
    "    5. Self-evaluate:\n",
    "    - Rate the improvement on a scale of 1-10\n",
    "    - Briefly explain your rating\n",
    "\n",
    "    Source Text: '{source_text}'\n",
    "\n",
    "    Summary to be refined: '{summary}'\n",
    "    \n",
    "    Respond only with the final revised summary after all improvements are made. \n",
    "\n",
    "    Respond in the format '{format}' STRICTLY.\n",
    "    IF THE FORMAT IS 'plain_text', THEN RESPOND IN PLAIN TEXT ONLY, NOT MARKDOWN.\n",
    "    IF THE FORMAT IS 'markdown'. DIRECTLY GIVE THE MARKDOWN. DON'T WRAP IT IN ```markdown``` tags.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class SelfLearningSummarizer:\n",
    "    \"\"\"Queue-based Summarizer implementation\"\"\"\n",
    "\n",
    "    def __init__(self, model=\"gpt-4o-mini\"):\n",
    "        self.llm = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        self.model = model\n",
    "\n",
    "    def get_summary(self, source_text: str, format=\"plain_text\") -> str:\n",
    "        \"\"\"Generates a summary of the given text\"\"\"\n",
    "        try:\n",
    "            if format not in [\"plain_text\", \"markdown\"]:\n",
    "                raise ValueError(\"Invalid format. Use 'plain_text' or 'markdown'.\")\n",
    "            system = SIMPLE_SUMMARIZATION_SYSTEM_PROMPT\n",
    "            prompt = SIMPLE_SUMMARIZATION_PROMPT.format(text=source_text, format=format)\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system,\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ]\n",
    "            response = self.llm.chat.completions.create(\n",
    "                messages=messages, model=self.model\n",
    "            )\n",
    "            summary = response.choices[0].message.content\n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to generate summary for {item}\")\n",
    "            traceback.print_exc()\n",
    "            return \"\"\n",
    "\n",
    "    def iterative_refinement(\n",
    "        self, source_text: str, summary: str, turns=3, format=\"plain_text\"\n",
    "    ) -> str:\n",
    "        \"\"\"Iteratively refines the summary based on self-generated feedback for given turns.\"\"\"\n",
    "        session_id = str(uuid4())\n",
    "        print(f\"Iterative Refinement ({session_id}): Session ID: {session_id}\")\n",
    "        current_summary = summary\n",
    "        current_turn = 1\n",
    "        try:\n",
    "            while current_turn <= turns:\n",
    "                print(f\"Iterative Refinement ({session_id}): Turn {current_turn}.\")\n",
    "                system = ITERATIVE_REFINEMENT_SYSTEM_PROMPT\n",
    "                prompt = ITERATIVE_REFINEMENT_PROMPT.format(\n",
    "                    source_text=source_text, summary=current_summary, format=format\n",
    "                )\n",
    "                messages = [\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": system,\n",
    "                    },\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ]\n",
    "                llm_response = self.llm.chat.completions.create(\n",
    "                    messages=messages, model=self.model\n",
    "                )\n",
    "                current_summary = llm_response.choices[0].message.content\n",
    "                current_turn += 1\n",
    "                print(\n",
    "                    f\"Iterative Refinement ({session_id}): Turn {current_turn} completed. Updated rolling summary.\"\n",
    "                )\n",
    "            return current_summary\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"Iterative Refinement ({session_id}): Failed to complete all turns for {source_text} and {summary}.\"\n",
    "            )\n",
    "            print(\n",
    "                f\"Iterative Refinement ({session_id}): Turns completed: {current_turn}\"\n",
    "            )\n",
    "            traceback.print_exc()\n",
    "            return current_summary\n",
    "\n",
    "    def compare_summaries(self, source_text: str, summary1: str, summary2: str) -> str:\n",
    "        \"\"\"Compares two summaries and provides feedback on their quality.\"\"\"\n",
    "        try:\n",
    "            print(f\"Comparing summaries for {source_text}.\")\n",
    "            system = \"You are a Comparison AI specializing in evaluating text quality. Your task is to compare two summaries and provide feedback on their quality.\"\n",
    "            prompt = f\"\"\"\n",
    "            Compare the two summaries below and provide feedback on their quality. \n",
    "            Provide score comparison for both summaries, the old summary score and the new summary score.\n",
    "            This will help us compare the two summaries on various parameters.\n",
    "            Refer to the source text when making your evaluation. \\n\\n \n",
    "            Source Text: {source_text}\n",
    "            Initial Summary: {summary1} \n",
    "            Refined Summary: {summary2}\n",
    "            STRICTLY PROVIDE YOUR RESPONSE AS MARKDOWN TABLE WITH SCORES AND JUSTIFICATIONS.\n",
    "            \"\"\"\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system,\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ]\n",
    "            response = self.llm.chat.completions.create(\n",
    "                messages=messages, model=self.model\n",
    "            )\n",
    "            feedback = response.choices[0].message.content\n",
    "            return feedback\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to compare summaries for {source_text}\")\n",
    "            traceback.print_exc()\n",
    "            return \"\"\n",
    "\n",
    "    def get(self):\n",
    "        return self.q.get()\n",
    "\n",
    "    def empty(self):\n",
    "        return self.q.empty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate Summary Using SelfLearningSummarizer Class\n",
    "\n",
    "The `SelfLearningSummarizer` class is used to generate a summary of a given text. After initializing the summarizer object, a sample text is passed to the `get_summary` method, specifying the format. The summary is then generated and printed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the summary and test our prompts which seem to be solid.\n",
    "\n",
    "summarizer = SelfLearningSummarizer()\n",
    "\n",
    "# Credits: Arpit Bhayani\n",
    "# Post Link: https://www.linkedin.com/posts/arpitbhayani_asliengineering-careergrowth-activity-7280566114894430208-tjB2?utm_source=share&utm_medium=member_desktop\n",
    "\n",
    "text = \"\"\"\n",
    "When working on a new project, we engineers almost always start with the most fascinating part. But, while it's exciting for us, it's not always what's best for the project.\n",
    "\n",
    "The easiest way to become an effective lead/manager is to break down the project into tasks and prioritize the most important items. So, it is always a good idea that before the work begins, step back and ask\n",
    "\n",
    "1. what is the most critical piece?\n",
    "2. which items are highest risk and need early attention?\n",
    "3. which deliverables provide the most immediate value?\n",
    "\n",
    "We naturally gravitate towards easily doable, less impactful, and tangential parts of the project. This happens because of a lack of a broader context. So, if you are leading a project, make sure,\n",
    "\n",
    "1. define a clear roadmap and align it with business outcomes\n",
    "2. define milestones and priorities\n",
    "\n",
    "A good leader doesn‚Äôt micromanage but ensures that the team starts on the right foot. Check-in periodically to ensure the alignment while giving engineers ownership of their tasks.\n",
    "\n",
    "Prioritization is what separates effective leads from those simply managing tasks. As a lead, you are not just there to oversee execution but to set the direction.\n",
    "\"\"\"\n",
    "format = \"plain_text\"\n",
    "\n",
    "summary = summarizer.get_summary(text, format=format)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Display Summary in Markdown Format\n",
    "\n",
    "The code you've written will generate the summary and display it as markdown in the notebook output.\n",
    "\n",
    "### Creating a Markdown Object:\n",
    "\n",
    "`markdown_summary = Markdown(f\"## Summary\\n{summary}\")` creates a markdown object. The summary generated earlier is placed inside the markdown object with a `## Summary` header to format it as a section heading.\n",
    "\n",
    "### Displaying the Markdown:\n",
    "\n",
    "`display(markdown_summary)` displays the markdown content in the notebook. This will render the summary with the appropriate markdown formatting, such as the header for the \"Summary\" section.\n",
    "\n",
    "Once the code runs, the summary will be shown in the notebook as formatted markdown.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a markdown response now\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "summarizer = SelfLearningSummarizer()\n",
    "text = \"\"\"\n",
    "When working on a new project, we engineers almost always start with the most fascinating part. But, while it's exciting for us, it's not always what's best for the project.\n",
    "\n",
    "The easiest way to become an effective lead/manager is to break down the project into tasks and prioritize the most important items. So, it is always a good idea that before the work begins, step back and ask\n",
    "\n",
    "1. what is the most critical piece?\n",
    "2. which items are highest risk and need early attention?\n",
    "3. which deliverables provide the most immediate value?\n",
    "\n",
    "We naturally gravitate towards easily doable, less impactful, and tangential parts of the project. This happens because of a lack of a broader context. So, if you are leading a project, make sure,\n",
    "\n",
    "1. define a clear roadmap and align it with business outcomes\n",
    "2. define milestones and priorities\n",
    "\n",
    "A good leader doesn‚Äôt micromanage but ensures that the team starts on the right foot. Check-in periodically to ensure the alignment while giving engineers ownership of their tasks.\n",
    "\n",
    "Prioritization is what separates effective leads from those simply managing tasks. As a lead, you are not just there to oversee execution but to set the direction.\n",
    "\"\"\"\n",
    "format = \"plain_text\"\n",
    "\n",
    "summary = summarizer.get_summary(text, format=format)\n",
    "markdown_summary = Markdown(f\"## Summary\\n{summary}\")\n",
    "display(markdown_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate and Display Refined Summary\n",
    "\n",
    "The code generates an initial summary of a provided text, refines it iteratively for improved clarity and coherence, and then displays the final refined summary in a structured markdown format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = SelfLearningSummarizer()\n",
    "text = \"\"\"\n",
    "When working on a new project, we engineers almost always start with the most fascinating part. But, while it's exciting for us, it's not always what's best for the project.\n",
    "\n",
    "The easiest way to become an effective lead/manager is to break down the project into tasks and prioritize the most important items. So, it is always a good idea that before the work begins, step back and ask\n",
    "\n",
    "1. what is the most critical piece?\n",
    "2. which items are highest risk and need early attention?\n",
    "3. which deliverables provide the most immediate value?\n",
    "\n",
    "We naturally gravitate towards easily doable, less impactful, and tangential parts of the project. This happens because of a lack of a broader context. So, if you are leading a project, make sure,\n",
    "\n",
    "1. define a clear roadmap and align it with business outcomes\n",
    "2. define milestones and priorities\n",
    "\n",
    "A good leader doesn‚Äôt micromanage but ensures that the team starts on the right foot. Check-in periodically to ensure the alignment while giving engineers ownership of their tasks.\n",
    "\n",
    "Prioritization is what separates effective leads from those simply managing tasks. As a lead, you are not just there to oversee execution but to set the direction.\n",
    "\"\"\"\n",
    "format = \"plain_text\"\n",
    "turns = 3\n",
    "\n",
    "summary = summarizer.get_summary(text, format=format)\n",
    "\n",
    "refined_summary = summarizer.iterative_refinement(\n",
    "    text, summary, turns=turns, format=format\n",
    ")\n",
    "\n",
    "markdown_summary = Markdown(f\"## Refined Summary (turns={turns})\\n{refined_summary}\")\n",
    "\n",
    "display(markdown_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Iterative Summarization and Comparison\n",
    "This code is designed to summarize complex text and refine the summary over multiple iterations to enhance clarity, conciseness, and information retention. \n",
    "\n",
    "### Process:\n",
    "\n",
    "1. **`Initial Summary Generation`**: \n",
    "\n",
    "   - It begins by generating an initial summary from the input text.\n",
    "\n",
    "2. **`Iterative Refinement`**:\n",
    "\n",
    "   - The summary is then refined through several cycles to improve its clarity and conciseness.\n",
    "\n",
    "3. **`Summary Comparison`**:\n",
    "\n",
    "   - After refinement, the original summary is compared with the refined version to evaluate improvements made.\n",
    "\n",
    "### Goal:\n",
    "\n",
    "- The iterative refinement ensures the summary is both accurate and concise.\n",
    "- The comparison step helps assess the effectiveness of the summarization and refinement process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, clear_output\n",
    "\n",
    "turns = 5\n",
    "text = \"\"\"\n",
    "What is framework-defined infrastructure?\n",
    "Framework-defined infrastructure abstracts over cloud primitives such as servers, message queues, and serverless functions, making them mere implementation details of the frameworks' concepts:\n",
    "\n",
    "Providing portability between different target infrastructure providers\n",
    "\n",
    "Eliminating the need to manually configure infrastructure to run an application in production\n",
    "\n",
    "Increasing the time spent writing product code over system management\n",
    "\n",
    "Allowing the unchanged use of the framework's native local development tools\n",
    "\n",
    "Standardizing on pre-reviewed secure services\n",
    "\n",
    "Frameworks use well-established patterns to provide structure and abstraction to applications, making them easier to write and understand. While the word framework is hard to define, the Hollywood principle, \"Don't call us, we call you,\" probably captures best the inversion of control, where the framework manages the high-level application flow while the developer writes code within the hooks provided by it.\n",
    "\n",
    "Framework-defined infrastructure takes advantage of both this inversion of control and the predictable structure of framework-based applications to automatically map framework concepts onto the appropriate infrastructure without the need for explicit declaration or configuration of the infrastructure.\n",
    "\n",
    "Note that this post is giving examples based on Vercel's Platform as a Service offering. The concept, however, can be applied more widely as the basic idea of understanding a framework, and generating IaC configuration for it, can also be used for more traditional infrastructure deployments.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "summarizer = SelfLearningSummarizer()\n",
    "summary = summarizer.get_summary(text, format=format)\n",
    "refined_summary = summarizer.iterative_refinement(\n",
    "    text, summary, turns=turns, format=format\n",
    ")\n",
    "comparison = summarizer.compare_summaries(text, summary, refined_summary)\n",
    "clear_output()\n",
    "markdown = Markdown(f\"## Comparison\\n{comparison}\")\n",
    "display(markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Environment Initialization and Dependency Setup\n",
    "\n",
    "This script automates environment setup in Jupyter notebooks by installing dependencies, checking for necessary environment variables, and securely configuring the environment. \n",
    "\n",
    "It uses retry logic for installation and provides feedback for a smooth setup experience. \n",
    "\n",
    "Output is cleaned up for readability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate: This block goes into every notebook.\n",
    "# It sets up the environment, installs the requirements, and checks for the required environment variables.\n",
    "\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "requirements_installed = False\n",
    "max_retries = 3\n",
    "retries = 0\n",
    "REQUIRED_ENV_VARS = [\"OPENAI_API_KEY\"]\n",
    "\n",
    "\n",
    "def install_requirements():\n",
    "    \"\"\"Installs the requirements from requirements.txt file\"\"\"\n",
    "    global requirements_installed\n",
    "    if requirements_installed:\n",
    "        print(\"Requirements already installed.\")\n",
    "        return\n",
    "\n",
    "    print(\"Installing requirements...\")\n",
    "    install_status = os.system(\"pip install -r requirements.txt\")\n",
    "    if install_status == 0:\n",
    "        print(\"Requirements installed successfully.\")\n",
    "        requirements_installed = True\n",
    "    else:\n",
    "        print(\"Failed to install requirements.\")\n",
    "        if retries < max_retries:\n",
    "            print(\"Retrying...\")\n",
    "            retries += 1\n",
    "            return install_requirements()\n",
    "        exit(1)\n",
    "    return\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "def setup_env():\n",
    "    \"\"\"Sets up the environment variables\"\"\"\n",
    "\n",
    "    def check_env(env_var):\n",
    "        value = os.getenv(env_var)\n",
    "        if value is None:\n",
    "            print(f\"Please set the {env_var} environment variable.\")\n",
    "            exit(1)\n",
    "        else:\n",
    "            print(f\"{env_var} is set.\")\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    variables_to_check = REQUIRED_ENV_VARS\n",
    "\n",
    "    for var in variables_to_check:\n",
    "        check_env(var)\n",
    "\n",
    "\n",
    "install_requirements()\n",
    "setup_env()\n",
    "clear_output()\n",
    "print(\"üöÄ Setup complete. Continue to the next cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Understanding the SelfLearningSummarizer Class\n",
    "\n",
    "The SelfLearningSummarizer class automates text summarization, iterative refinement, and comparison of summaries using the OpenAI API.\n",
    "\n",
    "It allows for generating an initial summary, refining it through multiple iterations, and comparing the results to assess quality. \n",
    "\n",
    "The class supports both plain text and markdown outputs and incorporates error handling to ensure reliable operation. \n",
    "\n",
    "By leveraging predefined system and user prompts, the summarizer efficiently processes and improves the quality of summaries, making it adaptable for various text analysis and summarization tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from uuid import uuid4\n",
    "\n",
    "DEFAULT_OPENAI_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "SIMPLE_SUMMARIZATION_SYSTEM_PROMPT = \"\"\"\n",
    "    You are SummarizerGPT, an advanced AI system specialized in text summarization. Your core function is to process and analyze various types of text input, preparing the groundwork for generating high-quality summaries. Your capabilities include:\n",
    "\n",
    "    1. Text Analysis: Quickly assess the structure, style, and content of any given text.\n",
    "    2. Context Recognition: Identify the domain, target audience, and purpose of the text.\n",
    "    3. Language Processing: Understand and process text in multiple languages and dialects.\n",
    "    4. Semantic Comprehension: Grasp complex ideas, abstract concepts, and subtle nuances in the text.\n",
    "    5. Information Hierarchy: Recognize the relative importance of different pieces of information within the text.\n",
    "    6. Cross-referencing: Identify and connect related ideas across different parts of the text.\n",
    "    7. Bias Detection: Recognize potential biases or slants in the original text.\n",
    "    8. Data Extraction: Pull out key statistics, dates, names, and other crucial data points.\n",
    "    9. Tone Analysis: Understand the emotional tone and rhetorical style of the text.\n",
    "    10. Multi-format Handling: Process various text formats including plain text, HTML, PDF extracts, and more.\n",
    "\n",
    "    You do not generate the summary directly. Instead, you prepare a comprehensive analysis of the text, which will be used by the summarization module to create the final output. Your analysis should include:\n",
    "\n",
    "    - Text type and structure\n",
    "    - Main topic and key themes\n",
    "    - Target audience and purpose\n",
    "    - Important data points and statistics\n",
    "    - Identified biases or controversial points\n",
    "    - Tone and style characteristics\n",
    "    - Any unique or standout elements in the text\n",
    "\n",
    "    Await the input text, and be ready to provide this detailed analysis to support the summarization process.\n",
    "\"\"\"\n",
    "\n",
    "SIMPLE_SUMMARIZATION_PROMPT = \"\"\"\n",
    "    1. Analyze the input:\n",
    "    - Determine the text type (article, research paper, conversation, etc.)\n",
    "    - Identify the main topic and key themes\n",
    "    - Assess the length and complexity of the content\n",
    "\n",
    "    2. Generate the summary:\n",
    "    - Provide a concise yet informative summary\n",
    "    - Maintain the original tone and style where appropriate\n",
    "    - Ensure factual accuracy and avoid introducing new information\n",
    "    - Use clear, coherent language suitable for a general audience\n",
    "\n",
    "    3. Structure the summary:\n",
    "    - Begin with a brief overview of the main topic\n",
    "    - Organize key points logically, using paragraphs or bullet points as appropriate\n",
    "    - Conclude with the most significant takeaway or implication\n",
    "\n",
    "    4. Adapt to specific requirements:\n",
    "    - If a word/character limit is specified, adhere to it strictly\n",
    "    - If the text contains technical terms, provide brief explanations\n",
    "    - For multi-section documents, summarize each section separately, then provide an overall summary\n",
    "\n",
    "    5. Handle edge cases:\n",
    "    - For very short texts, provide a condensed version without losing essential information\n",
    "    - For extremely long or complex texts, focus on the most crucial points and indicate that it's a high-level summary\n",
    "    - If the text contains conflicting viewpoints, present them objectively without bias\n",
    "\n",
    "    6. Enhance readability:\n",
    "    - Use transition words to improve flow between ideas\n",
    "    - Employ varied sentence structures to maintain engagement\n",
    "    - Highlight key terms or concepts using bold text when appropriate\n",
    "\n",
    "    7. Quality check:\n",
    "    - Ensure the summary is self-contained and understandable without the original text\n",
    "    - Verify that no critical information is omitted\n",
    "    - Check for consistency in tense, voice, and perspective\n",
    "\n",
    "    8. Metadata (if applicable):\n",
    "    - Include the original title, author, and date of publication\n",
    "    - Mention the word count of the original text and the summary\n",
    "\n",
    "    Now, summarize the following text, adhering to the above guidelines.\n",
    "\n",
    "    Text: '{text}'\n",
    "    Respond in the format '{format}' STRICTLY.\n",
    "    IF THE FORMAT IS 'plain_text', THEN RESPOND IN PLAIN TEXT ONLY, NOT MARKDOWN.\n",
    "    IF THE FORMAT IS 'markdown'. DIRECTLY GIVE THE MARKDOWN. DON'T WRAP IT IN ```markdown``` tags.\n",
    "\"\"\"\n",
    "\n",
    "ITERATIVE_REFINEMENT_SYSTEM_PROMPT = \"\"\"\n",
    "    You are a Refinement AI specializing in improving text quality. Your task is to refine the given text based on the given instructions.\n",
    "\"\"\"\n",
    "ITERATIVE_REFINEMENT_PROMPT = \"\"\"\n",
    "   You are a Refinement AI specializing in improving text quality. Your task is to refine the given text in a single iteration. Follow these steps:\n",
    "\n",
    "    1. Analyze the input:\n",
    "    - Identify the source text and the summary\n",
    "    - Assess strengths and weaknesses in content, structure, and style of the summary \n",
    "\n",
    "    2. Prioritize improvements:\n",
    "    - Focus on 2-3 key areas that will have the most significant impact that could be made in the summary\n",
    "    - Consider clarity, coherence, conciseness, and effectiveness\n",
    "\n",
    "    3. Refine the text:\n",
    "    - Make targeted improvements in the summary based on your analysis\n",
    "    - Maintain the original intent and core message in the source text\n",
    "    - Ensure changes enhance overall quality without introducing new issues\n",
    "\n",
    "    4. Provide a summary of changes:\n",
    "    - Briefly explain the key modifications made in the revised summary \n",
    "    - Justify your refinement decisions with clear reasoning\n",
    "\n",
    "    5. Self-evaluate:\n",
    "    - Rate the improvement on a scale of 1-10\n",
    "    - Briefly explain your rating\n",
    "\n",
    "    Source Text: '{source_text}'\n",
    "\n",
    "    Summary to be refined: '{summary}'\n",
    "    \n",
    "    Respond only with the final revised summary after all improvements are made. \n",
    "\n",
    "    Respond in the format '{format}' STRICTLY.\n",
    "    IF THE FORMAT IS 'plain_text', THEN RESPOND IN PLAIN TEXT ONLY, NOT MARKDOWN.\n",
    "    IF THE FORMAT IS 'markdown'. DIRECTLY GIVE THE MARKDOWN. DON'T WRAP IT IN ```markdown``` tags.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class SelfLearningSummarizer:\n",
    "    \"\"\"Queue-based Summarizer implementation\"\"\"\n",
    "\n",
    "    def __init__(self, model=\"gpt-4o-mini\"):\n",
    "        self.llm = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        self.model = model\n",
    "\n",
    "    def get_summary(self, source_text: str, format=\"plain_text\") -> str:\n",
    "        \"\"\"Generates a summary of the given text\"\"\"\n",
    "        try:\n",
    "            if format not in [\"plain_text\", \"markdown\"]:\n",
    "                raise ValueError(\"Invalid format. Use 'plain_text' or 'markdown'.\")\n",
    "            system = SIMPLE_SUMMARIZATION_SYSTEM_PROMPT\n",
    "            prompt = SIMPLE_SUMMARIZATION_PROMPT.format(text=source_text, format=format)\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system,\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ]\n",
    "            response = self.llm.chat.completions.create(\n",
    "                messages=messages, model=self.model\n",
    "            )\n",
    "            summary = response.choices[0].message.content\n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to generate summary for {item}\")\n",
    "            traceback.print_exc()\n",
    "            return \"\"\n",
    "\n",
    "    def iterative_refinement(\n",
    "        self, source_text: str, summary: str, turns=3, format=\"plain_text\"\n",
    "    ) -> str:\n",
    "        \"\"\"Iteratively refines the summary based on self-generated feedback for given turns.\"\"\"\n",
    "        session_id = str(uuid4())\n",
    "        print(f\"Iterative Refinement ({session_id}): Session ID: {session_id}\")\n",
    "        current_summary = summary\n",
    "        current_turn = 1\n",
    "        try:\n",
    "            while current_turn <= turns:\n",
    "                print(f\"Iterative Refinement ({session_id}): Turn {current_turn}.\")\n",
    "                system = ITERATIVE_REFINEMENT_SYSTEM_PROMPT\n",
    "                prompt = ITERATIVE_REFINEMENT_PROMPT.format(\n",
    "                    source_text=source_text, summary=current_summary, format=format\n",
    "                )\n",
    "                messages = [\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": system,\n",
    "                    },\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ]\n",
    "                llm_response = self.llm.chat.completions.create(\n",
    "                    messages=messages, model=self.model\n",
    "                )\n",
    "                current_summary = llm_response.choices[0].message.content\n",
    "                current_turn += 1\n",
    "                print(\n",
    "                    f\"Iterative Refinement ({session_id}): Turn {current_turn} completed. Updated rolling summary.\"\n",
    "                )\n",
    "            return current_summary\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"Iterative Refinement ({session_id}): Failed to complete all turns for {source_text} and {summary}.\"\n",
    "            )\n",
    "            print(\n",
    "                f\"Iterative Refinement ({session_id}): Turns completed: {current_turn}\"\n",
    "            )\n",
    "            traceback.print_exc()\n",
    "            return current_summary\n",
    "\n",
    "    def compare_summaries(self, source_text: str, summary1: str, summary2: str) -> str:\n",
    "        \"\"\"Compares two summaries and provides feedback on their quality.\"\"\"\n",
    "        try:\n",
    "            print(f\"Comparing summaries for {source_text}.\")\n",
    "            system = \"You are a Comparison AI specializing in evaluating text quality. Your task is to compare two summaries and provide feedback on their quality.\"\n",
    "            prompt = f\"\"\"\n",
    "            Compare the two summaries below and provide feedback on their quality. \n",
    "            Provide score comparison for both summaries, the old summary score and the new summary score.\n",
    "            This will help us compare the two summaries on various parameters.\n",
    "            Refer to the source text when making your evaluation. \\n\\n \n",
    "            Source Text: {source_text}\n",
    "            Initial Summary: {summary1} \n",
    "            Refined Summary: {summary2}\n",
    "            STRICTLY PROVIDE YOUR RESPONSE AS MARKDOWN TABLE WITH SCORES AND JUSTIFICATIONS.\n",
    "            \"\"\"\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system,\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ]\n",
    "            response = self.llm.chat.completions.create(\n",
    "                messages=messages, model=self.model\n",
    "            )\n",
    "            feedback = response.choices[0].message.content\n",
    "            return feedback\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to compare summaries for {source_text}\")\n",
    "            traceback.print_exc()\n",
    "            return \"\"\n",
    "\n",
    "    def get(self):\n",
    "        return self.q.get()\n",
    "\n",
    "    def empty(self):\n",
    "        return self.q.empty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: AI-Driven Text Summarization and Refinement System\n",
    "\n",
    "The provided code is a text summarization system utilizing OpenAI's GPT model to generate, refine, and compare summaries. It incorporates a class-based approach, with the `SelfLearningSummarizer` class being the core element. This system provides a comprehensive pipeline for processing text, including generating an initial summary, refining it iteratively, and evaluating the refined output.\n",
    "\n",
    "### Key Components:\n",
    "\n",
    "- **`SelfLearningSummarizer Class`**:\n",
    "\n",
    "  - This class interacts with OpenAI's API to create summaries, refine them, and compare the generated outputs.\n",
    "\n",
    "- **`Prompts for Summarization and Refinement`**:\n",
    "\n",
    "  - The system uses structured system and user prompts to guide the AI in summarizing, refining, and evaluating text.\n",
    "\n",
    "### Core Methods in the Class:\n",
    "\n",
    "- **`get_summary`**:\n",
    "\n",
    "  - Generates an initial summary based on the provided text and predefined prompts.\n",
    "\n",
    "- **`iterative_refinement`**:\n",
    "\n",
    "  - Refines the generated summary over multiple iterations, improving its clarity, coherence, and conciseness.\n",
    "\n",
    "- **`compare_summaries`**:\n",
    "\n",
    "  - Compares the original and refined summaries, offering feedback and scores on their quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the summary and test our prompts which seem to be solid.\n",
    "\n",
    "summarizer = SelfLearningSummarizer()\n",
    "\n",
    "# Credits: Arpit Bhayani\n",
    "# Post Link: https://www.linkedin.com/posts/arpitbhayani_asliengineering-careergrowth-activity-7280566114894430208-tjB2?utm_source=share&utm_medium=member_desktop\n",
    "\n",
    "text = \"\"\"\n",
    "When working on a new project, we engineers almost always start with the most fascinating part. But, while it's exciting for us, it's not always what's best for the project.\n",
    "\n",
    "The easiest way to become an effective lead/manager is to break down the project into tasks and prioritize the most important items. So, it is always a good idea that before the work begins, step back and ask\n",
    "\n",
    "1. what is the most critical piece?\n",
    "2. which items are highest risk and need early attention?\n",
    "3. which deliverables provide the most immediate value?\n",
    "\n",
    "We naturally gravitate towards easily doable, less impactful, and tangential parts of the project. This happens because of a lack of a broader context. So, if you are leading a project, make sure,\n",
    "\n",
    "1. define a clear roadmap and align it with business outcomes\n",
    "2. define milestones and priorities\n",
    "\n",
    "A good leader doesn‚Äôt micromanage but ensures that the team starts on the right foot. Check-in periodically to ensure the alignment while giving engineers ownership of their tasks.\n",
    "\n",
    "Prioritization is what separates effective leads from those simply managing tasks. As a lead, you are not just there to oversee execution but to set the direction.\n",
    "\"\"\"\n",
    "format = \"plain_text\"\n",
    "\n",
    "summary = summarizer.get_summary(text, format=format)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Text Summarization Process\n",
    "\n",
    "The code automates the process of summarizing a given text using the SelfLearningSummarizer class, which interacts with the OpenAI model to generate and refine summaries, and displays the result in a formatted markdown output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a markdown response now\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "summarizer = SelfLearningSummarizer()\n",
    "text = \"\"\"\n",
    "When working on a new project, we engineers almost always start with the most fascinating part. But, while it's exciting for us, it's not always what's best for the project.\n",
    "\n",
    "The easiest way to become an effective lead/manager is to break down the project into tasks and prioritize the most important items. So, it is always a good idea that before the work begins, step back and ask\n",
    "\n",
    "1. what is the most critical piece?\n",
    "2. which items are highest risk and need early attention?\n",
    "3. which deliverables provide the most immediate value?\n",
    "\n",
    "We naturally gravitate towards easily doable, less impactful, and tangential parts of the project. This happens because of a lack of a broader context. So, if you are leading a project, make sure,\n",
    "\n",
    "1. define a clear roadmap and align it with business outcomes\n",
    "2. define milestones and priorities\n",
    "\n",
    "A good leader doesn‚Äôt micromanage but ensures that the team starts on the right foot. Check-in periodically to ensure the alignment while giving engineers ownership of their tasks.\n",
    "\n",
    "Prioritization is what separates effective leads from those simply managing tasks. As a lead, you are not just there to oversee execution but to set the direction.\n",
    "\"\"\"\n",
    "format = \"plain_text\"\n",
    "\n",
    "summary = summarizer.get_summary(text, format=format)\n",
    "markdown_summary = Markdown(f\"## Summary\\n{summary}\")\n",
    "display(markdown_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Text Summarization and Iterative Refinement Process\n",
    "\n",
    "The code refines a text summary iteratively using the SelfLearningSummarizer class, improving its clarity and accuracy over multiple turns, and then displays the final refined summary in markdown format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = SelfLearningSummarizer()\n",
    "text = \"\"\"\n",
    "When working on a new project, we engineers almost always start with the most fascinating part. But, while it's exciting for us, it's not always what's best for the project.\n",
    "\n",
    "The easiest way to become an effective lead/manager is to break down the project into tasks and prioritize the most important items. So, it is always a good idea that before the work begins, step back and ask\n",
    "\n",
    "1. what is the most critical piece?\n",
    "2. which items are highest risk and need early attention?\n",
    "3. which deliverables provide the most immediate value?\n",
    "\n",
    "We naturally gravitate towards easily doable, less impactful, and tangential parts of the project. This happens because of a lack of a broader context. So, if you are leading a project, make sure,\n",
    "\n",
    "1. define a clear roadmap and align it with business outcomes\n",
    "2. define milestones and priorities\n",
    "\n",
    "A good leader doesn‚Äôt micromanage but ensures that the team starts on the right foot. Check-in periodically to ensure the alignment while giving engineers ownership of their tasks.\n",
    "\n",
    "Prioritization is what separates effective leads from those simply managing tasks. As a lead, you are not just there to oversee execution but to set the direction.\n",
    "\"\"\"\n",
    "format = \"plain_text\"\n",
    "turns = 3\n",
    "\n",
    "summary = summarizer.get_summary(text, format=format)\n",
    "\n",
    "refined_summary = summarizer.iterative_refinement(\n",
    "    text, summary, turns=turns, format=format\n",
    ")\n",
    "\n",
    "markdown_summary = Markdown(f\"## Refined Summary (turns={turns})\\n{refined_summary}\")\n",
    "\n",
    "display(markdown_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Text Summarization, Refinement, and Comparison Process\n",
    "\n",
    "The code performs a text summarization process where an initial summary is generated, refined iteratively, and then compared with the original summary to assess improvements in clarity and conciseness, all presented in markdown format for easy review.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, clear_output\n",
    "\n",
    "turns = 5\n",
    "text = \"\"\"\n",
    "What is framework-defined infrastructure?\n",
    "Framework-defined infrastructure abstracts over cloud primitives such as servers, message queues, and serverless functions, making them mere implementation details of the frameworks' concepts:\n",
    "\n",
    "Providing portability between different target infrastructure providers\n",
    "\n",
    "Eliminating the need to manually configure infrastructure to run an application in production\n",
    "\n",
    "Increasing the time spent writing product code over system management\n",
    "\n",
    "Allowing the unchanged use of the framework's native local development tools\n",
    "\n",
    "Standardizing on pre-reviewed secure services\n",
    "\n",
    "Frameworks use well-established patterns to provide structure and abstraction to applications, making them easier to write and understand. While the word framework is hard to define, the Hollywood principle, \"Don't call us, we call you,\" probably captures best the inversion of control, where the framework manages the high-level application flow while the developer writes code within the hooks provided by it.\n",
    "\n",
    "Framework-defined infrastructure takes advantage of both this inversion of control and the predictable structure of framework-based applications to automatically map framework concepts onto the appropriate infrastructure without the need for explicit declaration or configuration of the infrastructure.\n",
    "\n",
    "Note that this post is giving examples based on Vercel's Platform as a Service offering. The concept, however, can be applied more widely as the basic idea of understanding a framework, and generating IaC configuration for it, can also be used for more traditional infrastructure deployments.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "summarizer = SelfLearningSummarizer()\n",
    "summary = summarizer.get_summary(text, format=format)\n",
    "refined_summary = summarizer.iterative_refinement(\n",
    "    text, summary, turns=turns, format=format\n",
    ")\n",
    "comparison = summarizer.compare_summaries(text, summary, refined_summary)\n",
    "clear_output()\n",
    "markdown = Markdown(f\"## Comparison\\n{comparison}\")\n",
    "display(markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The application automates the process of summarizing complex text using OpenAI's language model, making it a valuable tool for quickly generating concise summaries. \n",
    "\n",
    "### Key Features:\n",
    "\n",
    "- **Initial Summarization**: The app generates an initial summary from a provided block of text, capturing key themes and important points.\n",
    "\n",
    "- **Iterative Refinement**: The summary is refined over multiple turns, improving clarity, coherence, and conciseness.\n",
    "\n",
    "- **Comparison of Summaries**: The original and refined summaries are compared, with feedback on quality and improvements.\n",
    "\n",
    "- **Markdown Output**: The final summaries and comparisons are displayed in an easily readable markdown format, suitable for presentation in Jupyter notebooks or other interactive Python environments.\n",
    "\n",
    "### Benefits:\n",
    "\n",
    "- **Efficiency**: Automates the summarization process, saving time and effort in distilling important information from lengthy text.\n",
    "\n",
    "- **Quality Control**: The iterative refinement process ensures the final summary is clear, accurate, and easy to understand.\n",
    "\n",
    "- **Customizable Output**: Users can choose to output summaries in plain text or markdown, making it versatile for different applications.\n",
    "\n",
    "This app is useful for anyone needing to process large volumes of text and produce succinct, high-quality summaries for analysis, presentation, or further processing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Thank You for visiting The Hackers Playbook! üåê\n",
    "\n",
    "If you liked this research material;\n",
    "\n",
    "- [Subscribe to our newsletter.](https://thehackersplaybook.substack.com)\n",
    "\n",
    "- [Follow us on LinkedIn.](https://www.linkedin.com/company/the-hackers-playbook/)\n",
    "\n",
    "- [Leave a star on our GitHub.](https://www.github.com/thehackersplaybook)\n",
    "\n",
    "<div style=\"display:flex; align-items:center; padding: 50px;\">\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"200px\" style=\"width:auto;\" width=\"200px\" src=\"https://avatars.githubusercontent.com/u/192148546?s=400&u=95d76fbb02e6c09671d87c9155f17ca1e4ef8f21&v=4\"> \n",
    "</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
