{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-learning Text Summarization üê¨\n",
    "\n",
    "##### üí° **Research Areas:** Rapid Prototyping, Generative AI, Iterative Refinement, Text Summarization.\n",
    "\n",
    "#### This is a simple prototype demonstrating the power of iterative refinement i.e. iteratively refining the output via the LLM to generate high-quality text summaries.\n",
    "\n",
    "<div style=\"display:flex; align-items:center; padding: 50px;\">\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"300px\" style=\"width:auto;\" width=\"200px\" src=\"https://avatars.githubusercontent.com/u/192148546?s=400&u=95d76fbb02e6c09671d87c9155f17ca1e4ef8f21&v=4\"> \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "## Description:\n",
    "\n",
    "Description\n",
    "Self-learning Text Summarization Prototype\n",
    "This project demonstrates the power of iterative refinement in generating high-quality text summaries. Using an AI-driven pipeline, the system analyzes input text, generates a summary, and improves it iteratively based on self-feedback to enhance clarity, coherence, and conciseness.\n",
    "\n",
    "- Core Features:\n",
    "\n",
    "   \n",
    "    - Rapid prototyping using LLMs.\n",
    "   \n",
    "    - Iterative refinement for quality improvement.\n",
    "   \n",
    "    - Multi-step summarization with context understanding.\n",
    "\n",
    "- Applications:\n",
    "\n",
    " \n",
    "    - Efficient text summarization.\n",
    "    \n",
    "    - Adaptable for multiple formats and contexts (plain text, markdown).\n",
    "    \n",
    "    - Provides metadata and quality evaluations.\n",
    "    \n",
    "    - This tool simplifies complex content for easier understanding and supports detailed refinement for professional use cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Initialization and Dependency Setup\n",
    "\n",
    "This script serves as a boilerplate for setting up a Python environment in Jupyter notebooks, ensuring that all dependencies are installed and required environment variables are configured. Below is a breakdown of its key functionalities:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Purpose**\n",
    "\n",
    "The script is designed to:\n",
    "  \n",
    "#### - Install necessary Python libraries specified in a `requirements.txt` file.\n",
    "\n",
    "#### - Verify the presence of essential environment variables (e.g., `OPENAI_API_KEY`).\n",
    "\n",
    "#### - Provide retry mechanisms for handling transient installation errors.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Installing Requirements**\n",
    "#### `install_requirements()` Function:\n",
    "\n",
    "- **Purpose:**\n",
    "\n",
    "  Installs packages listed in the `requirements.txt` file using `pip install -r requirements.txt`.\n",
    "\n",
    "- **Features:**\n",
    "\n",
    "  - Uses a `requirements_installed` flag to avoid redundant installations.\n",
    "\n",
    "  - Implements a retry mechanism (`max_retries` and `retries`) to address transient issues during installation.\n",
    "\n",
    "  - Terminates with a clear error message if all retries fail.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Environment Setup**\n",
    "\n",
    "#### **Loading Environment Variables:**\n",
    "\n",
    "- Uses the `dotenv` package to securely load variables from a `.env` file into the environment.\n",
    "\n",
    "- This is crucial for managing sensitive credentials like API keys.\n",
    "\n",
    "\n",
    "#### `setup_env()` Function:\n",
    "\n",
    "- **Purpose:**\n",
    "\n",
    "  Ensures all required environment variables are set before proceeding.\n",
    "\n",
    "\n",
    "- **Process:**\n",
    "\n",
    "  - Checks against the `REQUIRED_ENV_VARS` list.\n",
    "\n",
    "  - If an environment variable is missing:\n",
    "\n",
    "    - Displays a clear error message.\n",
    "\n",
    "    - Terminates the execution to prevent running the notebook in an incomplete state.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Clear Output and Final Message**\n",
    "\n",
    "- **`clear_output()`:**\n",
    "\n",
    "  Cleans up notebook cell output to improve readability after setup.\n",
    "\n",
    "- **Success Message:**\n",
    "\n",
    "  Indicates that the setup is complete and users can proceed confidently.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Resilience and User Guidance**\n",
    "\n",
    "- **Error Handling:**\n",
    "\n",
    "  Incorporates retry logic for dependency installation, reducing the need for manual intervention.\n",
    "  \n",
    "- **Informative Feedback:**\n",
    "\n",
    "  Provides clear and actionable error messages to guide users in resolving issues, such as setting missing environment variables.\n",
    "  \n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "This script automates the setup of a Python environment in Jupyter notebooks. By managing dependencies, verifying configurations, and offering robust error handling, it ensures a seamless and reliable user experience.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate: This block goes into every notebook.\n",
    "# It sets up the environment, installs the requirements, and checks for the required environment variables.\n",
    "\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "requirements_installed = False\n",
    "max_retries = 3\n",
    "retries = 0\n",
    "REQUIRED_ENV_VARS = [\"OPENAI_API_KEY\"]\n",
    "\n",
    "\n",
    "def install_requirements():\n",
    "    \"\"\"Installs the requirements from requirements.txt file\"\"\"\n",
    "    global requirements_installed\n",
    "    if requirements_installed:\n",
    "        print(\"Requirements already installed.\")\n",
    "        return\n",
    "\n",
    "    print(\"Installing requirements...\")\n",
    "    install_status = os.system(\"pip install -r requirements.txt\")\n",
    "    if install_status == 0:\n",
    "        print(\"Requirements installed successfully.\")\n",
    "        requirements_installed = True\n",
    "    else:\n",
    "        print(\"Failed to install requirements.\")\n",
    "        if retries < max_retries:\n",
    "            print(\"Retrying...\")\n",
    "            retries += 1\n",
    "            return install_requirements()\n",
    "        exit(1)\n",
    "    return\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "def setup_env():\n",
    "    \"\"\"Sets up the environment variables\"\"\"\n",
    "\n",
    "    def check_env(env_var):\n",
    "        value = os.getenv(env_var)\n",
    "        if value is None:\n",
    "            print(f\"Please set the {env_var} environment variable.\")\n",
    "            exit(1)\n",
    "        else:\n",
    "            print(f\"{env_var} is set.\")\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    variables_to_check = REQUIRED_ENV_VARS\n",
    "\n",
    "    for var in variables_to_check:\n",
    "        check_env(var)\n",
    "\n",
    "\n",
    "install_requirements()\n",
    "setup_env()\n",
    "clear_output()\n",
    "print(\"üöÄ Setup complete. Continue to the next cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: SelfLearningSummarizer Class Implementation\n",
    "\n",
    "## Imports and Constants\n",
    "\n",
    "- `import traceback:`  \n",
    "  Used to provide detailed information about exceptions (errors) that occur during program execution, including the error message and stack trace.\n",
    "\n",
    "- `from openai import OpenAI:`  \n",
    "  Imports the OpenAI class to interact with OpenAI's API for generating text responses.\n",
    "\n",
    "- `import os:`  \n",
    "  Provides functions for interacting with the operating system, such as environment variables and file paths.\n",
    "\n",
    "- `from uuid import uuid4:`  \n",
    "  Used to generate unique identifiers for various sessions or processes (e.g., for iterative refinement).\n",
    "\n",
    "- `DEFAULT_OPENAI_MODEL = \"gpt-4o-mini\":`  \n",
    "  Specifies a default model to use when interacting with OpenAI's API.\n",
    "\n",
    "## Prompts\n",
    "\n",
    "- `SIMPLE_SUMMARIZATION_SYSTEM_PROMPT:`  \n",
    "  A predefined system message that sets the behavior of the AI for summarization tasks.  \n",
    "  Describes capabilities (e.g., context recognition, semantic comprehension) and expectations for analyzing input text.\n",
    "\n",
    "- `SIMPLE_SUMMARIZATION_PROMPT:`  \n",
    "  The main instruction template for summarizing text.  \n",
    "  Contains detailed steps for analyzing and structuring the summary, ensuring adherence to specific requirements.\n",
    "\n",
    "- `ITERATIVE_REFINEMENT_SYSTEM_PROMPT:`  \n",
    "  Defines the AI's role for refining summaries iteratively.\n",
    "\n",
    "- `ITERATIVE_REFINEMENT_PROMPT:`  \n",
    "  Instructions for refining a summary in multiple iterations, focusing on clarity, coherence, and other factors.  \n",
    "  Includes steps like self-evaluation and providing reasons for refinements.\n",
    "\n",
    "## Class Definition: SelfLearningSummarizer\n",
    "\n",
    "- `class SelfLearningSummarizer::`  \n",
    "  Defines a class that encapsulates methods for summarization, refinement, and comparison of summaries.\n",
    "\n",
    "- `def __init__(self, model=\"gpt-4o-mini\")::`  \n",
    "  Constructor for initializing the summarizer instance.\n",
    "\n",
    "- `self.llm = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\")):`  \n",
    "  Initializes the OpenAI client using the API key from environment variables.\n",
    "\n",
    "- `self.model = model:`  \n",
    "  Sets the default model for the summarizer.\n",
    "\n",
    "## Method 1: get_summary\n",
    "\n",
    "- `def get_summary(self, source_text: str, format=\"plain_text\") -> str::`  \n",
    "  Method to generate a summary for a given text.\n",
    "\n",
    "- `Parameters:`  \n",
    "  - `source_text:` The text to summarize.  \n",
    "  - `format:` Specifies output format (plain_text or markdown).\n",
    "\n",
    "- `try::`  \n",
    "  Start of error-handling block for catching exceptions.\n",
    "\n",
    "- `if format not in [\"plain_text\", \"markdown\"]::`  \n",
    "  Ensures that the format parameter is valid.\n",
    "\n",
    "- `system = SIMPLE_SUMMARIZATION_SYSTEM_PROMPT:`  \n",
    "  Assigns the summarization system prompt.\n",
    "\n",
    "- `prompt = SIMPLE_SUMMARIZATION_PROMPT.format(text=source_text, format=format):`  \n",
    "  Prepares the summarization prompt by replacing placeholders (`{text}`, `{format}`) with the actual input text and desired format.\n",
    "\n",
    "- `messages = [{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": prompt}]:`  \n",
    "  Constructs the input message structure required by the OpenAI API.\n",
    "\n",
    "- `response = self.llm.chat.completions.create(...):`  \n",
    "  Calls the OpenAI API to generate a summary.\n",
    "\n",
    "- `summary = response.choices[0].message.content:`  \n",
    "  Extracts the generated summary from the API response.\n",
    "\n",
    "- `except Exception as e::`  \n",
    "  Handles errors, logs the issue using traceback, and returns an empty string.\n",
    "\n",
    "## Method 2: iterative_refinement\n",
    "\n",
    "- `def iterative_refinement(self, source_text: str, summary: str, turns=3, format=\"plain_text\") -> str::`  \n",
    "  Refines a summary iteratively based on feedback.\n",
    "\n",
    "- `Parameters:`  \n",
    "  - `source_text:` The original text.  \n",
    "  - `summary:` Initial summary to refine.  \n",
    "  - `turns:` Number of refinement iterations.  \n",
    "  - `format:` Output format.\n",
    "\n",
    "- `session_id = str(uuid4()):`  \n",
    "  Generates a unique ID for the refinement session.\n",
    "\n",
    "- `current_summary = summary:`  \n",
    "  Starts with the initial summary.\n",
    "\n",
    "- `while current_turn <= turns::`  \n",
    "  Loops through the specified number of refinement iterations.\n",
    "\n",
    "- `prompt = ITERATIVE_REFINEMENT_PROMPT.format(...):`  \n",
    "  Prepares the prompt for each refinement iteration.\n",
    "\n",
    "- `messages = [{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": prompt}]:`  \n",
    "  Constructs the input message for the API.\n",
    "\n",
    "- `current_summary = llm_response.choices[0].message.content:`  \n",
    "  Updates the summary with the refined version.\n",
    "\n",
    "- `return current_summary:`  \n",
    "  Returns the final refined summary after completing all iterations.\n",
    "\n",
    "## Method 3: compare_summaries\n",
    "\n",
    "- `def compare_summaries(self, source_text: str, summary1: str, summary2: str) -> str::`  \n",
    "  Compares two summaries and evaluates their quality.\n",
    "\n",
    "- `Parameters:`  \n",
    "  - `source_text:` Original text.  \n",
    "  - `summary1:` Initial summary.  \n",
    "  - `summary2:` Refined summary.\n",
    "\n",
    "- `prompt = f\"Compare the two summaries below ...\":`  \n",
    "  Prepares the prompt for comparing the summaries.\n",
    "\n",
    "- `response = self.llm.chat.completions.create(...):`  \n",
    "  Calls the OpenAI API to evaluate the summaries.\n",
    "\n",
    "- `return feedback:`  \n",
    "  Returns the feedback as a markdown table.\n",
    "\n",
    "## Utility Methods\n",
    "\n",
    "- `def get(self)::`  \n",
    "  Placeholder for retrieving items from an internal queue (not implemented).\n",
    "\n",
    "- `def empty(self)::`  \n",
    "  Placeholder for checking if the queue is empty (not implemented).\n",
    "\n",
    "This code provides a comprehensive framework for text summarization, iterative refinement, and quality comparison, leveraging OpenAI's language models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from uuid import uuid4\n",
    "\n",
    "DEFAULT_OPENAI_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "SIMPLE_SUMMARIZATION_SYSTEM_PROMPT = \"\"\"\n",
    "    You are SummarizerGPT, an advanced AI system specialized in text summarization. Your core function is to process and analyze various types of text input, preparing the groundwork for generating high-quality summaries. Your capabilities include:\n",
    "\n",
    "    1. Text Analysis: Quickly assess the structure, style, and content of any given text.\n",
    "    2. Context Recognition: Identify the domain, target audience, and purpose of the text.\n",
    "    3. Language Processing: Understand and process text in multiple languages and dialects.\n",
    "    4. Semantic Comprehension: Grasp complex ideas, abstract concepts, and subtle nuances in the text.\n",
    "    5. Information Hierarchy: Recognize the relative importance of different pieces of information within the text.\n",
    "    6. Cross-referencing: Identify and connect related ideas across different parts of the text.\n",
    "    7. Bias Detection: Recognize potential biases or slants in the original text.\n",
    "    8. Data Extraction: Pull out key statistics, dates, names, and other crucial data points.\n",
    "    9. Tone Analysis: Understand the emotional tone and rhetorical style of the text.\n",
    "    10. Multi-format Handling: Process various text formats including plain text, HTML, PDF extracts, and more.\n",
    "\n",
    "    You do not generate the summary directly. Instead, you prepare a comprehensive analysis of the text, which will be used by the summarization module to create the final output. Your analysis should include:\n",
    "\n",
    "    - Text type and structure\n",
    "    - Main topic and key themes\n",
    "    - Target audience and purpose\n",
    "    - Important data points and statistics\n",
    "    - Identified biases or controversial points\n",
    "    - Tone and style characteristics\n",
    "    - Any unique or standout elements in the text\n",
    "\n",
    "    Await the input text, and be ready to provide this detailed analysis to support the summarization process.\n",
    "\"\"\"\n",
    "\n",
    "SIMPLE_SUMMARIZATION_PROMPT = \"\"\"\n",
    "    1. Analyze the input:\n",
    "    - Determine the text type (article, research paper, conversation, etc.)\n",
    "    - Identify the main topic and key themes\n",
    "    - Assess the length and complexity of the content\n",
    "\n",
    "    2. Generate the summary:\n",
    "    - Provide a concise yet informative summary\n",
    "    - Maintain the original tone and style where appropriate\n",
    "    - Ensure factual accuracy and avoid introducing new information\n",
    "    - Use clear, coherent language suitable for a general audience\n",
    "\n",
    "    3. Structure the summary:\n",
    "    - Begin with a brief overview of the main topic\n",
    "    - Organize key points logically, using paragraphs or bullet points as appropriate\n",
    "    - Conclude with the most significant takeaway or implication\n",
    "\n",
    "    4. Adapt to specific requirements:\n",
    "    - If a word/character limit is specified, adhere to it strictly\n",
    "    - If the text contains technical terms, provide brief explanations\n",
    "    - For multi-section documents, summarize each section separately, then provide an overall summary\n",
    "\n",
    "    5. Handle edge cases:\n",
    "    - For very short texts, provide a condensed version without losing essential information\n",
    "    - For extremely long or complex texts, focus on the most crucial points and indicate that it's a high-level summary\n",
    "    - If the text contains conflicting viewpoints, present them objectively without bias\n",
    "\n",
    "    6. Enhance readability:\n",
    "    - Use transition words to improve flow between ideas\n",
    "    - Employ varied sentence structures to maintain engagement\n",
    "    - Highlight key terms or concepts using bold text when appropriate\n",
    "\n",
    "    7. Quality check:\n",
    "    - Ensure the summary is self-contained and understandable without the original text\n",
    "    - Verify that no critical information is omitted\n",
    "    - Check for consistency in tense, voice, and perspective\n",
    "\n",
    "    8. Metadata (if applicable):\n",
    "    - Include the original title, author, and date of publication\n",
    "    - Mention the word count of the original text and the summary\n",
    "\n",
    "    Now, summarize the following text, adhering to the above guidelines.\n",
    "\n",
    "    Text: '{text}'\n",
    "    Respond in the format '{format}' STRICTLY.\n",
    "    IF THE FORMAT IS 'plain_text', THEN RESPOND IN PLAIN TEXT ONLY, NOT MARKDOWN.\n",
    "    IF THE FORMAT IS 'markdown'. DIRECTLY GIVE THE MARKDOWN. DON'T WRAP IT IN ```markdown``` tags.\n",
    "\"\"\"\n",
    "\n",
    "ITERATIVE_REFINEMENT_SYSTEM_PROMPT = \"\"\"\n",
    "    You are a Refinement AI specializing in improving text quality. Your task is to refine the given text based on the given instructions.\n",
    "\"\"\"\n",
    "ITERATIVE_REFINEMENT_PROMPT = \"\"\"\n",
    "   You are a Refinement AI specializing in improving text quality. Your task is to refine the given text in a single iteration. Follow these steps:\n",
    "\n",
    "    1. Analyze the input:\n",
    "    - Identify the source text and the summary\n",
    "    - Assess strengths and weaknesses in content, structure, and style of the summary \n",
    "\n",
    "    2. Prioritize improvements:\n",
    "    - Focus on 2-3 key areas that will have the most significant impact that could be made in the summary\n",
    "    - Consider clarity, coherence, conciseness, and effectiveness\n",
    "\n",
    "    3. Refine the text:\n",
    "    - Make targeted improvements in the summary based on your analysis\n",
    "    - Maintain the original intent and core message in the source text\n",
    "    - Ensure changes enhance overall quality without introducing new issues\n",
    "\n",
    "    4. Provide a summary of changes:\n",
    "    - Briefly explain the key modifications made in the revised summary \n",
    "    - Justify your refinement decisions with clear reasoning\n",
    "\n",
    "    5. Self-evaluate:\n",
    "    - Rate the improvement on a scale of 1-10\n",
    "    - Briefly explain your rating\n",
    "\n",
    "    Source Text: '{source_text}'\n",
    "\n",
    "    Summary to be refined: '{summary}'\n",
    "    \n",
    "    Respond only with the final revised summary after all improvements are made. \n",
    "\n",
    "    Respond in the format '{format}' STRICTLY.\n",
    "    IF THE FORMAT IS 'plain_text', THEN RESPOND IN PLAIN TEXT ONLY, NOT MARKDOWN.\n",
    "    IF THE FORMAT IS 'markdown'. DIRECTLY GIVE THE MARKDOWN. DON'T WRAP IT IN ```markdown``` tags.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class SelfLearningSummarizer:\n",
    "    \"\"\"Queue-based Summarizer implementation\"\"\"\n",
    "\n",
    "    def __init__(self, model=\"gpt-4o-mini\"):\n",
    "        self.llm = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        self.model = model\n",
    "\n",
    "    def get_summary(self, source_text: str, format=\"plain_text\") -> str:\n",
    "        \"\"\"Generates a summary of the given text\"\"\"\n",
    "        try:\n",
    "            if format not in [\"plain_text\", \"markdown\"]:\n",
    "                raise ValueError(\"Invalid format. Use 'plain_text' or 'markdown'.\")\n",
    "            system = SIMPLE_SUMMARIZATION_SYSTEM_PROMPT\n",
    "            prompt = SIMPLE_SUMMARIZATION_PROMPT.format(text=source_text, format=format)\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system,\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ]\n",
    "            response = self.llm.chat.completions.create(\n",
    "                messages=messages, model=self.model\n",
    "            )\n",
    "            summary = response.choices[0].message.content\n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to generate summary for {item}\")\n",
    "            traceback.print_exc()\n",
    "            return \"\"\n",
    "\n",
    "    def iterative_refinement(\n",
    "        self, source_text: str, summary: str, turns=3, format=\"plain_text\"\n",
    "    ) -> str:\n",
    "        \"\"\"Iteratively refines the summary based on self-generated feedback for given turns.\"\"\"\n",
    "        session_id = str(uuid4())\n",
    "        print(f\"Iterative Refinement ({session_id}): Session ID: {session_id}\")\n",
    "        current_summary = summary\n",
    "        current_turn = 1\n",
    "        try:\n",
    "            while current_turn <= turns:\n",
    "                print(f\"Iterative Refinement ({session_id}): Turn {current_turn}.\")\n",
    "                system = ITERATIVE_REFINEMENT_SYSTEM_PROMPT\n",
    "                prompt = ITERATIVE_REFINEMENT_PROMPT.format(\n",
    "                    source_text=source_text, summary=current_summary, format=format\n",
    "                )\n",
    "                messages = [\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": system,\n",
    "                    },\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ]\n",
    "                llm_response = self.llm.chat.completions.create(\n",
    "                    messages=messages, model=self.model\n",
    "                )\n",
    "                current_summary = llm_response.choices[0].message.content\n",
    "                current_turn += 1\n",
    "                print(\n",
    "                    f\"Iterative Refinement ({session_id}): Turn {current_turn} completed. Updated rolling summary.\"\n",
    "                )\n",
    "            return current_summary\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"Iterative Refinement ({session_id}): Failed to complete all turns for {source_text} and {summary}.\"\n",
    "            )\n",
    "            print(\n",
    "                f\"Iterative Refinement ({session_id}): Turns completed: {current_turn}\"\n",
    "            )\n",
    "            traceback.print_exc()\n",
    "            return current_summary\n",
    "\n",
    "    def compare_summaries(self, source_text: str, summary1: str, summary2: str) -> str:\n",
    "        \"\"\"Compares two summaries and provides feedback on their quality.\"\"\"\n",
    "        try:\n",
    "            print(f\"Comparing summaries for {source_text}.\")\n",
    "            system = \"You are a Comparison AI specializing in evaluating text quality. Your task is to compare two summaries and provide feedback on their quality.\"\n",
    "            prompt = f\"\"\"\n",
    "            Compare the two summaries below and provide feedback on their quality. \n",
    "            Provide score comparison for both summaries, the old summary score and the new summary score.\n",
    "            This will help us compare the two summaries on various parameters.\n",
    "            Refer to the source text when making your evaluation. \\n\\n \n",
    "            Source Text: {source_text}\n",
    "            Initial Summary: {summary1} \n",
    "            Refined Summary: {summary2}\n",
    "            STRICTLY PROVIDE YOUR RESPONSE AS MARKDOWN TABLE WITH SCORES AND JUSTIFICATIONS.\n",
    "            \"\"\"\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system,\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ]\n",
    "            response = self.llm.chat.completions.create(\n",
    "                messages=messages, model=self.model\n",
    "            )\n",
    "            feedback = response.choices[0].message.content\n",
    "            return feedback\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to compare summaries for {source_text}\")\n",
    "            traceback.print_exc()\n",
    "            return \"\"\n",
    "\n",
    "    def get(self):\n",
    "        return self.q.get()\n",
    "\n",
    "    def empty(self):\n",
    "        return self.q.empty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate Summary Using SelfLearningSummarizer Class\n",
    "\n",
    "1. **Creating the Summarizer Object:**\n",
    "\n",
    "   The line `summarizer = SelfLearningSummarizer()` initializes an object of the `SelfLearningSummarizer` class. \n",
    "\n",
    "   This object will be used to process the provided text.\n",
    "\n",
    "2. **Sample Text for Summarization:**\n",
    "\n",
    "   The `text` variable holds a sample paragraph discussing how to effectively manage projects as an engineer, focusing on task prioritization, leadership, and ensuring project success.\n",
    "\n",
    "3. **Choosing the Format:**\n",
    "\n",
    "   The `format` variable is set to `\"plain_text\"`, meaning the summary will be generated in plain text format, not markdown.\n",
    "\n",
    "4. **Generating the Summary:**\n",
    "\n",
    "   The `summarizer.get_summary(text, format=format)` method is called to generate a summary of the provided text. \n",
    "\n",
    "   This will call the `get_summary` method within the `SelfLearningSummarizer` class, which uses the OpenAI API to generate a summary based on the provided system and user prompts.\n",
    "\n",
    "5. **Outputting the Summary:**\n",
    "\n",
    "   The `print(summary)` statement will output the generated summary to the console.\n",
    "\n",
    "   When you run the code, it should generate a concise, informative summary of the provided text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the summary and test our prompts which seem to be solid.\n",
    "\n",
    "summarizer = SelfLearningSummarizer()\n",
    "\n",
    "# Credits: Arpit Bhayani\n",
    "# Post Link: https://www.linkedin.com/posts/arpitbhayani_asliengineering-careergrowth-activity-7280566114894430208-tjB2?utm_source=share&utm_medium=member_desktop\n",
    "\n",
    "text = \"\"\"\n",
    "When working on a new project, we engineers almost always start with the most fascinating part. But, while it's exciting for us, it's not always what's best for the project.\n",
    "\n",
    "The easiest way to become an effective lead/manager is to break down the project into tasks and prioritize the most important items. So, it is always a good idea that before the work begins, step back and ask\n",
    "\n",
    "1. what is the most critical piece?\n",
    "2. which items are highest risk and need early attention?\n",
    "3. which deliverables provide the most immediate value?\n",
    "\n",
    "We naturally gravitate towards easily doable, less impactful, and tangential parts of the project. This happens because of a lack of a broader context. So, if you are leading a project, make sure,\n",
    "\n",
    "1. define a clear roadmap and align it with business outcomes\n",
    "2. define milestones and priorities\n",
    "\n",
    "A good leader doesn‚Äôt micromanage but ensures that the team starts on the right foot. Check-in periodically to ensure the alignment while giving engineers ownership of their tasks.\n",
    "\n",
    "Prioritization is what separates effective leads from those simply managing tasks. As a lead, you are not just there to oversee execution but to set the direction.\n",
    "\"\"\"\n",
    "format = \"plain_text\"\n",
    "\n",
    "summary = summarizer.get_summary(text, format=format)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Display Summary in Markdown Format\n",
    "\n",
    "The code you've written will generate the summary and display it as markdown in the notebook output.\n",
    "\n",
    "Here's a breakdown of the added steps for markdown display:\n",
    "\n",
    "### Creating a Markdown Object:\n",
    "\n",
    "`markdown_summary = Markdown(f\"## Summary\\n{summary}\")` creates a markdown object. The summary generated earlier is placed inside the markdown object with a `## Summary` header to format it as a section heading.\n",
    "\n",
    "### Displaying the Markdown:\n",
    "\n",
    "`display(markdown_summary)` displays the markdown content in the notebook. This will render the summary with the appropriate markdown formatting, such as the header for the \"Summary\" section.\n",
    "\n",
    "Once the code runs, the summary will be shown in the notebook as formatted markdown.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a markdown response now\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "summarizer = SelfLearningSummarizer()\n",
    "text = \"\"\"\n",
    "When working on a new project, we engineers almost always start with the most fascinating part. But, while it's exciting for us, it's not always what's best for the project.\n",
    "\n",
    "The easiest way to become an effective lead/manager is to break down the project into tasks and prioritize the most important items. So, it is always a good idea that before the work begins, step back and ask\n",
    "\n",
    "1. what is the most critical piece?\n",
    "2. which items are highest risk and need early attention?\n",
    "3. which deliverables provide the most immediate value?\n",
    "\n",
    "We naturally gravitate towards easily doable, less impactful, and tangential parts of the project. This happens because of a lack of a broader context. So, if you are leading a project, make sure,\n",
    "\n",
    "1. define a clear roadmap and align it with business outcomes\n",
    "2. define milestones and priorities\n",
    "\n",
    "A good leader doesn‚Äôt micromanage but ensures that the team starts on the right foot. Check-in periodically to ensure the alignment while giving engineers ownership of their tasks.\n",
    "\n",
    "Prioritization is what separates effective leads from those simply managing tasks. As a lead, you are not just there to oversee execution but to set the direction.\n",
    "\"\"\"\n",
    "format = \"plain_text\"\n",
    "\n",
    "summary = summarizer.get_summary(text, format=format)\n",
    "markdown_summary = Markdown(f\"## Summary\\n{summary}\")\n",
    "display(markdown_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate and Display Refined Summary\n",
    "\n",
    "### Summarizer Initialization:\n",
    "\n",
    "The `SelfLearningSummarizer` class is instantiated, creating an object that will be used for generating and refining summaries. This object contains methods for the summarization process.\n",
    "\n",
    "### Text Input:\n",
    "\n",
    "The text input represents the content that will be summarized. In this case, the text discusses project management, leadership, and prioritization in an engineering context.\n",
    "\n",
    "### Format for Summary:\n",
    "\n",
    "The format in which the summary will be generated is set to `plain_text`. This means the output will be returned as simple text, with no markdown or advanced formatting applied.\n",
    "\n",
    "### Generate Initial Summary:\n",
    "\n",
    "The summarizer analyzes the input text and generates an initial summary based on the content. This summary is aimed at capturing the main ideas and key points from the original text.\n",
    "\n",
    "### Iterative Refinement:\n",
    "\n",
    "The initial summary is then refined iteratively. In this case, the process will go through 3 cycles of refinement. Each cycle involves analyzing the current version of the summary and making improvements to enhance clarity, coherence, and conciseness.\n",
    "\n",
    "### Prepare the Markdown Object:\n",
    "\n",
    "Once the final refined summary is obtained, it is formatted as a markdown object, which includes a header that specifies the number of refinement turns applied. The refined summary text is also included under this header.\n",
    "\n",
    "### Display the Markdown Summary:\n",
    "\n",
    "The markdown summary, which includes the header and the final refined summary, is displayed in the notebook. This allows the summary to be presented in a structured, easily readable format.\n",
    "\n",
    "### Summary of the Process:\n",
    "\n",
    "- First, an initial summary is created based on the provided text.\n",
    "\n",
    "- Then, that summary goes through a series of refinement steps to improve its quality.\n",
    "\n",
    "- The final refined summary is displayed in a markdown format, making it clear and structured for easy reading. This process ensures the summary captures the essence of the original text while being concise and coherent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = SelfLearningSummarizer()\n",
    "text = \"\"\"\n",
    "When working on a new project, we engineers almost always start with the most fascinating part. But, while it's exciting for us, it's not always what's best for the project.\n",
    "\n",
    "The easiest way to become an effective lead/manager is to break down the project into tasks and prioritize the most important items. So, it is always a good idea that before the work begins, step back and ask\n",
    "\n",
    "1. what is the most critical piece?\n",
    "2. which items are highest risk and need early attention?\n",
    "3. which deliverables provide the most immediate value?\n",
    "\n",
    "We naturally gravitate towards easily doable, less impactful, and tangential parts of the project. This happens because of a lack of a broader context. So, if you are leading a project, make sure,\n",
    "\n",
    "1. define a clear roadmap and align it with business outcomes\n",
    "2. define milestones and priorities\n",
    "\n",
    "A good leader doesn‚Äôt micromanage but ensures that the team starts on the right foot. Check-in periodically to ensure the alignment while giving engineers ownership of their tasks.\n",
    "\n",
    "Prioritization is what separates effective leads from those simply managing tasks. As a lead, you are not just there to oversee execution but to set the direction.\n",
    "\"\"\"\n",
    "format = \"plain_text\"\n",
    "turns = 3\n",
    "\n",
    "summary = summarizer.get_summary(text, format=format)\n",
    "\n",
    "refined_summary = summarizer.iterative_refinement(\n",
    "    text, summary, turns=turns, format=format\n",
    ")\n",
    "\n",
    "markdown_summary = Markdown(f\"## Refined Summary (turns={turns})\\n{refined_summary}\")\n",
    "\n",
    "display(markdown_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Iterative Summarization and Comparison\n",
    "\n",
    "### 1. Importing Necessary Libraries\n",
    "\n",
    "- `IPython.display`: This is a module that allows you to display rich media, including Markdown text, HTML, and other objects in Jupyter notebooks or IPython environments.\n",
    "\n",
    "- `Markdown`: A function from the `IPython.display` module that renders text as Markdown in the notebook.\n",
    "\n",
    "- `clear_output`: Clears the output of the current cell in a Jupyter notebook, which is useful when you want to refresh the display or hide unnecessary outputs during execution.\n",
    "\n",
    "### 2. Input Text\n",
    "\n",
    "This variable `text` holds the original content you want to summarize and process.\n",
    "\n",
    "It explains the concept of framework-defined infrastructure, its benefits, and how it operates in cloud environments.\n",
    "\n",
    "### 3. Defining Variables for Summary Iterations\n",
    "\n",
    "- `turns`: Defines how many iterations the summarizer will undergo to refine the summary.\n",
    "\n",
    "- In this case, it is set to 5, meaning the summarizer will refine the initial summary in 5 rounds.\n",
    "\n",
    "### 4. Summarizing the Text\n",
    "\n",
    "- `summarizer = SelfLearningSummarizer()`: Here, a summarizer object is created. This class or function is responsible for processing the input text and generating a summary.\n",
    "\n",
    "- `get_summary(text, format=format)`: This method processes the input text and returns a summarized version of it. The format for output is specified by the variable `format`. We would need to define `format` earlier in the code, typically something like `plain_text` or `markdown`.\n",
    "\n",
    "### 5. Iterative Refinement of the Summary\n",
    "\n",
    "- `iterative_refinement`: This method is key to improving the initial summary over multiple iterations. Each iteration aims to refine the summary by making it more concise and accurate, while retaining important concepts from the original text.\n",
    "\n",
    "- **Parameters**:\n",
    "  - `text`: The original input text to help with refining the summary.\n",
    "\n",
    "  - `summary`: The initial summary created in the previous step.\n",
    "\n",
    "  - `turns=turns`: Specifies how many times the summary will be refined. Here, it will refine the summary 5 times.\n",
    "\n",
    "  - `format=format`: Ensures the summary is output in the desired format (e.g., `plain_text`).\n",
    "\n",
    "\n",
    "### 6. Comparing Original and Refined Summaries\n",
    "\n",
    "- `compare_summaries`: This method compares the initial summary with the refined summary after multiple iterations. It helps to assess how much the refinement process improved the quality, clarity, and conciseness of the summary.\n",
    "\n",
    "- **Parameters**:\n",
    "  - `text`: The original input text.\n",
    "  \n",
    "  - `summary`: The initial summary generated by the summarizer.\n",
    "  \n",
    "  - `refined_summary`: The version of the summary after being refined over `turns` iterations.\n",
    "\n",
    "### 7. Clearing the Output and Displaying Comparison\n",
    "\n",
    "- `clear_output()`: Clears the output area of the notebook to ensure that only relevant results are shown, particularly when running cells multiple times.\n",
    "\n",
    "- `Markdown(f\"## Comparison\\n{comparison}\")`: Converts the comparison (which is likely a text-based comparison or report) into Markdown format. The `##` in the string indicates a second-level heading in Markdown.\n",
    "\n",
    "- `display(markdown)`: Displays the Markdown formatted text in the notebook. This will render the comparison of the original and refined summaries for easy comparison.\n",
    "\n",
    "### Overall Process and Flow\n",
    "\n",
    "- Input the text you want to summarize.\n",
    "\n",
    "- Generate an initial summary using the `SelfLearningSummarizer`.\n",
    "\n",
    "- Refine the summary iteratively to improve clarity, conciseness, and information retention.\n",
    "\n",
    "- Compare the original and refined summaries to assess the effectiveness of the refinement process.\n",
    "\n",
    "- Clear the output to refresh the display and then show the comparison in Markdown format.\n",
    "\n",
    "### Purpose of this Code\n",
    "\n",
    "The primary goal of this code is to summarize complex text and refine the summary over multiple iterations. The iterative refinement process ensures that the final summary is both accurate and concise. By comparing the initial and refined summaries, users can see how much improvement was made during the refinement stages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, clear_output\n",
    "\n",
    "turns = 5\n",
    "text = \"\"\"\n",
    "What is framework-defined infrastructure?\n",
    "Framework-defined infrastructure abstracts over cloud primitives such as servers, message queues, and serverless functions, making them mere implementation details of the frameworks' concepts:\n",
    "\n",
    "Providing portability between different target infrastructure providers\n",
    "\n",
    "Eliminating the need to manually configure infrastructure to run an application in production\n",
    "\n",
    "Increasing the time spent writing product code over system management\n",
    "\n",
    "Allowing the unchanged use of the framework's native local development tools\n",
    "\n",
    "Standardizing on pre-reviewed secure services\n",
    "\n",
    "Frameworks use well-established patterns to provide structure and abstraction to applications, making them easier to write and understand. While the word framework is hard to define, the Hollywood principle, \"Don't call us, we call you,\" probably captures best the inversion of control, where the framework manages the high-level application flow while the developer writes code within the hooks provided by it.\n",
    "\n",
    "Framework-defined infrastructure takes advantage of both this inversion of control and the predictable structure of framework-based applications to automatically map framework concepts onto the appropriate infrastructure without the need for explicit declaration or configuration of the infrastructure.\n",
    "\n",
    "Note that this post is giving examples based on Vercel's Platform as a Service offering. The concept, however, can be applied more widely as the basic idea of understanding a framework, and generating IaC configuration for it, can also be used for more traditional infrastructure deployments.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "summarizer = SelfLearningSummarizer()\n",
    "summary = summarizer.get_summary(text, format=format)\n",
    "refined_summary = summarizer.iterative_refinement(\n",
    "    text, summary, turns=turns, format=format\n",
    ")\n",
    "comparison = summarizer.compare_summaries(text, summary, refined_summary)\n",
    "clear_output()\n",
    "markdown = Markdown(f\"## Comparison\\n{comparison}\")\n",
    "display(markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Environment Initialization and Dependency Setup\n",
    "\n",
    "This script serves as a boilerplate for setting up a Python environment in Jupyter notebooks, ensuring that all dependencies are installed and required environment variables are configured. Below is a breakdown of its key functionalities:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Purpose**\n",
    "\n",
    "The script is designed to:\n",
    "  \n",
    "#### - Install necessary Python libraries specified in a `requirements.txt` file.\n",
    "\n",
    "#### - Verify the presence of essential environment variables (e.g., `OPENAI_API_KEY`).\n",
    "\n",
    "#### - Provide retry mechanisms for handling transient installation errors.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Installing Requirements**\n",
    "#### `install_requirements()` Function:\n",
    "\n",
    "- **Purpose:**\n",
    "\n",
    "  Installs packages listed in the `requirements.txt` file using `pip install -r requirements.txt`.\n",
    "\n",
    "- **Features:**\n",
    "\n",
    "  - Uses a `requirements_installed` flag to avoid redundant installations.\n",
    "\n",
    "  - Implements a retry mechanism (`max_retries` and `retries`) to address transient issues during installation.\n",
    "\n",
    "  - Terminates with a clear error message if all retries fail.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Environment Setup**\n",
    "\n",
    "#### **Loading Environment Variables:**\n",
    "\n",
    "- Uses the `dotenv` package to securely load variables from a `.env` file into the environment.\n",
    "\n",
    "- This is crucial for managing sensitive credentials like API keys.\n",
    "\n",
    "\n",
    "#### `setup_env()` Function:\n",
    "\n",
    "- **Purpose:**\n",
    "\n",
    "  Ensures all required environment variables are set before proceeding.\n",
    "\n",
    "\n",
    "- **Process:**\n",
    "\n",
    "  - Checks against the `REQUIRED_ENV_VARS` list.\n",
    "\n",
    "  - If an environment variable is missing:\n",
    "\n",
    "    - Displays a clear error message.\n",
    "\n",
    "    - Terminates the execution to prevent running the notebook in an incomplete state.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Clear Output and Final Message**\n",
    "\n",
    "- **`clear_output()`:**\n",
    "\n",
    "  Cleans up notebook cell output to improve readability after setup.\n",
    "\n",
    "- **Success Message:**\n",
    "\n",
    "  Indicates that the setup is complete and users can proceed confidently.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Resilience and User Guidance**\n",
    "\n",
    "- **Error Handling:**\n",
    "\n",
    "  Incorporates retry logic for dependency installation, reducing the need for manual intervention.\n",
    "  \n",
    "- **Informative Feedback:**\n",
    "\n",
    "  Provides clear and actionable error messages to guide users in resolving issues, such as setting missing environment variables.\n",
    "  \n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "This script automates the setup of a Python environment in Jupyter notebooks. By managing dependencies, verifying configurations, and offering robust error handling, it ensures a seamless and reliable user experience.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate: This block goes into every notebook.\n",
    "# It sets up the environment, installs the requirements, and checks for the required environment variables.\n",
    "\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "requirements_installed = False\n",
    "max_retries = 3\n",
    "retries = 0\n",
    "REQUIRED_ENV_VARS = [\"OPENAI_API_KEY\"]\n",
    "\n",
    "\n",
    "def install_requirements():\n",
    "    \"\"\"Installs the requirements from requirements.txt file\"\"\"\n",
    "    global requirements_installed\n",
    "    if requirements_installed:\n",
    "        print(\"Requirements already installed.\")\n",
    "        return\n",
    "\n",
    "    print(\"Installing requirements...\")\n",
    "    install_status = os.system(\"pip install -r requirements.txt\")\n",
    "    if install_status == 0:\n",
    "        print(\"Requirements installed successfully.\")\n",
    "        requirements_installed = True\n",
    "    else:\n",
    "        print(\"Failed to install requirements.\")\n",
    "        if retries < max_retries:\n",
    "            print(\"Retrying...\")\n",
    "            retries += 1\n",
    "            return install_requirements()\n",
    "        exit(1)\n",
    "    return\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "def setup_env():\n",
    "    \"\"\"Sets up the environment variables\"\"\"\n",
    "\n",
    "    def check_env(env_var):\n",
    "        value = os.getenv(env_var)\n",
    "        if value is None:\n",
    "            print(f\"Please set the {env_var} environment variable.\")\n",
    "            exit(1)\n",
    "        else:\n",
    "            print(f\"{env_var} is set.\")\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    variables_to_check = REQUIRED_ENV_VARS\n",
    "\n",
    "    for var in variables_to_check:\n",
    "        check_env(var)\n",
    "\n",
    "\n",
    "install_requirements()\n",
    "setup_env()\n",
    "clear_output()\n",
    "print(\"üöÄ Setup complete. Continue to the next cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Understanding the SelfLearningSummarizer Class\n",
    "\n",
    "### 1. Constants and Prompts\n",
    "\n",
    "- `DEFAULT_OPENAI_MODEL`: This is the default model used to interact with the OpenAI API, set to \"gpt-4o-mini\".\n",
    "\n",
    "**Prompt Strings**:\n",
    "\n",
    "- `SIMPLE_SUMMARIZATION_SYSTEM_PROMPT`: Defines the system's role and capabilities for summarization. This prompt outlines the summarizer's features, including its ability to process and analyze text in various formats, understand language, and identify critical information.\n",
    "\n",
    "- `SIMPLE_SUMMARIZATION_PROMPT`: A detailed prompt that guides the summarization process, including:\n",
    "\n",
    "  - Text analysis (identifying key themes, structure, and audience).\n",
    "\n",
    "  - Generation of a concise summary.\n",
    "\n",
    "  - Formatting the summary (ensuring readability, structuring, etc.).\n",
    "\n",
    "  - Handling edge cases like very short or long texts.\n",
    "\n",
    "- `ITERATIVE_REFINEMENT_SYSTEM_PROMPT`: A system prompt that instructs the AI to refine the summary based on feedback and improve its quality.\n",
    "\n",
    "- `ITERATIVE_REFINEMENT_PROMPT`: Provides detailed instructions to guide the refinement process, focusing on analyzing the text, prioritizing areas of improvement, making targeted changes, and providing a self-evaluation.\n",
    "\n",
    "### 2. SelfLearningSummarizer Class\n",
    "\n",
    "The core of this class is to manage the summarization, iterative refinement, and comparison of text summaries. It integrates the OpenAI API for text generation, refinement, and evaluation.\n",
    "\n",
    "#### 2.1 `__init__` Method\n",
    "\n",
    "- **Purpose**: This initializes an instance of the SelfLearningSummarizer class, setting up the OpenAI API connection using an API key (loaded from environment variables). The default model is set to `gpt-4o-mini`.\n",
    "\n",
    "#### 2.2 `get_summary` Method\n",
    "\n",
    "- **Purpose**: Generates a summary of the provided `source_text` based on a defined prompt.\n",
    "\n",
    "- **Steps**:\n",
    "\n",
    "  - Validates the `format` argument to ensure it‚Äôs either 'plain_text' or 'markdown'.\n",
    "\n",
    "  - Constructs the system and user messages to be sent to the OpenAI API, using the `SIMPLE_SUMMARIZATION_SYSTEM_PROMPT` and `SIMPLE_SUMMARIZATION_PROMPT`.\n",
    "\n",
    "  - Sends a request to the OpenAI model and retrieves the generated summary.\n",
    "\n",
    "  - Returns the generated summary.\n",
    "\n",
    "#### 2.3 `iterative_refinement` Method\n",
    "\n",
    "- **Purpose**: This method refines the generated summary iteratively over a specified number of turns (`turns`).\n",
    "\n",
    "- **Steps**:\n",
    "\n",
    "  - Initializes a session using a unique ID (via `uuid4`).\n",
    "\n",
    "  - For each turn (up to `turns`):\n",
    "\n",
    "    - Constructs the system and user messages for iterative refinement using the `ITERATIVE_REFINEMENT_SYSTEM_PROMPT` and `ITERATIVE_REFINEMENT_PROMPT`.\n",
    "\n",
    "    - Sends the request to the OpenAI API to refine the summary.\n",
    "\n",
    "    - Updates the summary based on the AI's response.\n",
    "\n",
    "  - Returns the final refined summary after completing all turns.\n",
    "\n",
    "#### 2.4 `compare_summaries` Method\n",
    "\n",
    "- **Purpose**: Compares two summaries (the initial one and the refined one) to evaluate their quality and provide feedback.\n",
    "- **Steps**:\n",
    "\n",
    "  - Constructs a system and user message for comparing summaries using the `compare_summaries` prompt.\n",
    "\n",
    "  - Sends the request to the OpenAI API, which provides a markdown table comparing the two summaries based on quality, structure, and other parameters.\n",
    "\n",
    "  - Returns the feedback as a markdown table.\n",
    "\n",
    "\n",
    "#### 2.5 `get` and `empty` Methods\n",
    "\n",
    "- These methods likely relate to a queue (`self.q`), but the queue isn‚Äôt initialized in the provided code snippet. If present, these methods would allow fetching items from the queue and checking if the queue is empty. These are standard methods for working with queues, often used in asynchronous or parallel processing.\n",
    "\n",
    "### 3. Error Handling\n",
    "\n",
    "The code uses `try-except` blocks to catch and handle exceptions:\n",
    "\n",
    "- In `get_summary`: If an error occurs while generating the summary (e.g., API failure), the exception is caught, and a traceback is printed.\n",
    "\n",
    "- In `iterative_refinement`: If an error occurs during any of the iterative refinement turns, the process is stopped, and the current summary is returned. A traceback is also printed for debugging.\n",
    "\n",
    "### 4. Output Format\n",
    "\n",
    "- The summary can be returned in either `plain_text` or `markdown` format, depending on the specified `format` argument. This flexibility allows the summarizer to be used in various contexts (e.g., plain text output for applications, markdown output for rendering in web platforms).\n",
    "\n",
    "### 5. Using the Summarizer\n",
    "\n",
    "To use the `SelfLearningSummarizer`, you would instantiate the class and call its methods like so:\n",
    "\n",
    "This code allows for summarizing text, refining the summary, and comparing the results to improve the quality and effectiveness of the final output.\n",
    "\n",
    "### Summary of Purpose\n",
    "\n",
    "This class automates the process of summarizing a given text, refining that summary iteratively, and comparing the original summary to a refined version to evaluate its quality. It leverages the OpenAI API for natural language processing tasks and ensures flexibility with different output formats, enabling use in various applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from uuid import uuid4\n",
    "\n",
    "DEFAULT_OPENAI_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "SIMPLE_SUMMARIZATION_SYSTEM_PROMPT = \"\"\"\n",
    "    You are SummarizerGPT, an advanced AI system specialized in text summarization. Your core function is to process and analyze various types of text input, preparing the groundwork for generating high-quality summaries. Your capabilities include:\n",
    "\n",
    "    1. Text Analysis: Quickly assess the structure, style, and content of any given text.\n",
    "    2. Context Recognition: Identify the domain, target audience, and purpose of the text.\n",
    "    3. Language Processing: Understand and process text in multiple languages and dialects.\n",
    "    4. Semantic Comprehension: Grasp complex ideas, abstract concepts, and subtle nuances in the text.\n",
    "    5. Information Hierarchy: Recognize the relative importance of different pieces of information within the text.\n",
    "    6. Cross-referencing: Identify and connect related ideas across different parts of the text.\n",
    "    7. Bias Detection: Recognize potential biases or slants in the original text.\n",
    "    8. Data Extraction: Pull out key statistics, dates, names, and other crucial data points.\n",
    "    9. Tone Analysis: Understand the emotional tone and rhetorical style of the text.\n",
    "    10. Multi-format Handling: Process various text formats including plain text, HTML, PDF extracts, and more.\n",
    "\n",
    "    You do not generate the summary directly. Instead, you prepare a comprehensive analysis of the text, which will be used by the summarization module to create the final output. Your analysis should include:\n",
    "\n",
    "    - Text type and structure\n",
    "    - Main topic and key themes\n",
    "    - Target audience and purpose\n",
    "    - Important data points and statistics\n",
    "    - Identified biases or controversial points\n",
    "    - Tone and style characteristics\n",
    "    - Any unique or standout elements in the text\n",
    "\n",
    "    Await the input text, and be ready to provide this detailed analysis to support the summarization process.\n",
    "\"\"\"\n",
    "\n",
    "SIMPLE_SUMMARIZATION_PROMPT = \"\"\"\n",
    "    1. Analyze the input:\n",
    "    - Determine the text type (article, research paper, conversation, etc.)\n",
    "    - Identify the main topic and key themes\n",
    "    - Assess the length and complexity of the content\n",
    "\n",
    "    2. Generate the summary:\n",
    "    - Provide a concise yet informative summary\n",
    "    - Maintain the original tone and style where appropriate\n",
    "    - Ensure factual accuracy and avoid introducing new information\n",
    "    - Use clear, coherent language suitable for a general audience\n",
    "\n",
    "    3. Structure the summary:\n",
    "    - Begin with a brief overview of the main topic\n",
    "    - Organize key points logically, using paragraphs or bullet points as appropriate\n",
    "    - Conclude with the most significant takeaway or implication\n",
    "\n",
    "    4. Adapt to specific requirements:\n",
    "    - If a word/character limit is specified, adhere to it strictly\n",
    "    - If the text contains technical terms, provide brief explanations\n",
    "    - For multi-section documents, summarize each section separately, then provide an overall summary\n",
    "\n",
    "    5. Handle edge cases:\n",
    "    - For very short texts, provide a condensed version without losing essential information\n",
    "    - For extremely long or complex texts, focus on the most crucial points and indicate that it's a high-level summary\n",
    "    - If the text contains conflicting viewpoints, present them objectively without bias\n",
    "\n",
    "    6. Enhance readability:\n",
    "    - Use transition words to improve flow between ideas\n",
    "    - Employ varied sentence structures to maintain engagement\n",
    "    - Highlight key terms or concepts using bold text when appropriate\n",
    "\n",
    "    7. Quality check:\n",
    "    - Ensure the summary is self-contained and understandable without the original text\n",
    "    - Verify that no critical information is omitted\n",
    "    - Check for consistency in tense, voice, and perspective\n",
    "\n",
    "    8. Metadata (if applicable):\n",
    "    - Include the original title, author, and date of publication\n",
    "    - Mention the word count of the original text and the summary\n",
    "\n",
    "    Now, summarize the following text, adhering to the above guidelines.\n",
    "\n",
    "    Text: '{text}'\n",
    "    Respond in the format '{format}' STRICTLY.\n",
    "    IF THE FORMAT IS 'plain_text', THEN RESPOND IN PLAIN TEXT ONLY, NOT MARKDOWN.\n",
    "    IF THE FORMAT IS 'markdown'. DIRECTLY GIVE THE MARKDOWN. DON'T WRAP IT IN ```markdown``` tags.\n",
    "\"\"\"\n",
    "\n",
    "ITERATIVE_REFINEMENT_SYSTEM_PROMPT = \"\"\"\n",
    "    You are a Refinement AI specializing in improving text quality. Your task is to refine the given text based on the given instructions.\n",
    "\"\"\"\n",
    "ITERATIVE_REFINEMENT_PROMPT = \"\"\"\n",
    "   You are a Refinement AI specializing in improving text quality. Your task is to refine the given text in a single iteration. Follow these steps:\n",
    "\n",
    "    1. Analyze the input:\n",
    "    - Identify the source text and the summary\n",
    "    - Assess strengths and weaknesses in content, structure, and style of the summary \n",
    "\n",
    "    2. Prioritize improvements:\n",
    "    - Focus on 2-3 key areas that will have the most significant impact that could be made in the summary\n",
    "    - Consider clarity, coherence, conciseness, and effectiveness\n",
    "\n",
    "    3. Refine the text:\n",
    "    - Make targeted improvements in the summary based on your analysis\n",
    "    - Maintain the original intent and core message in the source text\n",
    "    - Ensure changes enhance overall quality without introducing new issues\n",
    "\n",
    "    4. Provide a summary of changes:\n",
    "    - Briefly explain the key modifications made in the revised summary \n",
    "    - Justify your refinement decisions with clear reasoning\n",
    "\n",
    "    5. Self-evaluate:\n",
    "    - Rate the improvement on a scale of 1-10\n",
    "    - Briefly explain your rating\n",
    "\n",
    "    Source Text: '{source_text}'\n",
    "\n",
    "    Summary to be refined: '{summary}'\n",
    "    \n",
    "    Respond only with the final revised summary after all improvements are made. \n",
    "\n",
    "    Respond in the format '{format}' STRICTLY.\n",
    "    IF THE FORMAT IS 'plain_text', THEN RESPOND IN PLAIN TEXT ONLY, NOT MARKDOWN.\n",
    "    IF THE FORMAT IS 'markdown'. DIRECTLY GIVE THE MARKDOWN. DON'T WRAP IT IN ```markdown``` tags.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class SelfLearningSummarizer:\n",
    "    \"\"\"Queue-based Summarizer implementation\"\"\"\n",
    "\n",
    "    def __init__(self, model=\"gpt-4o-mini\"):\n",
    "        self.llm = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        self.model = model\n",
    "\n",
    "    def get_summary(self, source_text: str, format=\"plain_text\") -> str:\n",
    "        \"\"\"Generates a summary of the given text\"\"\"\n",
    "        try:\n",
    "            if format not in [\"plain_text\", \"markdown\"]:\n",
    "                raise ValueError(\"Invalid format. Use 'plain_text' or 'markdown'.\")\n",
    "            system = SIMPLE_SUMMARIZATION_SYSTEM_PROMPT\n",
    "            prompt = SIMPLE_SUMMARIZATION_PROMPT.format(text=source_text, format=format)\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system,\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ]\n",
    "            response = self.llm.chat.completions.create(\n",
    "                messages=messages, model=self.model\n",
    "            )\n",
    "            summary = response.choices[0].message.content\n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to generate summary for {item}\")\n",
    "            traceback.print_exc()\n",
    "            return \"\"\n",
    "\n",
    "    def iterative_refinement(\n",
    "        self, source_text: str, summary: str, turns=3, format=\"plain_text\"\n",
    "    ) -> str:\n",
    "        \"\"\"Iteratively refines the summary based on self-generated feedback for given turns.\"\"\"\n",
    "        session_id = str(uuid4())\n",
    "        print(f\"Iterative Refinement ({session_id}): Session ID: {session_id}\")\n",
    "        current_summary = summary\n",
    "        current_turn = 1\n",
    "        try:\n",
    "            while current_turn <= turns:\n",
    "                print(f\"Iterative Refinement ({session_id}): Turn {current_turn}.\")\n",
    "                system = ITERATIVE_REFINEMENT_SYSTEM_PROMPT\n",
    "                prompt = ITERATIVE_REFINEMENT_PROMPT.format(\n",
    "                    source_text=source_text, summary=current_summary, format=format\n",
    "                )\n",
    "                messages = [\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": system,\n",
    "                    },\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ]\n",
    "                llm_response = self.llm.chat.completions.create(\n",
    "                    messages=messages, model=self.model\n",
    "                )\n",
    "                current_summary = llm_response.choices[0].message.content\n",
    "                current_turn += 1\n",
    "                print(\n",
    "                    f\"Iterative Refinement ({session_id}): Turn {current_turn} completed. Updated rolling summary.\"\n",
    "                )\n",
    "            return current_summary\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"Iterative Refinement ({session_id}): Failed to complete all turns for {source_text} and {summary}.\"\n",
    "            )\n",
    "            print(\n",
    "                f\"Iterative Refinement ({session_id}): Turns completed: {current_turn}\"\n",
    "            )\n",
    "            traceback.print_exc()\n",
    "            return current_summary\n",
    "\n",
    "    def compare_summaries(self, source_text: str, summary1: str, summary2: str) -> str:\n",
    "        \"\"\"Compares two summaries and provides feedback on their quality.\"\"\"\n",
    "        try:\n",
    "            print(f\"Comparing summaries for {source_text}.\")\n",
    "            system = \"You are a Comparison AI specializing in evaluating text quality. Your task is to compare two summaries and provide feedback on their quality.\"\n",
    "            prompt = f\"\"\"\n",
    "            Compare the two summaries below and provide feedback on their quality. \n",
    "            Provide score comparison for both summaries, the old summary score and the new summary score.\n",
    "            This will help us compare the two summaries on various parameters.\n",
    "            Refer to the source text when making your evaluation. \\n\\n \n",
    "            Source Text: {source_text}\n",
    "            Initial Summary: {summary1} \n",
    "            Refined Summary: {summary2}\n",
    "            STRICTLY PROVIDE YOUR RESPONSE AS MARKDOWN TABLE WITH SCORES AND JUSTIFICATIONS.\n",
    "            \"\"\"\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system,\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ]\n",
    "            response = self.llm.chat.completions.create(\n",
    "                messages=messages, model=self.model\n",
    "            )\n",
    "            feedback = response.choices[0].message.content\n",
    "            return feedback\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to compare summaries for {source_text}\")\n",
    "            traceback.print_exc()\n",
    "            return \"\"\n",
    "\n",
    "    def get(self):\n",
    "        return self.q.get()\n",
    "\n",
    "    def empty(self):\n",
    "        return self.q.empty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: AI-Driven Text Summarization and Refinement System\n",
    "\n",
    "### Explanation of the Text Summarization System\n",
    "\n",
    "The code is a text summarization setup using OpenAI's GPT model to generate summaries. The system also includes functionality for refining summaries and comparing them iteratively. The code contains several core elements like:\n",
    "\n",
    "### 1. **SelfLearningSummarizer Class**\n",
    "\n",
    "- This class is the core of the summarization system. It interacts with OpenAI's GPT model to generate summaries, refine them, and compare the quality of different summaries.\n",
    "\n",
    "### 2. **Prompts for Summarization and Refinement**\n",
    "\n",
    "- The class uses predefined system prompts and user instructions to guide the summarization and refinement process. These prompts define how the AI should approach summarizing and improving text.\n",
    "\n",
    "### 3. **Method Breakdown**\n",
    "\n",
    "The methods in the SelfLearningSummarizer class are responsible for different stages of the summarization process.\n",
    "\n",
    "### **Explanation of the Core Functions**:\n",
    "\n",
    "#### 3.1 **Initialization (`__init__` method)**\n",
    "\n",
    "- The `SelfLearningSummarizer` class is initialized with a default model (`gpt-4o-mini`), but this can be changed by passing a different model during instantiation.\n",
    "- `self.llm` is set to the OpenAI API instance with the API key, allowing the summarizer to interact with OpenAI's models for generating summaries and refinements.\n",
    "\n",
    "#### 3.2 **`get_summary` Method**:\n",
    "\n",
    "- **Purpose**: This method is responsible for generating an initial summary of a given text.\n",
    "\n",
    "- **System Prompt**: This prompt instructs the model on how to approach the summarization. It defines the task in detail, such as understanding the text, extracting key themes, and generating a summary.\n",
    "\n",
    "- **User Prompt**: This prompt contains instructions for the model, specifying how to analyze and summarize the provided text. It also includes the format in which the summary should be returned (either plain_text or markdown).\n",
    "\n",
    "- The method sends these prompts to OpenAI's API using the `chat.completions.create` method and returns the generated summary.\n",
    "\n",
    "#### 3.3 **`iterative_refinement` Method**:\n",
    "\n",
    "- **Purpose**: This method refines the generated summary iteratively.\n",
    "\n",
    "- **Loop**: It loops through a set number of \"turns\" (iterations), where the summary is refined in each iteration based on feedback from the AI.\n",
    "\n",
    "- **System Prompt for Refinement**: This defines the role of the AI in each iteration, where it reviews the summary, looks for weaknesses, and refines it.\n",
    "\n",
    "- **Improvement Steps**: Each iteration involves an analysis of the current summary and making changes to improve clarity, coherence, and conciseness.\n",
    "\n",
    "- This process continues for the specified number of turns (turns=3 by default). The final refined summary is returned.\n",
    "\n",
    "#### 3.4 **`compare_summaries` Method**:\n",
    "\n",
    "- **Purpose**: This method compares two summaries (the original and the refined version) and provides feedback on their quality.\n",
    "\n",
    "- **System Prompt for Comparison**: This guides the AI in comparing the two summaries and scoring them based on various parameters, such as coherence, clarity, and factual accuracy.\n",
    "\n",
    "- **Output**: The AI produces a comparison between the two summaries in a markdown format, including scores and justifications for the differences.\n",
    "\n",
    "#### 3.5 **Using the Summarizer**:\n",
    "\n",
    "- You create an instance of the `SelfLearningSummarizer` class (`summarizer = SelfLearningSummarizer()`).\n",
    "\n",
    "- The `get_summary` method is used to generate a summary of the input text.\n",
    "\n",
    "- The `iterative_refinement` method is used to refine the summary iteratively.\n",
    "\n",
    "- Finally, the `compare_summaries` method can be used to compare the original and refined summaries.\n",
    "\n",
    "### **Example Use Case (Your Code)**:\n",
    "\n",
    "In the final part of your code:\n",
    "\n",
    "```python\n",
    "summarizer = SelfLearningSummarizer()\n",
    "\n",
    "text = \"\"\" ... \"\"\"  # Example text to be summarized\n",
    "format = \"plain_text\"\n",
    "\n",
    "summary = summarizer.get_summary(text, format=format)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the summary and test our prompts which seem to be solid.\n",
    "\n",
    "summarizer = SelfLearningSummarizer()\n",
    "\n",
    "# Credits: Arpit Bhayani\n",
    "# Post Link: https://www.linkedin.com/posts/arpitbhayani_asliengineering-careergrowth-activity-7280566114894430208-tjB2?utm_source=share&utm_medium=member_desktop\n",
    "\n",
    "text = \"\"\"\n",
    "When working on a new project, we engineers almost always start with the most fascinating part. But, while it's exciting for us, it's not always what's best for the project.\n",
    "\n",
    "The easiest way to become an effective lead/manager is to break down the project into tasks and prioritize the most important items. So, it is always a good idea that before the work begins, step back and ask\n",
    "\n",
    "1. what is the most critical piece?\n",
    "2. which items are highest risk and need early attention?\n",
    "3. which deliverables provide the most immediate value?\n",
    "\n",
    "We naturally gravitate towards easily doable, less impactful, and tangential parts of the project. This happens because of a lack of a broader context. So, if you are leading a project, make sure,\n",
    "\n",
    "1. define a clear roadmap and align it with business outcomes\n",
    "2. define milestones and priorities\n",
    "\n",
    "A good leader doesn‚Äôt micromanage but ensures that the team starts on the right foot. Check-in periodically to ensure the alignment while giving engineers ownership of their tasks.\n",
    "\n",
    "Prioritization is what separates effective leads from those simply managing tasks. As a lead, you are not just there to oversee execution but to set the direction.\n",
    "\"\"\"\n",
    "format = \"plain_text\"\n",
    "\n",
    "summary = summarizer.get_summary(text, format=format)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Text Summarization Process\n",
    "\n",
    "The code defines a process to summarize a given text using the `SelfLearningSummarizer` class. Here's a brief overview:\n",
    "\n",
    "### 1. **Text Input**\n",
    "\n",
    "- A block of text is provided, which discusses project management and leadership.\n",
    "\n",
    "### 2. **Summarization**\n",
    "\n",
    "- The `SelfLearningSummarizer` instance generates a summary of the text by interacting with the OpenAI model.\n",
    "- The summary is returned in plain text format.\n",
    "\n",
    "### 3. **Markdown Output**\n",
    "\n",
    "- The summary is formatted with a markdown header (`## Summary`) and displayed in a Jupyter notebook using IPython.display.\n",
    "\n",
    "### **Purpose of the Code**\n",
    "\n",
    "- The code automates text summarization and outputs the result in a formatted way suitable for displaying in interactive Python environments like Jupyter notebooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a markdown response now\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "summarizer = SelfLearningSummarizer()\n",
    "text = \"\"\"\n",
    "When working on a new project, we engineers almost always start with the most fascinating part. But, while it's exciting for us, it's not always what's best for the project.\n",
    "\n",
    "The easiest way to become an effective lead/manager is to break down the project into tasks and prioritize the most important items. So, it is always a good idea that before the work begins, step back and ask\n",
    "\n",
    "1. what is the most critical piece?\n",
    "2. which items are highest risk and need early attention?\n",
    "3. which deliverables provide the most immediate value?\n",
    "\n",
    "We naturally gravitate towards easily doable, less impactful, and tangential parts of the project. This happens because of a lack of a broader context. So, if you are leading a project, make sure,\n",
    "\n",
    "1. define a clear roadmap and align it with business outcomes\n",
    "2. define milestones and priorities\n",
    "\n",
    "A good leader doesn‚Äôt micromanage but ensures that the team starts on the right foot. Check-in periodically to ensure the alignment while giving engineers ownership of their tasks.\n",
    "\n",
    "Prioritization is what separates effective leads from those simply managing tasks. As a lead, you are not just there to oversee execution but to set the direction.\n",
    "\"\"\"\n",
    "format = \"plain_text\"\n",
    "\n",
    "summary = summarizer.get_summary(text, format=format)\n",
    "markdown_summary = Markdown(f\"## Summary\\n{summary}\")\n",
    "display(markdown_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Text Summarization and Iterative Refinement Process\n",
    "\n",
    "The code performs text summarization and iterative refinement:\n",
    "\n",
    "### 1. **Text Input**\n",
    "\n",
    "- A block of text related to project management is provided.\n",
    "\n",
    "### 2. **Initial Summary**\n",
    "\n",
    "- The `SelfLearningSummarizer` class generates an initial summary of the input text.\n",
    "\n",
    "### 3. **Iterative Refinement**\n",
    "\n",
    "- The summary is then refined over a specified number of turns (`turns=3`).\n",
    "- The `iterative_refinement` method is used to improve the summary by re-evaluating and enhancing it.\n",
    "\n",
    "### 4. **Markdown Output**\n",
    "\n",
    "- The final refined summary is displayed in a markdown format with a header that includes the number of refinement turns.\n",
    "\n",
    "### **Purpose of the Process**\n",
    "\n",
    "- This process helps in refining a summary iteratively to improve clarity, coherence, and accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = SelfLearningSummarizer()\n",
    "text = \"\"\"\n",
    "When working on a new project, we engineers almost always start with the most fascinating part. But, while it's exciting for us, it's not always what's best for the project.\n",
    "\n",
    "The easiest way to become an effective lead/manager is to break down the project into tasks and prioritize the most important items. So, it is always a good idea that before the work begins, step back and ask\n",
    "\n",
    "1. what is the most critical piece?\n",
    "2. which items are highest risk and need early attention?\n",
    "3. which deliverables provide the most immediate value?\n",
    "\n",
    "We naturally gravitate towards easily doable, less impactful, and tangential parts of the project. This happens because of a lack of a broader context. So, if you are leading a project, make sure,\n",
    "\n",
    "1. define a clear roadmap and align it with business outcomes\n",
    "2. define milestones and priorities\n",
    "\n",
    "A good leader doesn‚Äôt micromanage but ensures that the team starts on the right foot. Check-in periodically to ensure the alignment while giving engineers ownership of their tasks.\n",
    "\n",
    "Prioritization is what separates effective leads from those simply managing tasks. As a lead, you are not just there to oversee execution but to set the direction.\n",
    "\"\"\"\n",
    "format = \"plain_text\"\n",
    "turns = 3\n",
    "\n",
    "summary = summarizer.get_summary(text, format=format)\n",
    "\n",
    "refined_summary = summarizer.iterative_refinement(\n",
    "    text, summary, turns=turns, format=format\n",
    ")\n",
    "\n",
    "markdown_summary = Markdown(f\"## Refined Summary (turns={turns})\\n{refined_summary}\")\n",
    "\n",
    "display(markdown_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Text Summarization, Refinement, and Comparison Process\n",
    "\n",
    "The code performs the following steps:\n",
    "\n",
    "### 1. **Text Input**\n",
    "\n",
    "- A block of text explaining \"framework-defined infrastructure\" is provided.\n",
    "\n",
    "### 2. **Initial Summary**\n",
    "\n",
    "- The `SelfLearningSummarizer` class generates an initial summary of the input text.\n",
    "\n",
    "### 3. **Iterative Refinement**\n",
    "\n",
    "- The summary undergoes refinement over a specified number of turns (`turns=5`).\n",
    "- Each turn iteratively improves the summary for better clarity, conciseness, and readability.\n",
    "\n",
    "### 4. **Comparison**\n",
    "\n",
    "- The original and refined summaries are compared.\n",
    "- A detailed comparison, including feedback on quality and improvements, is generated.\n",
    "\n",
    "### 5. **Markdown Output**\n",
    "\n",
    "- The comparison is displayed in a markdown format for easy review.\n",
    "\n",
    "### **Purpose of the Process**\n",
    "\n",
    "- This helps track the progress of the summary improvement process and compare the quality of the initial and refined summaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, clear_output\n",
    "\n",
    "turns = 5\n",
    "text = \"\"\"\n",
    "What is framework-defined infrastructure?\n",
    "Framework-defined infrastructure abstracts over cloud primitives such as servers, message queues, and serverless functions, making them mere implementation details of the frameworks' concepts:\n",
    "\n",
    "Providing portability between different target infrastructure providers\n",
    "\n",
    "Eliminating the need to manually configure infrastructure to run an application in production\n",
    "\n",
    "Increasing the time spent writing product code over system management\n",
    "\n",
    "Allowing the unchanged use of the framework's native local development tools\n",
    "\n",
    "Standardizing on pre-reviewed secure services\n",
    "\n",
    "Frameworks use well-established patterns to provide structure and abstraction to applications, making them easier to write and understand. While the word framework is hard to define, the Hollywood principle, \"Don't call us, we call you,\" probably captures best the inversion of control, where the framework manages the high-level application flow while the developer writes code within the hooks provided by it.\n",
    "\n",
    "Framework-defined infrastructure takes advantage of both this inversion of control and the predictable structure of framework-based applications to automatically map framework concepts onto the appropriate infrastructure without the need for explicit declaration or configuration of the infrastructure.\n",
    "\n",
    "Note that this post is giving examples based on Vercel's Platform as a Service offering. The concept, however, can be applied more widely as the basic idea of understanding a framework, and generating IaC configuration for it, can also be used for more traditional infrastructure deployments.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "summarizer = SelfLearningSummarizer()\n",
    "summary = summarizer.get_summary(text, format=format)\n",
    "refined_summary = summarizer.iterative_refinement(\n",
    "    text, summary, turns=turns, format=format\n",
    ")\n",
    "comparison = summarizer.compare_summaries(text, summary, refined_summary)\n",
    "clear_output()\n",
    "markdown = Markdown(f\"## Comparison\\n{comparison}\")\n",
    "display(markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The application automates the process of summarizing complex text using OpenAI's language model, making it a valuable tool for quickly generating concise summaries. \n",
    "\n",
    "### Key Features:\n",
    "\n",
    "- **Initial Summarization**: The app generates an initial summary from a provided block of text, capturing key themes and important points.\n",
    "\n",
    "- **Iterative Refinement**: The summary is refined over multiple turns, improving clarity, coherence, and conciseness.\n",
    "\n",
    "- **Comparison of Summaries**: The original and refined summaries are compared, with feedback on quality and improvements.\n",
    "\n",
    "- **Markdown Output**: The final summaries and comparisons are displayed in an easily readable markdown format, suitable for presentation in Jupyter notebooks or other interactive Python environments.\n",
    "\n",
    "### Benefits:\n",
    "\n",
    "- **Efficiency**: Automates the summarization process, saving time and effort in distilling important information from lengthy text.\n",
    "\n",
    "- **Quality Control**: The iterative refinement process ensures the final summary is clear, accurate, and easy to understand.\n",
    "\n",
    "- **Customizable Output**: Users can choose to output summaries in plain text or markdown, making it versatile for different applications.\n",
    "\n",
    "This app is useful for anyone needing to process large volumes of text and produce succinct, high-quality summaries for analysis, presentation, or further processing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Thank You for visiting The Hackers Playbook! üåê\n",
    "\n",
    "If you liked this research material;\n",
    "\n",
    "- [Subscribe to our newsletter.](https://thehackersplaybook.substack.com)\n",
    "\n",
    "- [Follow us on LinkedIn.](https://www.linkedin.com/company/the-hackers-playbook/)\n",
    "\n",
    "- [Leave a star on our GitHub.](https://www.github.com/thehackersplaybook)\n",
    "\n",
    "<div style=\"display:flex; align-items:center; padding: 50px;\">\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"200px\" style=\"width:auto;\" width=\"200px\" src=\"https://avatars.githubusercontent.com/u/192148546?s=400&u=95d76fbb02e6c09671d87c9155f17ca1e4ef8f21&v=4\"> \n",
    "</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
