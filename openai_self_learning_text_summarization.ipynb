{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate: This block goes into every notebook.\n",
    "# It sets up the environment, installs the requirements, and checks for the required environment variables.\n",
    "\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "requirements_installed = False\n",
    "max_retries = 3\n",
    "retries = 0\n",
    "REQUIRED_ENV_VARS = [\"OPENAI_API_KEY\"]\n",
    "\n",
    "\n",
    "def install_requirements():\n",
    "    \"\"\"Installs the requirements from requirements.txt file\"\"\"\n",
    "    global requirements_installed\n",
    "    if requirements_installed:\n",
    "        print(\"Requirements already installed.\")\n",
    "        return\n",
    "\n",
    "    print(\"Installing requirements...\")\n",
    "    install_status = os.system(\"pip install -r requirements.txt\")\n",
    "    if install_status == 0:\n",
    "        print(\"Requirements installed successfully.\")\n",
    "        requirements_installed = True\n",
    "    else:\n",
    "        print(\"Failed to install requirements.\")\n",
    "        if retries < max_retries:\n",
    "            print(\"Retrying...\")\n",
    "            retries += 1\n",
    "            return install_requirements()\n",
    "        exit(1)\n",
    "    return\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "def setup_env():\n",
    "    \"\"\"Sets up the environment variables\"\"\"\n",
    "\n",
    "    def check_env(env_var):\n",
    "        value = os.getenv(env_var)\n",
    "        if value is None:\n",
    "            print(f\"Please set the {env_var} environment variable.\")\n",
    "            exit(1)\n",
    "        else:\n",
    "            print(f\"{env_var} is set.\")\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    variables_to_check = REQUIRED_ENV_VARS\n",
    "\n",
    "    for var in variables_to_check:\n",
    "        check_env(var)\n",
    "\n",
    "\n",
    "install_requirements()\n",
    "setup_env()\n",
    "clear_output()\n",
    "print(\"ðŸš€ Setup complete. Continue to the next cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from uuid import uuid4\n",
    "\n",
    "DEFAULT_OPENAI_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "SIMPLE_SUMMARIZATION_SYSTEM_PROMPT = \"\"\"\n",
    "    You are SummarizerGPT, an advanced AI system specialized in text summarization. Your core function is to process and analyze various types of text input, preparing the groundwork for generating high-quality summaries. Your capabilities include:\n",
    "\n",
    "    1. Text Analysis: Quickly assess the structure, style, and content of any given text.\n",
    "    2. Context Recognition: Identify the domain, target audience, and purpose of the text.\n",
    "    3. Language Processing: Understand and process text in multiple languages and dialects.\n",
    "    4. Semantic Comprehension: Grasp complex ideas, abstract concepts, and subtle nuances in the text.\n",
    "    5. Information Hierarchy: Recognize the relative importance of different pieces of information within the text.\n",
    "    6. Cross-referencing: Identify and connect related ideas across different parts of the text.\n",
    "    7. Bias Detection: Recognize potential biases or slants in the original text.\n",
    "    8. Data Extraction: Pull out key statistics, dates, names, and other crucial data points.\n",
    "    9. Tone Analysis: Understand the emotional tone and rhetorical style of the text.\n",
    "    10. Multi-format Handling: Process various text formats including plain text, HTML, PDF extracts, and more.\n",
    "\n",
    "    You do not generate the summary directly. Instead, you prepare a comprehensive analysis of the text, which will be used by the summarization module to create the final output. Your analysis should include:\n",
    "\n",
    "    - Text type and structure\n",
    "    - Main topic and key themes\n",
    "    - Target audience and purpose\n",
    "    - Important data points and statistics\n",
    "    - Identified biases or controversial points\n",
    "    - Tone and style characteristics\n",
    "    - Any unique or standout elements in the text\n",
    "\n",
    "    Await the input text, and be ready to provide this detailed analysis to support the summarization process.\n",
    "\"\"\"\n",
    "\n",
    "SIMPLE_SUMMARIZATION_PROMPT = \"\"\"\n",
    "    1. Analyze the input:\n",
    "    - Determine the text type (article, research paper, conversation, etc.)\n",
    "    - Identify the main topic and key themes\n",
    "    - Assess the length and complexity of the content\n",
    "\n",
    "    2. Generate the summary:\n",
    "    - Provide a concise yet informative summary\n",
    "    - Maintain the original tone and style where appropriate\n",
    "    - Ensure factual accuracy and avoid introducing new information\n",
    "    - Use clear, coherent language suitable for a general audience\n",
    "\n",
    "    3. Structure the summary:\n",
    "    - Begin with a brief overview of the main topic\n",
    "    - Organize key points logically, using paragraphs or bullet points as appropriate\n",
    "    - Conclude with the most significant takeaway or implication\n",
    "\n",
    "    4. Adapt to specific requirements:\n",
    "    - If a word/character limit is specified, adhere to it strictly\n",
    "    - If the text contains technical terms, provide brief explanations\n",
    "    - For multi-section documents, summarize each section separately, then provide an overall summary\n",
    "\n",
    "    5. Handle edge cases:\n",
    "    - For very short texts, provide a condensed version without losing essential information\n",
    "    - For extremely long or complex texts, focus on the most crucial points and indicate that it's a high-level summary\n",
    "    - If the text contains conflicting viewpoints, present them objectively without bias\n",
    "\n",
    "    6. Enhance readability:\n",
    "    - Use transition words to improve flow between ideas\n",
    "    - Employ varied sentence structures to maintain engagement\n",
    "    - Highlight key terms or concepts using bold text when appropriate\n",
    "\n",
    "    7. Quality check:\n",
    "    - Ensure the summary is self-contained and understandable without the original text\n",
    "    - Verify that no critical information is omitted\n",
    "    - Check for consistency in tense, voice, and perspective\n",
    "\n",
    "    8. Metadata (if applicable):\n",
    "    - Include the original title, author, and date of publication\n",
    "    - Mention the word count of the original text and the summary\n",
    "\n",
    "    Now, summarize the following text, adhering to the above guidelines.\n",
    "\n",
    "    Text: '{text}'\n",
    "    Respond in the format '{format}' STRICTLY.\n",
    "    IF THE FORMAT IS 'plain_text', THEN RESPOND IN PLAIN TEXT ONLY, NOT MARKDOWN.\n",
    "    IF THE FORMAT IS 'markdown'. DIRECTLY GIVE THE MARKDOWN. DON'T WRAP IT IN ```markdown``` tags.\n",
    "\"\"\"\n",
    "\n",
    "ITERATIVE_REFINEMENT_SYSTEM_PROMPT = \"\"\"\n",
    "    You are a Refinement AI specializing in improving text quality. Your task is to refine the given text based on the given instructions.\n",
    "\"\"\"\n",
    "ITERATIVE_REFINEMENT_PROMPT = \"\"\"\n",
    "   You are a Refinement AI specializing in improving text quality. Your task is to refine the given text in a single iteration. Follow these steps:\n",
    "\n",
    "    1. Analyze the input:\n",
    "    - Identify the source text and the summary\n",
    "    - Assess strengths and weaknesses in content, structure, and style of the summary \n",
    "\n",
    "    2. Prioritize improvements:\n",
    "    - Focus on 2-3 key areas that will have the most significant impact that could be made in the summary\n",
    "    - Consider clarity, coherence, conciseness, and effectiveness\n",
    "\n",
    "    3. Refine the text:\n",
    "    - Make targeted improvements in the summary based on your analysis\n",
    "    - Maintain the original intent and core message in the source text\n",
    "    - Ensure changes enhance overall quality without introducing new issues\n",
    "\n",
    "    4. Provide a summary of changes:\n",
    "    - Briefly explain the key modifications made in the revised summary \n",
    "    - Justify your refinement decisions with clear reasoning\n",
    "\n",
    "    5. Self-evaluate:\n",
    "    - Rate the improvement on a scale of 1-10\n",
    "    - Briefly explain your rating\n",
    "\n",
    "    Source Text: '{source_text}'\n",
    "\n",
    "    Summary to be refined: '{summary}'\n",
    "    \n",
    "    Respond only with the final revised summary after all improvements are made. \n",
    "\n",
    "    Respond in the format '{format}' STRICTLY.\n",
    "    IF THE FORMAT IS 'plain_text', THEN RESPOND IN PLAIN TEXT ONLY, NOT MARKDOWN.\n",
    "    IF THE FORMAT IS 'markdown'. DIRECTLY GIVE THE MARKDOWN. DON'T WRAP IT IN ```markdown``` tags.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class SelfLearningSummarizer:\n",
    "    \"\"\"Queue-based Summarizer implementation\"\"\"\n",
    "\n",
    "    def __init__(self, model=\"gpt-4o-mini\"):\n",
    "        self.llm = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        self.model = model\n",
    "\n",
    "    def get_summary(self, source_text: str, format=\"plain_text\") -> str:\n",
    "        \"\"\"Generates a summary of the given text\"\"\"\n",
    "        try:\n",
    "            if format not in [\"plain_text\", \"markdown\"]:\n",
    "                raise ValueError(\"Invalid format. Use 'plain_text' or 'markdown'.\")\n",
    "            system = SIMPLE_SUMMARIZATION_SYSTEM_PROMPT\n",
    "            prompt = SIMPLE_SUMMARIZATION_PROMPT.format(text=source_text, format=format)\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system,\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ]\n",
    "            response = self.llm.chat.completions.create(\n",
    "                messages=messages, model=self.model\n",
    "            )\n",
    "            summary = response.choices[0].message.content\n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to generate summary for {item}\")\n",
    "            traceback.print_exc()\n",
    "            return \"\"\n",
    "\n",
    "    def iterative_refinement(\n",
    "        self, source_text: str, summary: str, turns=3, format=\"plain_text\"\n",
    "    ) -> str:\n",
    "        \"\"\"Iteratively refines the summary based on self-generated feedback for given turns.\"\"\"\n",
    "        session_id = str(uuid4())\n",
    "        print(f\"Iterative Refinement ({session_id}): Session ID: {session_id}\")\n",
    "        current_summary = summary\n",
    "        current_turn = 1\n",
    "        try:\n",
    "            while current_turn <= turns:\n",
    "                print(f\"Iterative Refinement ({session_id}): Turn {current_turn}.\")\n",
    "                system = ITERATIVE_REFINEMENT_SYSTEM_PROMPT\n",
    "                prompt = ITERATIVE_REFINEMENT_PROMPT.format(\n",
    "                    source_text=source_text, summary=current_summary, format=format\n",
    "                )\n",
    "                messages = [\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": system,\n",
    "                    },\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ]\n",
    "                llm_response = self.llm.chat.completions.create(\n",
    "                    messages=messages, model=self.model\n",
    "                )\n",
    "                current_summary = llm_response.choices[0].message.content\n",
    "                current_turn += 1\n",
    "                print(\n",
    "                    f\"Iterative Refinement ({session_id}): Turn {current_turn} completed. Updated rolling summary.\"\n",
    "                )\n",
    "            return current_summary\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"Iterative Refinement ({session_id}): Failed to complete all turns for {source_text} and {summary}.\"\n",
    "            )\n",
    "            print(\n",
    "                f\"Iterative Refinement ({session_id}): Turns completed: {current_turn}\"\n",
    "            )\n",
    "            traceback.print_exc()\n",
    "            return current_summary\n",
    "\n",
    "    def compare_summaries(self, source_text: str, summary1: str, summary2: str) -> str:\n",
    "        \"\"\"Compares two summaries and provides feedback on their quality.\"\"\"\n",
    "        try:\n",
    "            print(f\"Comparing summaries for {source_text}.\")\n",
    "            system = \"You are a Comparison AI specializing in evaluating text quality. Your task is to compare two summaries and provide feedback on their quality.\"\n",
    "            prompt = f\"\"\"\n",
    "            Compare the two summaries below and provide feedback on their quality. \n",
    "            Provide score comparison for both summaries, the old summary score and the new summary score.\n",
    "            This will help us compare the two summaries on various parameters.\n",
    "            Refer to the source text when making your evaluation. \\n\\n \n",
    "            Source Text: {source_text}\n",
    "            Initial Summary: {summary1} \n",
    "            Refined Summary: {summary2}\n",
    "            STRICTLY PROVIDE YOUR RESPONSE AS MARKDOWN TABLE WITH SCORES AND JUSTIFICATIONS.\n",
    "            \"\"\"\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system,\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ]\n",
    "            response = self.llm.chat.completions.create(\n",
    "                messages=messages, model=self.model\n",
    "            )\n",
    "            feedback = response.choices[0].message.content\n",
    "            return feedback\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to compare summaries for {source_text}\")\n",
    "            traceback.print_exc()\n",
    "            return \"\"\n",
    "\n",
    "    def get(self):\n",
    "        return self.q.get()\n",
    "\n",
    "    def empty(self):\n",
    "        return self.q.empty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the summary and test our prompts which seem to be solid.\n",
    "\n",
    "summarizer = SelfLearningSummarizer()\n",
    "\n",
    "# Credits: Arpit Bhayani\n",
    "# Post Link: https://www.linkedin.com/posts/arpitbhayani_asliengineering-careergrowth-activity-7280566114894430208-tjB2?utm_source=share&utm_medium=member_desktop\n",
    "\n",
    "text = \"\"\"\n",
    "When working on a new project, we engineers almost always start with the most fascinating part. But, while it's exciting for us, it's not always what's best for the project.\n",
    "\n",
    "The easiest way to become an effective lead/manager is to break down the project into tasks and prioritize the most important items. So, it is always a good idea that before the work begins, step back and ask\n",
    "\n",
    "1. what is the most critical piece?\n",
    "2. which items are highest risk and need early attention?\n",
    "3. which deliverables provide the most immediate value?\n",
    "\n",
    "We naturally gravitate towards easily doable, less impactful, and tangential parts of the project. This happens because of a lack of a broader context. So, if you are leading a project, make sure,\n",
    "\n",
    "1. define a clear roadmap and align it with business outcomes\n",
    "2. define milestones and priorities\n",
    "\n",
    "A good leader doesnâ€™t micromanage but ensures that the team starts on the right foot. Check-in periodically to ensure the alignment while giving engineers ownership of their tasks.\n",
    "\n",
    "Prioritization is what separates effective leads from those simply managing tasks. As a lead, you are not just there to oversee execution but to set the direction.\n",
    "\"\"\"\n",
    "format = \"plain_text\"\n",
    "\n",
    "summary = summarizer.get_summary(text, format=format)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a markdown response now\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "summarizer = SelfLearningSummarizer()\n",
    "format = \"markdown\"\n",
    "\n",
    "summary = summarizer.get_summary(text, format=format)\n",
    "markdown_summary = Markdown(f\"## Summary\\n{summary}\")\n",
    "display(markdown_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turns = 3\n",
    "summarizer = SelfLearningSummarizer()\n",
    "\n",
    "summary = summarizer.get_summary(text, format=format)\n",
    "\n",
    "refined_summary = summarizer.iterative_refinement(\n",
    "    text, summary, turns=turns, format=format\n",
    ")\n",
    "\n",
    "markdown_summary = Markdown(f\"## Refined Summary (turns={turns})\\n{refined_summary}\")\n",
    "\n",
    "display(markdown_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, clear_output\n",
    "\n",
    "summarizer = SelfLearningSummarizer()\n",
    "comparison = summarizer.compare_summaries(text, summary, refined_summary)\n",
    "clear_output()\n",
    "markdown = Markdown(f\"## Comparison\\n{comparison}\")\n",
    "display(markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
