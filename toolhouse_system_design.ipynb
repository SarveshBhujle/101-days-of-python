{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toolhouse and OpenAI Integration for System Design and Reporting\n",
    "\n",
    "<div style=\"display:flex; align-items:center; padding: 50px;\">\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"200px\" style=\"width:auto;\" width=\"200px\" src=\"https://avatars.githubusercontent.com/u/192148546?s=400&u=95d76fbb02e6c09671d87c9155f17ca1e4ef8f21&v=4\"> \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "## Description:\n",
    "\n",
    "This app demonstrates the integration of OpenAI's language models with Toolhouse's system design and utility tools. It generates detailed reports, executes commands, and emails results based on user inputs, specifically focusing on system design topics. The app is designed for use in Jupyter notebooks, automating tasks like generating code, system design documentation, and sending email reports. It is highly customizable and uses environment variables for secure API key management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Installing Python Dependencies\n",
    "\n",
    "This code sets up the environment for a Jupyter notebook:\n",
    "\n",
    "- `Install Requirements`: The install_requirements() function checks if the required dependencies from requirements.txt are installed. If not, it installs them and retries up to three times if the installation fails.\n",
    "\n",
    "- `Environment Setup`: The setup_env() function loads environment variables from a .env file using load_dotenv(). It checks if essential environment variables (like OPENAI_API_KEY and TOOLHOUSE_API_KEY) are set and exits if any are missing.\n",
    "\n",
    "- `Final Setup` : Once the requirements are installed and environment variables are validated, the setup is marked complete with a success message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate: This block goes into every notebook.\n",
    "# It sets up the environment, installs the requirements, and checks for the required environment variables.\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "requirements_installed = False\n",
    "max_retries = 3\n",
    "retries = 0\n",
    "REQUIRED_ENV_VARS = [\"OPENAI_API_KEY\", \"TOOLHOUSE_API_KEY\"]\n",
    "\n",
    "\n",
    "def install_requirements():\n",
    "    \"\"\"Installs the requirements from requirements.txt file\"\"\"\n",
    "    global requirements_installed\n",
    "    if requirements_installed:\n",
    "        print(\"Requirements already installed.\")\n",
    "        return\n",
    "\n",
    "    print(\"Installing requirements...\")\n",
    "    install_status = os.system(\"pip install -r requirements.txt\")\n",
    "    if install_status == 0:\n",
    "        print(\"Requirements installed successfully.\")\n",
    "        requirements_installed = True\n",
    "    else:\n",
    "        print(\"Failed to install requirements.\")\n",
    "        if retries < max_retries:\n",
    "            print(\"Retrying...\")\n",
    "            retries += 1\n",
    "            return install_requirements()\n",
    "        exit(1)\n",
    "    return\n",
    "\n",
    "\n",
    "def setup_env():\n",
    "    \"\"\"Sets up the environment variables\"\"\"\n",
    "\n",
    "    def check_env(env_var):\n",
    "        value = os.getenv(env_var)\n",
    "        if value is None:\n",
    "            print(f\"Please set the {env_var} environment variable.\")\n",
    "            exit(1)\n",
    "        else:\n",
    "            print(f\"{env_var} is set.\")\n",
    "\n",
    "    load_dotenv(override=True)\n",
    "\n",
    "    variables_to_check = REQUIRED_ENV_VARS\n",
    "\n",
    "    for var in variables_to_check:\n",
    "        check_env(var)\n",
    "\n",
    "\n",
    "install_requirements()\n",
    "clear_output()\n",
    "setup_env()\n",
    "print(\"🚀 Setup complete. Continue to the next cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Setting Up OpenAI and Toolhouse Integration\n",
    "\n",
    "This script integrates OpenAI with Toolhouse to generate code based on user input, executes it dynamically, and displays the results, enabling seamless interaction between code generation and execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example: Just a basic use of Toolhouse x OpenAI\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from toolhouse import Toolhouse\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TOOLHOUSE_API_KEY = os.getenv(\"TOOLHOUSE_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "th = Toolhouse(api_key=TOOLHOUSE_API_KEY, provider=\"openai\")\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Generate FizzBuzz code.\"\n",
    "        \"Execute it to show me the results up to 10.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL, messages=messages, tools=th.get_tools()\n",
    ")\n",
    "\n",
    "messages += th.run_tools(response)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL, messages=messages, tools=th.get_tools()\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Integration of OpenAI with Toolhouse for System Design\n",
    "\n",
    "This code integrates OpenAI’s language model with Toolhouse’s system design tools, enabling iterative refinement of system design tasks through the `llm` function, which dynamically utilizes both platforms for enhanced efficiency and accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example: LLM with Toolhouse\n",
    "## Include the following tools in the Toolhouse bundle: thp-system-design-assistant\n",
    "## Sendgrid, Web Scraper, and Memory tools are included in this bundle.\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from toolhouse import Toolhouse\n",
    "import traceback\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TOOLHOUSE_API_KEY = os.getenv(\"TOOLHOUSE_API_KEY\")\n",
    "MAX_ITERS = 10\n",
    "th = Toolhouse(api_key=TOOLHOUSE_API_KEY, provider=\"openai\")\n",
    "openai = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "\n",
    "def llm(\n",
    "    prompt: str,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    system=\"You are a helpful AI assistant\",\n",
    "    intermediate_output=True,\n",
    "    verbose=True,\n",
    ") -> str:\n",
    "    \"\"\"Wrapper over Open AI LLM calls with Toolhouse Tools.\"\"\"\n",
    "    try:\n",
    "        if verbose:\n",
    "            print(\"System: \", system)\n",
    "            print(\"Prompt: \", prompt)\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "        response = openai.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=th.get_tools(\"thp-system-design-assistant\"),\n",
    "        )\n",
    "\n",
    "        tool_calls = response.choices[0].message.tool_calls\n",
    "        iters = 0\n",
    "        content = response.choices[0].message.content\n",
    "\n",
    "        while tool_calls and len(tool_calls) > 0 and iters < MAX_ITERS:\n",
    "            if verbose or intermediate_output:\n",
    "                if content:\n",
    "                    print(f\"Cycle {iters}: \", content)\n",
    "                else:\n",
    "                    print(f\"Cycle {iters}: No content.\")\n",
    "            messages += th.run_tools(response)\n",
    "            response = openai.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                tools=th.get_tools(\"thp-system-design-assistant\"),\n",
    "            )\n",
    "            if verbose or intermediate_output:\n",
    "                print(f\"Generated intermediate response...\")\n",
    "            content = response.choices[0].message.content\n",
    "            iters += 1\n",
    "            tool_calls = response.choices[0].message.tool_calls\n",
    "\n",
    "        if content and (verbose or intermediate_output):\n",
    "            print(f\"Final response: {content}\")\n",
    "\n",
    "        return content\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        return \"Sorry, failed to generate response.\\nError: \" + str(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: System Design Report Generation on \"Bloom Filters\" with OpenAI and Toolhouse\n",
    "\n",
    "The process starts with selecting the topic \"Bloom Filters\" and setting up system and prompt messages for the AI to follow. The AI, acting as a system design assistant, generates a comprehensive report on Bloom Filters, including use cases, advantages, and examples. After generating the markdown report, it is converted to HTML, and the email is sent via Toolhouse's SendGrid integration. The entire process is iterative, refining the report with multiple API calls until the content is polished and ready for delivery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing simple 'System Design' report emailer use case\n",
    "\n",
    "topic = \"Bloom Filters\"\n",
    "email = \"contact.adityapatange@gmail.com\"\n",
    "model = \"gpt-4o\"\n",
    "\n",
    "system = f\"\"\"\n",
    "    You are THP System Design AI.\n",
    "    An intelligent assistant that helps you understand system design concepts.\n",
    "    You will provide detailed explanations of the topics you are asked to research.\n",
    "    I will tell you the various things to research. \n",
    "    You will generate a detailed markdown report on the topic.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "    Provide a detailed explanation of {topic}.\n",
    "    Include the following points:\n",
    "    - What is {topic}?\n",
    "    - How does '{topic}' work?\n",
    "    - What are the use cases of '{topic}'?\n",
    "    - Advantages and disadvantages of '{topic}'. (If applicable)\n",
    "    - Industry examples of {topic}. \n",
    "\n",
    "    INSTRUCTIONS:\n",
    "    - Generate a detailed markdown report on {topic}.\n",
    "    This is for study purposes, so please provide a detailed explanation.\n",
    "    - Generated a nicely formatted HTML email on your research with title 'The Hackers Playbook System Design: Case Studies on {topic}'.\n",
    "    - Send the email to {email}\n",
    "\"\"\"\n",
    "\n",
    "response = llm(\n",
    "    prompt, model=model, system=system, intermediate_output=True, verbose=True\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This app serves as a powerful tool for automating **system design research** and **report generation** by leveraging OpenAI’s language model and Toolhouse’s suite of tools. With capabilities like **GPT-4 integration** and **email delivery through SendGrid**, the app efficiently generates detailed and structured reports on complex topics, such as **Bloom Filters**, and sends them directly to the user’s email.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Strengths of the App:\n",
    "\n",
    "1. **Seamless Integration:**  \n",
    "\n",
    "   Combines the power of OpenAI and Toolhouse to create a robust environment for automated research and report delivery.\n",
    "\n",
    "2. **Customizable Functionality:**  \n",
    "\n",
    "   Users can easily modify the topic or focus area, enabling **flexible, on-demand research generation** tailored to specific needs.\n",
    "\n",
    "3. **Automated Workflow:**  \n",
    "\n",
    "   From generating detailed markdown reports to delivering formatted HTML emails, the app automates the entire process, saving time and effort.\n",
    "\n",
    "4. **Iterative Process:**  \n",
    "\n",
    "   Supports iterative tool calls to refine content until it meets the desired quality and level of detail.\n",
    "\n",
    "5. **Practical Use Cases:**  \n",
    "\n",
    "   Perfect for students, professionals, or teams involved in system design. It is useful for:\n",
    "\n",
    "   - Studying and exploring new concepts.\n",
    "   - Researching detailed system design topics.\n",
    "   - Generating professional reports with easy email sharing.\n",
    "\n",
    "\n",
    "\n",
    "### Final Thoughts:\n",
    "\n",
    "With its **flexibility**, **ease of use**, and **ability to deliver tailored insights**, this app is an invaluable resource for anyone looking to **explore or present system design concepts** in a structured, professional manner. It not only accelerates learning but also simplifies **knowledge sharing**, making it an efficient tool for study, research, and professional collaboration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Thank You for visiting The Hackers Playbook! 🌐\n",
    "\n",
    "If you liked this research material;\n",
    "\n",
    "- [Subscribe to our newsletter.](https://thehackersplaybook.substack.com)\n",
    "\n",
    "- [Follow us on LinkedIn.](https://www.linkedin.com/company/the-hackers-playbook/)\n",
    "\n",
    "- [Leave a star on our GitHub.](https://www.github.com/thehackersplaybook)\n",
    "\n",
    "<div style=\"display:flex; align-items:center; padding: 50px;\">\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"200px\" style=\"width:auto;\" width=\"200px\" src=\"https://avatars.githubusercontent.com/u/192148546?s=400&u=95d76fbb02e6c09671d87c9155f17ca1e4ef8f21&v=4\"> \n",
    "</p>\n",
    "</div>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
