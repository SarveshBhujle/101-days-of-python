{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phi4 Tool: Advanced Query and Data Processing Utility\n",
    "\n",
    "<div style=\"display:flex; align-items:center; padding: 50px;\">\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"200px\" style=\"width:auto;\" width=\"200px\" src=\"https://avatars.githubusercontent.com/u/192148546?s=400&u=95d76fbb02e6c09671d87c9155f17ca1e4ef8f21&v=4\"> \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "## Description\n",
    "\n",
    "The Phi4 Tool is a powerful application designed for advanced query processing, designed to handle complex data interactions with precision and efficiency. Using sophisticated validation and dynamic query handling methods, it simplifies the management of user requests and external system integrations. Ideal for developers and businesses looking to optimize workflow automation and data processing, Phi4 Tool enhances accuracy and scalability while reducing the potential for errors in high-demand environments. This versatile tool integrates seamlessly into various systems to streamline operations and improve overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Boilerplate Setup\n",
    "\n",
    "This step sets up the boilerplate code for the project. It includes:\n",
    "\n",
    "- ### Import Statements:\n",
    "\n",
    "    - `os`: Used for running shell commands and accessing environment variables.\n",
    "\n",
    "    - `load_dotenv`: Loads environment variables from a `.env` file into the system for easy configuration.\n",
    "\n",
    "    - `clear_output`: Clears the notebook's output to keep it clean after successful setup.\n",
    "\n",
    "\n",
    "\n",
    "- ### Global Variables:\n",
    "\n",
    "    - `requirements_installed`: Tracks whether dependencies are already installed.\n",
    "    \n",
    "    - `max_retries`: Limits how many times the code will retry installing dependencies in case of failure.\n",
    "    \n",
    "    - `REQUIRED_ENV_VARS`: Specifies the environment variables that must be present.\n",
    "\n",
    "\n",
    "\n",
    "- ### `install_requirements` Function:\n",
    "\n",
    "    - Uses the `os.system` command to run `pip install -r requirements.txt`.\n",
    "\n",
    "    - If the installation fails, it retries up to `max_retries`.\n",
    "\n",
    "    - If retries are exhausted, it exits the program with a failure code.\n",
    "\n",
    "\n",
    "\n",
    "- ### `setup_env` Function:\n",
    "\n",
    "    - Loads environment variables from `.env`.\n",
    "\n",
    "    - Verifies the presence of each required variable using the `check_env` function.\n",
    "\n",
    "    - Exits the program if any required environment variable is missing.\n",
    "\n",
    "\n",
    "\n",
    "- ### Execution:\n",
    "\n",
    "    - Calls `install_requirements` to install dependencies.\n",
    "\n",
    "    - Calls `setup_env` to validate the environment.\n",
    "\n",
    "    - Clears the output and confirms the setup is complete.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate: This block goes into every notebook.\n",
    "# It sets up the environment, installs the requirements, and checks for the required environment variables.\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "requirements_installed = False\n",
    "max_retries = 3\n",
    "retries = 0\n",
    "REQUIRED_ENV_VARS = [\"OPENAI_API_KEY\"]\n",
    "\n",
    "\n",
    "def install_requirements():\n",
    "    \"\"\"Installs the requirements from requirements.txt file\"\"\"\n",
    "    global requirements_installed\n",
    "    if requirements_installed:\n",
    "        print(\"Requirements already installed.\")\n",
    "        return\n",
    "\n",
    "    print(\"Installing requirements...\")\n",
    "    install_status = os.system(\"pip install -r requirements.txt\")\n",
    "    if install_status == 0:\n",
    "        print(\"Requirements installed successfully.\")\n",
    "        requirements_installed = True\n",
    "    else:\n",
    "        print(\"Failed to install requirements.\")\n",
    "        if retries < max_retries:\n",
    "            print(\"Retrying...\")\n",
    "            retries += 1\n",
    "            return install_requirements()\n",
    "        exit(1)\n",
    "    return\n",
    "\n",
    "\n",
    "def setup_env():\n",
    "    \"\"\"Sets up the environment variables\"\"\"\n",
    "\n",
    "    def check_env(env_var):\n",
    "        value = os.getenv(env_var)\n",
    "        if value is None:\n",
    "            print(f\"Please set the {env_var} environment variable.\")\n",
    "            exit(1)\n",
    "        else:\n",
    "            print(f\"{env_var} is set.\")\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    variables_to_check = REQUIRED_ENV_VARS\n",
    "\n",
    "    for var in variables_to_check:\n",
    "        check_env(var)\n",
    "\n",
    "\n",
    "install_requirements()\n",
    "clear_output()\n",
    "setup_env()\n",
    "print(\"🚀 Setup complete. Continue to the next cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Imports and Default Constants  \n",
    "\n",
    "### **Imports**  \n",
    "\n",
    "- **`from typing import Union`**  \n",
    "  - Used to define type hints for variables or return values that can take on multiple types (e.g., `Union[BaseModel, None]`).  \n",
    "\n",
    "- **`from pydantic import BaseModel`**  \n",
    "  - Imports `BaseModel` from Pydantic, which is used to define and validate data models.  \n",
    "\n",
    "- **`import json`**  \n",
    "  - Provides utilities for working with JSON data, such as parsing and formatting.  \n",
    "\n",
    "- **`import traceback`**  \n",
    "  - Enables the capturing and printing of detailed stack traces in case of exceptions.  \n",
    "\n",
    "- **`import ollama`**  \n",
    "  - Presumably the library for interacting with the Ollama API, which facilitates communication with a language model.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Default Configuration Variables**  \n",
    "\n",
    "- **`DEFAULT_SYSTEM_PROMPT`**  \n",
    "  - The system's default instruction for the assistant:  \n",
    "    `\"You are an intelligent assistant. You are helping the user with their query.\"`  \n",
    "\n",
    "- **`DEFAULT_TEMPERATURE`**  \n",
    "  - Sets the randomness level of the language model’s output. A value of `0.5` balances creativity and determinism.  \n",
    "\n",
    "- **`DEFAULT_MAX_TOKENS`**  \n",
    "  - Restricts the maximum number of tokens (words/pieces) in the model's response.  \n",
    "\n",
    "- **`DEFAULT_OLLAMA_MODEL`**  \n",
    "  - Specifies the model to use, here set to `\"phi4\"`.  \n",
    "\n",
    "- **`DEFAULT_VERBOSE`** and **`DEFAULT_DEBUG`**  \n",
    "  - Flags to control the verbosity (`True`) and debugging behavior (`True`) of the function.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Function: build_dummy_pydantic_object**  \n",
    "\n",
    "#### **Function Definition**  \n",
    "- **Purpose**: Creates a \"dummy\" instance of the given Pydantic schema to understand its structure.  \n",
    "\n",
    "- **`return schema()`**  \n",
    "  - Initializes and returns an instance of the provided Pydantic schema. Useful for extracting the schema structure without requiring input data.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Function: generate_object**  \n",
    "\n",
    "#### **Function Definition**  \n",
    "- **Purpose**: Accepts parameters like `prompt`, `response_model`, and configurations for system behavior, such as temperature and verbosity.  \n",
    "\n",
    "- **`if verbose or debug:`**  \n",
    "  - Logs the prompt for transparency if verbosity or debugging is enabled.  \n",
    "\n",
    "- **`prompt_with_structured_output`**  \n",
    "  - A formatted string containing the:  \n",
    "    1. User prompt.  \n",
    "    2. JSON representation of the expected response schema (from `build_dummy_pydantic_object`).  \n",
    "    3. Instructions for the assistant to strictly adhere to the schema and JSON format.  \n",
    "\n",
    "#### **Debug Block**  \n",
    "- Logs detailed parameter configurations (`params`) when debugging is enabled.  \n",
    "\n",
    "#### **`response = ollama.chat(...)`**  \n",
    "- Sends the request to the Ollama API with:  \n",
    "  1. The model to use.  \n",
    "  2. The messages to structure the conversation (e.g., system and user prompts).  \n",
    "  3. The format (`json`) for the expected response.  \n",
    "\n",
    "#### **`response.message.content`**  \n",
    "- Extracts the JSON content from the response.  \n",
    "\n",
    "#### **Logging**  \n",
    "- Logs the response received from the API for debugging or verbose output.  \n",
    "\n",
    "#### **`json.loads(response_json)`**  \n",
    "- Parses the JSON string (`response_json`) into a Python dictionary.  \n",
    "\n",
    "#### **`response_model.model_validate(response_obj)`**  \n",
    "- Validates the parsed JSON dictionary (`response_obj`) against the provided Pydantic response model.  \n",
    "\n",
    "#### **Final Logs**  \n",
    "- Logs the successful creation of the structured object, or detailed debugging information if enabled.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Exception Handling**  \n",
    "\n",
    "- **`except Exception as e:`**  \n",
    "  - Captures any errors that occur during object generation.  \n",
    "\n",
    "- **`traceback.print_exc()`**  \n",
    "  - Prints the full stack trace for debugging purposes if an exception occurs.  \n",
    "\n",
    "- **`return None`**  \n",
    "  - Ensures the function returns `None` in case of failure, providing a predictable return type.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ollama: Generate Object\n",
    "\n",
    "from typing import Union\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "import traceback\n",
    "import ollama\n",
    "\n",
    "DEFAULT_SYSTEM_PROMPT = (\n",
    "    \"You are an intelligent assistant. You are helping the user with their query.\"\n",
    ")\n",
    "DEFAULT_TEMPERATURE = 0.5\n",
    "DEFAULT_MAX_TOKENS = 100\n",
    "DEFAULT_OLLAMA_MODEL = \"phi4\"\n",
    "DEFAULT_VERBOSE = True\n",
    "DEFAULT_DEBUG = True\n",
    "\n",
    "\n",
    "def build_dummy_pydantic_object(schema: BaseModel) -> BaseModel:\n",
    "    \"\"\"\n",
    "    Build a dummy Pydantic object using the given schema.\n",
    "\n",
    "    Args:\n",
    "      schema: The Pydantic schema to build the object from\n",
    "\n",
    "    Returns:\n",
    "      BaseModel: The dummy Pydantic object\n",
    "    \"\"\"\n",
    "    return schema()\n",
    "\n",
    "\n",
    "def generate_object(\n",
    "    prompt: str,\n",
    "    response_model: BaseModel,\n",
    "    system=DEFAULT_SYSTEM_PROMPT,\n",
    "    model=DEFAULT_OLLAMA_MODEL,\n",
    "    temperature=DEFAULT_TEMPERATURE,\n",
    "    max_tokens=DEFAULT_MAX_TOKENS,\n",
    "    debug=DEFAULT_DEBUG,\n",
    "    verbose=DEFAULT_VERBOSE,\n",
    ") -> Union[BaseModel, None]:\n",
    "    \"\"\"Generates an object using the OpenAI API and given response model.\"\"\"\n",
    "    try:\n",
    "        if verbose or debug:\n",
    "            print(f\"Generating object for prompt: {prompt}\")\n",
    "\n",
    "        prompt_with_structured_output = f\"\"\"\n",
    "            Prompt: {prompt} \n",
    "            SCHEMA: {build_dummy_pydantic_object(response_model).model_dump_json()}\n",
    "\n",
    "            INSTRUCTIONS: \n",
    "            - RESPOND IN JSON FORMAT. \n",
    "            - STRICTLY FOLLOW THE SCHEMA.\n",
    "            - MAKE SURE TO INCLUDE ALL THE REQUIRED FIELDS.\n",
    "            - DON'T INCLUDE ANY ADDITIONAL FIELDS.\n",
    "            - INCASE YOU DON'T HAVE AN ANSWER FOR A FIELD, LEAVE IT EMPTY.\n",
    "        \"\"\"\n",
    "\n",
    "        if debug:\n",
    "            params = {\n",
    "                \"prompt\": prompt_with_structured_output,\n",
    "                \"system\": system,\n",
    "                \"temperature\": temperature,\n",
    "                \"max_tokens\": max_tokens,\n",
    "                \"model\": model,\n",
    "            }\n",
    "            params = json.dumps(params, indent=2)\n",
    "            print(f\"Params: {params}\")\n",
    "\n",
    "        response = ollama.chat(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system},\n",
    "                {\"role\": \"user\", \"content\": prompt_with_structured_output},\n",
    "            ],\n",
    "            format=\"json\",\n",
    "        )\n",
    "\n",
    "        response_json = response.message.content  # Get the response content\n",
    "\n",
    "        if verbose or debug:\n",
    "            print(f\"{model}: Response received successfully. 🎉\")\n",
    "            print(f\"Response: {response_json}\")\n",
    "\n",
    "        response_obj = json.loads(response_json)\n",
    "        response_structured = response_model.model_validate(response_obj)\n",
    "\n",
    "        if verbose or debug:\n",
    "            print(\"Object generated successfully. 🎉\")\n",
    "\n",
    "        if debug:\n",
    "            print(f\"EasyLLM Response: {response_json}\")\n",
    "        return response_structured\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to generate object. Error: {str(e)}\")\n",
    "        if debug:\n",
    "            traceback.print_exc()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate and Validate Random Movie Data\n",
    "\n",
    "### Import the Required Module  \n",
    "\n",
    "#### **`from pydantic import BaseModel`**  \n",
    "\n",
    "- Imports the `BaseModel` class from the **Pydantic** library.  \n",
    "\n",
    "- Used to define and validate structured data models in Python.  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Define the Movie Model  \n",
    "\n",
    "#### **Class Definition**  \n",
    "\n",
    "**`class Movie(BaseModel):`**  \n",
    "\n",
    "- Creates a new Pydantic model named **`Movie`**.  \n",
    "\n",
    "- Represents the structure of a movie object with specific attributes and default values.  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Model Fields**  \n",
    "\n",
    "1. **`title: str = \"Movie name\"`**  \n",
    "   - Field named **`title`** of type `str`.  \n",
    "   - **Default Value**: `\"Movie name\"`.  \n",
    "   - Represents the **movie's title**.  \n",
    "\n",
    "2. **`year: int = 0`**  \n",
    "   - Field named **`year`** of type `int`.  \n",
    "   - **Default Value**: `0`.  \n",
    "   - Represents the **release year** of the movie.  \n",
    "\n",
    "3. **`genre: str = \"movie genre\"`**  \n",
    "   - Field named **`genre`** of type `str`.  \n",
    "   - **Default Value**: `\"movie genre\"`.  \n",
    "   - Represents the **genre** of the movie.  \n",
    "\n",
    "4. **`director: str = \"movie director\"`**  \n",
    "   - Field named **`director`** of type `str`.  \n",
    "   - **Default Value**: `\"movie director\"`.  \n",
    "   - Represents the **director** of the movie.  \n",
    "\n",
    "5. **`rating: float = 0.0`**  \n",
    "   - Field named **`rating`** of type `float`.  \n",
    "   - **Default Value**: `0.0`.  \n",
    "   - Represents the **rating** of the movie.  \n",
    "\n",
    "---\n",
    "\n",
    "### Generate a Movie Object  \n",
    "\n",
    "#### **Code Snippet**  \n",
    "**`response = generate_object(...)`**  \n",
    "\n",
    "- Calls the **`generate_object`** function to create a random movie object based on the **`Movie`** model schema.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **Arguments Passed**  \n",
    "\n",
    "1. **`prompt=\"Generate a random movie\"`**  \n",
    "   - Instructs the AI to generate a **random movie**.  \n",
    "\n",
    "2. **`response_model=Movie`**  \n",
    "   - Specifies the **`Movie`** schema to validate and structure the output.  \n",
    "\n",
    "3. **`verbose=False`**  \n",
    "   - Disables **verbose logging** to reduce output noise.  \n",
    "\n",
    "4. **`debug=False`**  \n",
    "   - Disables **debug information** for a cleaner console output.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **Function Details**  \n",
    "- Interacts with an AI model via the **`ollama`** library.  \n",
    "\n",
    "- Uses the **prompt** and schema to generate a structured movie object.  \n",
    "\n",
    "- Ensures the result adheres to the **`Movie`** schema.  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Print the Generated Movie Object  \n",
    "\n",
    "#### **Code Snippet**  \n",
    "\n",
    "**`print(response.model_dump_json())`**  \n",
    "\n",
    "- Calls the **`model_dump_json()`** method on the **response** object.  \n",
    "\n",
    "- Converts the Pydantic **`BaseModel`** instance into a **JSON-formatted string**.  \n",
    "\n",
    "- Outputs the JSON string to the console for:  \n",
    "\n",
    "  - **Readability**.  \n",
    "\n",
    "  - **Usability** in other applications or systems.  \n",
    "\n",
    "---\n",
    "\n",
    "### Summary  \n",
    "\n",
    "1. **Structured Schema**  \n",
    "   - Defines a structured schema for a **movie object** using **Pydantic**.  \n",
    "\n",
    "2. **AI-Generated Object**  \n",
    "   - Generates a random movie object using an AI model while ensuring compliance with the schema.  \n",
    "\n",
    "3. **Readable Output**  \n",
    "   - Prints the generated movie object in **JSON format** for easy readability and usability.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Movie(BaseModel):\n",
    "    title: str = \"Movie name\"\n",
    "    year: int = 0\n",
    "    genre: str = \"movie genre\"\n",
    "    director: str = \"movie director\"\n",
    "    rating: float = 0.0\n",
    "\n",
    "\n",
    "response = generate_object(\n",
    "    prompt=\"Generate a random movie\",\n",
    "    response_model=Movie,\n",
    "    verbose=False,\n",
    "    debug=False,\n",
    ")\n",
    "\n",
    "print(response.model_dump_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Tool Execution and Response Generation\n",
    "\n",
    "### Imports and Setup  \n",
    "\n",
    "- **`random`**: A Python module used to generate random numbers.  \n",
    "\n",
    "- **`BaseModel`**: A class from Pydantic, used to define schemas and validate data structures.  \n",
    "\n",
    "---\n",
    "\n",
    "### Stock Price Function  \n",
    "\n",
    "- **`get_stock_price(symbol: str)`**: A function that simulates fetching a stock's price.  \n",
    "\n",
    "- **`random.randint(1, 200)`**: Generates a random stock price between 1 and 200.  \n",
    "\n",
    "- **`return`**: Returns a formatted string with the stock symbol and the random price.  \n",
    "\n",
    "---\n",
    "\n",
    "### Tools Setup  \n",
    "\n",
    "- **`tools`**: A list of dictionaries defining available tools.  \n",
    "\n",
    "    - Each tool contains:  \n",
    "\n",
    "      - **`name`**: The name of the tool.  \n",
    "\n",
    "      - **`description`**: A brief explanation of the tool's functionality.  \n",
    "\n",
    "      - **`function`**: The function to execute the tool's logic (e.g., **`get_stock_price`**).  \n",
    "\n",
    "      - **`input`**: A description of the required input parameters.  \n",
    "\n",
    "      - **`output`**: A description of the function's output.  \n",
    "\n",
    "---\n",
    "\n",
    "### Query Setup  \n",
    "\n",
    "- **`query`**: The user request, which asks for the stock price of \"AAPL\".  \n",
    "\n",
    "---\n",
    "\n",
    "### Pydantic Schema  \n",
    "\n",
    "- **`class ToolUseRequest(BaseModel)`**: Defines a Pydantic model named **`ToolUseRequest`** that inherits from **`BaseModel`**.  \n",
    "\n",
    "    - **`tool_name`**: **`str`** = \"tool name\": A string field representing the tool's name with a default value \"tool name\".  \n",
    "\n",
    "    - **`tool_input`**: **`dict`** = `{...}`: A dictionary field representing the input arguments for the tool, with a default set of arguments (arg1, arg2, info).  \n",
    "\n",
    "---\n",
    "\n",
    "### Prompt Setup  \n",
    "\n",
    "- **`prompt`**: A string containing the instruction for generating the tool request.  \n",
    "\n",
    "    - The **`query`** variable is inserted into the prompt to tell the assistant what the user asked.  \n",
    "\n",
    "    - It instructs the assistant to check whether any tool is needed and to provide the input in the predefined schema format.  \n",
    "\n",
    "    - It also tells the assistant to respond strictly using the defined schema, and not to invent any additional fields or types.  \n",
    "\n",
    "    - This setup ensures that the input for tools and the output will strictly follow the format required by the **`ToolUseRequest`** schema.  \n",
    "\n",
    "---\n",
    "\n",
    "### Tool Execution Function  \n",
    "\n",
    "- **`call_tool(tool_name, tool_input)`**: A function that takes the tool name and input parameters and executes the corresponding function.  \n",
    "\n",
    "    - It iterates through the **`tools`** list and checks for a match on the **`tool_name`**.  \n",
    "\n",
    "    - When it finds a match, it calls the associated tool's function (**`tool[\"function\"]`**) and passes the required parameters (**`**tool_input`**).  \n",
    "\n",
    "    - If no match is found, it returns **`\"Tool not found.\"`**.  \n",
    "\n",
    "---\n",
    "\n",
    "### Generating Object  \n",
    "\n",
    "- **`generate_object(...)`**: This function generates the structured request based on the provided prompt.  \n",
    "\n",
    "    - **`prompt`**: The input query and instructions for the assistant (including the available tools).  \n",
    "\n",
    "    - **`response_model`**: The model (**`ToolUseRequest`**) that the assistant's response must match.  \n",
    "\n",
    "    - **`verbose` and `debug`**: Flags to enable detailed logging of the process.  \n",
    "\n",
    "    - The function will output an object based on the assistant's response that contains the name of the tool to be used and the input parameters.  \n",
    "\n",
    "---\n",
    "\n",
    "### Handling the Tool Output  \n",
    "\n",
    "- **`tool_output`**: A variable initialized to **`None`**, which will later store the result of the tool.  \n",
    "\n",
    "    - The **`if`** condition checks whether a valid tool is specified.  \n",
    "\n",
    "    - It ensures that **`response.tool_name`** is not null, empty, or the string \"None\".  \n",
    "\n",
    "    - If a valid tool is specified, the function **`call_tool(response.tool_name, response.tool_input)`** is called to execute the tool and obtain the result.  \n",
    "\n",
    "    - The result is printed and assigned to the **`tool_output`**.  \n",
    "\n",
    "---\n",
    "\n",
    "### Final Prompt with Tool Output  \n",
    "\n",
    "- **`prompt`**: A final formatted string that includes the original query, the tool used, the input for that tool, and the resulting output.  \n",
    "\n",
    "    - This will display the entire flow from the user's query to the tool's execution and the final result.  \n",
    "\n",
    "---\n",
    "\n",
    "### Summary of Code's Flow  \n",
    "\n",
    "- **Setup**: Defines a list of available tools and a query asking for the stock price of \"AAPL\".  \n",
    "\n",
    "- **Schema**: Defines a Pydantic schema (**`ToolUseRequest`**) for structuring the tool request.  \n",
    "\n",
    "- **Generate Object**: Uses the **`generate_object`** function to generate the structured tool request based on the user's query.  \n",
    "\n",
    "- **Tool Execution**: If the generated response contains a valid tool name, it executes the tool (**`call_tool`**).  \n",
    "\n",
    "- **Final Output**: Outputs the tool's result, including the tool name, input, and output.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "def get_stock_price(symbol: str) -> str:\n",
    "    price = random.randint(1, 200)\n",
    "    return f\"The current price of {symbol} is {str(price)}.\"\n",
    "\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"name\": \"Get Stock Price\",\n",
    "        \"description\": \"Get the current price of a stock.\",\n",
    "        \"function\": get_stock_price,\n",
    "        \"input\": [\n",
    "            {\n",
    "                \"name\": \"symbol\",\n",
    "                \"type\": \"str\",\n",
    "                \"description\": \"The stock symbol.\",\n",
    "            }\n",
    "        ],\n",
    "        \"output\": {\n",
    "            \"return_type\": \"str\",\n",
    "            \"description\": \"The current price of the stock.\",\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "query = \"Get the current price of AAPL.\"\n",
    "\n",
    "\n",
    "class ToolUseRequest(BaseModel):\n",
    "    tool_name: str = \"tool name\"\n",
    "    tool_input: dict = {\n",
    "        \"arg1\": \"val1\",\n",
    "        \"arg2\": \"val2\",\n",
    "        \"info\": \"This object should contain the args for the tool and the arg names should correspond to the provided tool args.\",\n",
    "    }\n",
    "\n",
    "\n",
    "prompt = f\"\"\"For the given query: {query}. \n",
    "    Tell me if you need any tools to be used and provide the input for the tool.\"\n",
    "    These are the available tools: {tools}\".\n",
    "    If no tool needs to be used respond with null values.\n",
    "    Respond strictly in the given schema format.\n",
    "    Don't make up field names or types.\n",
    "    Use the exact field names and types as given in the schema.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def call_tool(tool_name: str, tool_input: dict):\n",
    "    for tool in tools:\n",
    "        if tool[\"name\"] == tool_name:\n",
    "            return tool[\"function\"](**tool_input)\n",
    "    return \"Tool not found.\"\n",
    "\n",
    "\n",
    "response = generate_object(\n",
    "    prompt=prompt,\n",
    "    response_model=ToolUseRequest,\n",
    "    verbose=True,\n",
    "    debug=True,\n",
    ")\n",
    "\n",
    "tool_output = None\n",
    "\n",
    "if not (\n",
    "    not response.tool_name\n",
    "    or response.tool_name == \"null\"\n",
    "    or response.tool_name == \"None\"\n",
    "    or response.tool_name == \"\"\n",
    "):\n",
    "    result = call_tool(response.tool_name, response.tool_input)\n",
    "    print(\"Tool Output:\", result)\n",
    "    tool_output = result\n",
    "\n",
    "prompt = f\"\"\"Query: {query}\n",
    "    TOOLS USED:\n",
    "    Tool Name: {response.tool_name}\n",
    "    Tool Input: {response.tool_input}\n",
    "    Tool Output: {tool_output}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This code is designed to help manage user queries and connect with different external tools in a smooth and organized way. It uses a system called Pydantic to check that the information users provide is accurate and follows the required format. This helps avoid errors and ensures that the program works properly.\n",
    "\n",
    "When a user asks a question, the code decides which external tool (like an API or service) is needed to answer the query and then runs that tool. The results are then returned in a clear, expected format.\n",
    "\n",
    "The way the code is set up makes it easy to add new tools or services, which means it can be used for various tasks. For example, it could be applied in customer service systems, where the program automatically interacts with users and uses external services to help answer their questions or solve problems.\n",
    "\n",
    "In short, this system allows the program to talk to different tools and services easily, making it efficient for automating tasks, answering queries, and processing information. It is designed to be flexible, reliable, and easy to expand for future needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Thank You for visiting The Hackers Playbook! 🌐\n",
    "\n",
    "If you liked this research material;\n",
    "\n",
    "- [Subscribe to our newsletter.](https://thehackersplaybook.substack.com)\n",
    "\n",
    "- [Follow us on LinkedIn.](https://www.linkedin.com/company/the-hackers-playbook/)\n",
    "\n",
    "- [Leave a star on our GitHub.](https://www.github.com/thehackersplaybook)\n",
    "\n",
    "<div style=\"display:flex; align-items:center; padding: 50px;\">\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"200px\" style=\"width:auto;\" width=\"200px\" src=\"https://avatars.githubusercontent.com/u/192148546?s=400&u=95d76fbb02e6c09671d87c9155f17ca1e4ef8f21&v=4\"> \n",
    "</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
